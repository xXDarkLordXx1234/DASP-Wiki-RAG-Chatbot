%META:TOPICINFO{author="bugert" comment="" date="1580121799" format="1.1" reprev="25" version="25"}%
%META:TOPICPARENT{name="WebHome"}%
<div style="color: orange; font-weight:800; border: solid 2px orange; padding: 5px">
<p align="center">
We are in late beta stage until Q2 2020.
</p>
</div>

---+!! Slurm Compute Cluster
%TOC%

---++ Frequently Asked Questions
See [[ComputeClusterFAQ]].

---++ Principle of Slurm
On traditional compute servers (the way we had them at UKP before summer 2019), running compute experiments works by connecting to a specific server, then starting a script with GNU screen or tmux.

Slurm is a job scheduling service. With Slurm, compute experiments are done by connecting to a headnode where one can submit a compute job into a queue of compute jobs. Slurm prioritizes compute jobs in a way that every user gets his/her share of the compute resources that he/she deserves. If a compute job has a high enough priority and a node (== compute server) with sufficient resources is free, Slurm will automatically start the compute experiment. Once a job finishes, an email notification is sent.

---++ Walkthrough Usage Example

Jobs on slurm are started by writing a shell script and then calling it via =sbatch myscript.sh= . The [[https://slurm.schedmd.com/sbatch.html][official sbatch documentation]] describes all parameters that can be used.

<div style="border: solid 2px lightblue; font-weight:800; padding: 5px">
<p align="center">
[[https://public.ukp.informatik.tu-darmstadt.de/slurm-tutorial/slurm-tutorial.zip][A tutorial project for our Slurm compute cluster can be found here.]]
</p>
</div>

More examples can be found on the websites of the [[https://www.hhlr.tu-darmstadt.de/hhlr/arbeit_auf_dem_cluster/arbeit_mit_lsf_1/index~1.de.jsp][TU Darmstadt Lichtenberg]] or the [[https://doku.lrz.de/display/PUBLIC/Example+parallel+job+scripts+on+the+Linux-Cluster][Leipzig Rechenzentrum]], or at [[https://www.ch.cam.ac.uk/computing/slurm-usage][Univ Cambridge]].

---++ Quota

Before explaining how user quotas work, you need to learn about accounts in Slurm.

---+++ Accounts
Slurm tracks resource usage via so-called *accounts*. Slurm accounts work a bit like bank accounts, i.e. a single user can have multiple accounts.
The total compute power of the cluster is distributed across all accounts, meaning every account receives a percentage of the total compute power. Your affiliation (the lab you belong to) and your employment relation (researcher or student) decides over your accounts and their quota. If your affiliation is UKP/AIPHES, you will have one UKP account and one AIPHES account, giving you a larger share of the total compute power.

You can see your accounts via =sshare -U=. Add =--account=SOME_ACCOUNT= to your =sbatch= or =srun= call to run using a different account.

---+++ !FairShare
Account quotas in Slurm are not hard limits. Instead, every account has a !FairShare value between 0.0 and 1.0 attached to it. Jobs can be submitted independent of the !FairShare value. However, *jobs by accounts with higher !FairShare value are prioritized by the scheduler*. By running jobs, the !FairShare value decreases depending on the duration and the resource requirements of the jobs. The !FairShare value recovers over time (it has a half-life of two weeks).

%INCLUDE{"ComputeClusterDetermineFairShare"}%

---++ Partitions / Queues

When submitting a job in Slurm, one has to specify a *partition* into which the job will be queued. We have several partitions in our cluster for different purposes. Some are for day-in-day-out experiments, one is for testing jobs interactively, one for running demonstrator systems, and so on. We explain each partition's time and resource limits below.

   * To run a job in a specific partition use =-p PARTITIONNAME=, for example <verbatim>sbatch -p aiphes your_script.sh</verbatim>
   * To see all available partitions, run =scontrol show partition=

%TABPANE%
%TAB{"aiphes, tk, ukp"}%
These are the default partitions for each lab with multiple GPU and CPU nodes. The following limits apply:

%TABLE{ headerrows="2" }%
| *User Group* | *Researchers* || *Students* |
| *Available QOS* | *researcher (default)* | *snail* | *student* |
| Max nodes per job | 1 | 1 | 1 |
| Max CPUs per job | 24 | 16 %ICON{new}% | 24 |
| Max CPUs per user %ICON{new}% | 72 | 72 | 36 |
| Max GPUs per job | unlimited | 1 | unlimited  |
| Max GPUs per user | 4 | 4 | 2 |
| Max memory per job (GB) | 128 | 64 | 64 |
| Max memory per user (GB) %ICON{new}% | 384 | 384 | 192 |
| Max job duration (days) | 3 | 7 | 3 |

When submitting a job, one can request different *quality of service (QOS)* settings. The QOS influences the resource limits. %INCLUDE{"ComputeClusterLongRunningJobs"}%
%ENDTAB%
%TAB{"testing"}%
%INCLUDE{"ComputeClusterTestingPartition"}%
%ENDTAB%
%TAB{"yolo"}%
%ENDTAB%
%TAB{"demo"}%
This partition is reserved for running demonstrator systems for user studies.
%ENDTAB%
%ENDTABPANE%

---++ Resource Limits





---++ Slurm Command Documentation / External References

| *Command* | *Purpose* | *Example* | *Documentation* |
| =srun= | Schedule a compute job. Executed in the foreground (directly on your terminal). | =srun --pty bash=  | [[https://slurm.schedmd.com/srun.html]] |
| =sbatch= | Schedule a compute job. Executed in the background. | =sbatch my_script.sh= | [[https://slurm.schedmd.com/sbatch.html]] |
| =squeue= | Show the job queue and status. | =squeue --user=bugert= | [[https://slurm.schedmd.com/squeue.html]] |
| =scancel= | Cancel a job. | =scancel [job_id]= | [[https://slurm.schedmd.com/scancel.html]] |
| =sinfo= | Show status of cluster nodes and available resources. | =sinfo --Format=nodehost,statelong,cpus,memory,gres= | [[https://slurm.schedmd.com/sinfo.html]] |
| =sshare= | Display accounts and !FairShare. | =sshare -a= | [[https://slurm.schedmd.com/sshare.html]] |

---++ Moving code and data into the cluster
See [[ComputeClusterStorage]].

%META:TOPICMOVED{by="bugert" date="1570804848" from="Services.ComputeCluster" to="Services/Campus.ComputeCluster"}%
