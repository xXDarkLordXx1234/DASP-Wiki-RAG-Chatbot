%META:TOPICINFO{author="ArnePottharst" date="1202314686" format="1.1" version="3"}%
%META:TOPICPARENT{name="ArnePottharst"}%
---+ Logbuch
%TOC%

---++ 06.02.2008
Erschließen eines Textkorpus "Redaktionelle Texte":
   * Crawlen verschiedener Newssites mittels Curl und Wget, Texte ca. seit Anfang 2007 bis heute
   * Extrahieren des Textes mittels Perl
   * Einspeisen in MySQL-Datenbank für schnellen Zugriff
   * Statistik:
      * heise.de: 3259 Texte
      * hartware.de: 2973 Texte
      * de.internet.com: 471 Texte
      * golem.de: 7757 Texte
   * Insgesamt also: 14460 Texte

Jetzt muß ich schauen, welche Texte geeignet sind, also nach Stichwörtern sinnvolle Texte herausfinden und markieren. Von diesen Texte einige manuell klassifizieren für Stanford-NER-Training. Ausprobieren, ob ich das mit Hilfe von Wikipedia-Artikeln machen kann.

Ein weiterer Textkorpus soll "User generated Content", also Blogeinträge, enthalten, hier muß ich schauen, die Technokrati funktioniert.

---++ 05.02.2008
Trainieren des Stanford-NER mit ein paar Textdateien, die ich von Hand klassifiziert habe. Erste Ergebnisse sehen ganz gut aus, es werden auch Dinge richtig klassifiziert, die in den Trainingsdaten nicht vorhanden sind, aber ein paar Fehler treten noch auf, ich brauche mehr Trainingsdaten.

---++ 01.02.2008
Checkin ins SVN:
   * Der *WikiParser*, der zum Erstellen von SVN-Dateien dient, die dann eingelesen werden können von K-Infinity
   * Grundversion des *Stanford-NER*. In der Datei !TeXHyphenator#loadDefault() habe ich einen String eingefügt, der gefehlt hat, Decompiler sei Dank ;-)

---++ 25.01.2008
Erstellen des Wissensnetzes:
   1 Einlesen von Wikipedia-Kategorien (=Typen)
   1 Einlesen von Artikeln mit Zuordnung zu den Kategorien (=Instanzen)
   1 Einlesen der Links in den Artikeln, um die Artikel untereinander zu verlinken.
  
Dies alles kann ich in K-Infinity importieren und so ein Wissensnetz daraus aufbauen.
Es fehlen allerdings noch wichtige Metainformationen bei den Links zwischen den einzelnen Artikeln wie "A stellt her B" oder "A ist Konkurrent von B", ebenso könnten noch Metainformationen zu den einzelnen Instanzen gespeichert werden. Hier überlege ich grade, welche Informationen ich noch aus Wikipedia ziehen kann, und ob bzw. welche weiteren Quellen ich noch verwenden kann -> Ideen sind willkommen :-) 

---++ 09.01.2008
Einarbeitung in UIMA und K-Infinity: ich habe ein Testprogramm (Proofe of Concept) für UIMA erstellt, das einen gegebenen Text zerlegt und großgeschriebene Wörter in einem Text findet (seeehr simples NER) und diese im Wissensnetz von K-Infinity sucht und gefundene entsprechend in UIMA markiert.