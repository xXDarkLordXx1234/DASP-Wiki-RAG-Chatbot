%META:TOPICINFO{author="SimonKulessa" date="1227104203" format="1.1" version="14"}%
%META:TOPICPARENT{name="SimonKulessa"}%
Fehler unbekannter Ursache und andere Dinge:


---++ !UKPSentenceSplitter:

<b>Vermutete Ursache</b><br>
DocumentText ist null ... UKPSentenceSplitter hat keine Möglichkeit auf die Views zuzugreifen ??<br>
<br>
CAS Objekt im Reader befüllt mit ...<br>
<br>
		// Set previous revision<br>
		JCas revA = jcas.createView("PREVIOUS_REVISION");<br>
		revA.setDocumentText(previousRevision);<br>
<br>
		// Set current revision<br>
		JCas revB = jcas.createView("CURRENT_REVISION");<br>
		revB.setDocumentText(currentRevision);<br>
<br>
<br>
<b>StackTrace</b><br>

org.apache.uima.analysis_engine.AnalysisEngineProcessException: Annotator processing failed. <br>   
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.callAnalysisComponentProcess(PrimitiveAnalysisEngine_impl.java:389)<br>
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.processAndOutputNewCASes(PrimitiveAnalysisEngine_impl.java:297)<br>
	at org.apache.uima.analysis_engine.impl.AnalysisEngineImplBase.process(AnalysisEngineImplBase.java:218)<br>
	at org.apache.uima.collection.impl.cpm.engine.ProcessingUnit.processNext(ProcessingUnit.java:892)<br>
	at org.apache.uima.collection.impl.cpm.engine.ProcessingUnit.run(ProcessingUnit.java:577)<br>
Caused by: java.lang.NullPointerException<br>
	at java.text.StringCharacterIterator.<init>(Unknown Source)<br>
	at java.text.StringCharacterIterator.<init>(Unknown Source)<br>
	at java.text.BreakIterator.setText(Unknown Source)<br>
	at de.tudarmstadt.ukp.dkpro.core.annotator.UkpSentenceSplitter.makeAnnotations(UkpSentenceSplitter.java:73)<br>
	at de.tudarmstadt.ukp.dkpro.core.annotator.UkpSentenceSplitter.process(UkpSentenceSplitter.java:66)<br>
	at org.apache.uima.analysis_component.JCasAnnotator_ImplBase.process(JCasAnnotator_ImplBase.java:48)<br>
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.callAnalysisComponentProcess(PrimitiveAnalysisEngine_impl.java:375)<br>
	... 4 more<br>
<br>

----------------

*TZ:* !SentenceSplitter ist eine Single-View Komponente, die eigentlich nichts von Views weiss. Sie kann aber auch mit Views arbeiten, indem im CPE Deskriptor (oder im Aggregate) ein !SofaMapping vorgenommen wird.
<verbatim>
<sofaNameMappings>
<sofaNameMapping cpeSofaName="PREVIOUS_REVISION" componentSofaName="_InitialView"/>
</sofaNameMappings>
</verbatim>

Damit beide Revisionen bearbeitet werden, muss der !SentenceSplitter entsprechend zweimal aufgerufen werden, mit jeweils anderem !SofaMapping.

----------------

*SK:*
Scheint zu funktionieren ... vorrausgesetzt man benutzt die richtigen Felder ;).

Ist es eigentlich normal das die CPE GUI jedesmal eine NullPointerException wirft wenn man den Reader ändert?
Das neue Laden eines Readers scheint nur nach dem Ausführen von 'Clear-All' möglich zu sein.

----------------

*TZ:* Ja, ist normal. Ist ein Bug in der GUI.
----------------
---++ Zuordnen von Annotation zu Sofa's

Eigentlich wollte ich die Annotation den Sofa's / Views zuordnen, aber das scheint nicht möglich / nicht notwendig zu sein ?

  * [[%ATTACHURL%/SQLDiffReader.xml][SQLDiffReader.xml]]: Reader<br>

Im Deskriptor ist das nicht notwendig. Alle Views, die von einer CAS abgeleitet werden, erben dessen Filesystem.
Im Java-Code muss man die Annotationen natuerlich dann dem View hinzufuegen =view.addToIndexes()= anstatt der CAS =jcas.addToIndexes()=.

----------------
---++ Paramter Gruppen
Die CPE GUI zeigt keine Parameter Gruppen an?

*TZ:* Ja, die GUI ist halt doof.

----------------
---++ Iterieren von Annotation
<br>
Ich habe das Diff nun über Annotation an den Revisionen realisiert (und nicht über einen getrennten View).<br>
Nun würde ich gerne anhand dieser Annotationen zugriff auf die Sentence Annotation kriegen.<br>
<br>
Gibt es eine einfachere Methode (bessere Schnittstelle) als die über die beiden Annotations-Typen getrennt <br>
zu iterieren und die Indizes zu vergleichen?<br>
<br>
Beispiel:<br>
Revision A enthält eine Diff Annotation von Position 200 bis 300, <br>
und Satz Annotationen von 0-150, 151-210, 211-290, 291-330, ...<br>
<br>
Als Ergebniss will ich die Sätze 151-210, 211-290 und 291-330 zurückgeliefert bekommen.<br>
*TZ:* In diesem Fall hilft der Subiterator nicht weiter, da die Indizes nur teilweise überlappen. Dann musst du tatsächlich über die Satz Annotationen iterieren und die Offsets vergleichen.
<br>
Ps: Der Iterator iteriert immer in text-positions-Reihenfolge ?<br>
*TZ:* Ja.
<br>
<br>

---++ !UKPSentenceSplitter II:

Verbessungsvorschläge:
   1 Ein einzelner Punkt ist kein Satz
   1 Ein einzelner Buchstabe gefolgt von einen Punkt ist kein Satz(ende)
      * Kann sein, muss aber nicht: "'Ich darf nicht nochmal antreten', sagte George W."
   1 Das Fragezeichen in einer URL ist ebenfalls kein Satzende
   1 (==[=]+) sollte (optional?) als Satzende interpertiert werden

Wenn du die Funktionalität brauchst, solltest du sie als zusätzlichen Sentence Splitter II (wie in Überschrift angedeutet) implementieren.
Alternativ kann man auch damit leben und die auftretenden Probleme beim Bereinigen der Kandidaten angehen.
Wie es besser geht ...

*SK:* Da es sich bei den Wikipedia Revisionen um "HTML Texte" handelt, kann man ebenfalls davon ausgehen, 
dass jeder Zeilenumbruch einem neuen Satz entspricht. (Edit: Stimmt leider doch nicht)

Daher werde ich wohl einen Sentence Splitter II bauen, der die Sätze nocheinmal überprüft und die Annotationen ggf ändert.

<br>
---++ Bereinigung des Textes<br>
<br>
Die Aufgabenstellung sieht eine Bereinigung des Textes vor ...<br>
<br>
Spricht etwas dagegen wenn man einfach alles was kein Buchstabe (A-Za-z) ist<br>
{und ggf. kein Satzzeichen (, . ; ! ?) ist -- Die Satzzeichen spielen für die Paraphrasensuche ja eigentlich keine Rolle?}<br>
aus dem Kandidaten-Text eliminiert. Damit das ganze prinzipiell sprachunabhängig bleibt man könnte man das <br>
Alphabet als optionalen Parameter übergeben.<br>
--<br>
Für diesen Schritt würde ich auch keine eigenen Komponenten implementieren, sondern das ganze direkt nach<br>
dem Extrahieren der Kandidaten (vor Erzeugung und Befüllung der neuen CAS - siehe nächstes Thema) machen.<br>
Ggf. ebenfalls in Verbindung mit einem zusätzlichen Satz Splitter.<br>
<br>
Das würde dann allerdings eher in die Richtung gehen, dass der CandidateExtractor und der CandidateFilter<br>
zusammengelegt werden und alle 'einfachen Filter' Schitte in dieser Komponente gemacht werden.<br>
<br>
Zusammengefasst wären das folgende Schritte:<br>
1. Erkennen und extrahieren der Kandidaten<br>
2. Bereinigen der Kandidaten-Sätze<br>
3. Splitting der Sätze in Token (anhand der Leerzeichen - siehe Thema weiter unten)<br>
4. Vergleichen der Token der Kandidaten per Bag-Of-Words<br>
5. Erstellung eines neuen Views mit Token, Sentence und ParaphraseCandidate Annotationen.<br>
<br>

*TZ:* wegen Bereinigung solltest du zu einem Gesprächstermin mit Delphine sprechen

---++ CASMultiplier / Flow Controll<br>
<br>
Annotator: CandidateExtractor<br>
<br>
Momentan ändere ich keines der beiden Datenhaltenden CAS-Objekte (Previous und CurrentRevision),<br>
um ggf. die Referenz zum unveränderten Text nicht zu verlieren.<br>
<br>
Stattdessen erzeuge ich einen neuen View und ergänze dort die Annotationen die ich für den Rest der Pipeline brauche. <br>
<br>
Das erzeugen eines neuen View (CAS) - das in jedem Fall erzeugt werden müsste - <br>
dürfte gegenüber den CASMultiplier - der dann entweder 0 oder 1 neues CAS erzeugen würde - <br>
nur Nachteile haben (?). <br>
<br>
Ich denke in diesem Fall wäre die Verwendung eines CASMultipliers von Vorteil, vorausgesetzt man kann die<br>
Referenz auf das ursprüngliche Objekt für diesen zusätzlichen Schritt im Objekt behalten (- aber ich meine<br>
irgendwo gelesen zu haben, dass man das nicht machen sollte.)<br>
<br>
Eine (bessere?) Alternative dazu wäre möglicherweise die Benutzung eines Flow Controllers. <br>
Allerdings habe ich diesen Teil von UIMA noch nicht verstanden. <br>
<br>
Habt ihr ein Beispiel bei das einen Flow Controller verwendet?<br>
Am besten eines wo das CAS Objekt ggf. gedroppt wird.<br>
<br>
<br>

*TZ:* Wir haben hier leider kein Beispiel. Vielleicht gibt es etwas in den UIMA Beispielen selbst. Musst du mal schauen. Den Rest der Diskussion zu Multipliern verstehe ich nicht.

*SK:* Ich suche weiterhin einen Weg zu finden dass CAS unnötigt erzeugt werden, sowie einen Weg zu verhindern das CAS die keinen Sinn und Zweck mehr haben durch die Pipeline laufen.

*TZ:* Da die Pipeline lokal fuer ein Dokument (d.h. ein Revisionspaar ist) scheint es mir egal zu sein, ob ungenutzte CAS weiter existieren (oder gibt es ein Speicherproblem?) Nach Abarbeitung des Dokumentes werden sowieso alle CAS weggeworfen.

---++ UKPTokenSpiltter:<br>
<br>
Was genau macht der eigentlich und auf welche Weise funktioniert er (java implementatorisch)?<br>
Im Prinzip vermutlich auch nicht mehr als die Leerzeichen zwischen einzelnen Wörtern zu erkennen?<br>
<br>

*TZ:* Warum musst du das wissen?

*SK:* Wenn ich den CandidateExtractor und CandidateFilter zusammenlege - was mir bisher die beste Lösung zu sein scheint - 
dann müßte ich die Token Annoationen innerhalb der Komponente selber erzeugen. 

Die Frage war daher ob ein Token "mehr" ist als ein Wort. Und falls ihr eine bessere Art und Weise kennen würdet um 
die Token zu unterteilen, wäre ich nicht abgeneigt diese zu verwenden.

*TZ:* Andere Komponenten wie der POS-Tagger verlassen sich darauf, dass die Tokens exakt so sind, wie unser Tokenizer sie macht (prinzipiell sind es tatsächlich nur "Wörter"). Aber was ist ein Wort? Wenn da etwas steht wie =Adam's house=, ist =Adam's= ein Wort, oder sind es eigentlich zwei (=Adam= und ='s=)?

---++ Fehlende Resourcen:<br>
<br>
Spell Checker:<br>
ClassNotFoundException 	com/swabunga/spell/engine/SpellDictionary<br>
----------------
<br>
SwearWord Tagger:<br>
FileNotFoundException 	 	\home\chmark\Tools\Jazzy\dictionary\swear_words.txt <br>
(Es ist ebenfalls ungünstig das der Pfad der Datei nicht per Parameter übergeben werden kann)<br>
----------------
<br>
StopWordTagger:<br>
Muss ich die StopWörter dort selber eintragen oder gibt es dafür eine InputFile?<br>
<br>
Fehlermeldung beim starten ohne etwas einzutragen:<br>
...<br>
Caused by: java.lang.NullPointerException<br>
	at de.tudarmstadt.ukp.dkpro.ir.annotator.util.StopWordSet.<init>(StopWordSet.java:29)<br>
	at de.tudarmstadt.ukp.dkpro.ir.annotator.StopWordTagger.initialize(StopWordTagger.java:51)<br>
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.initializeAnalysisComponent(PrimitiveAnalysisEngine_impl.java:251)<br>
	... 18 more<br>
<br>

*TZ:* Diese Komponenten wurden kürzlich verbessert. Bitte beim nächsten Gesprächstermin darauf ansprechen.

----------------
TreeTaggerPosLemma<br>
<br>
Kein Problem hiermit (vorerst), aber der "Language Code: en" und die Benutzung der "english.par" Parameter File<br>
(heruntergeladen von http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html) ist korrekt?<br>

*TZ:* Ist korrekt.

*SK:* Ganz so problemlos läufts dann doch nicht, der Tree Tagger Thread ist ziemlich oft tot.

ThreadGroup.uncaughtException()-Got Error<br>
java.lang.ThreadDeath<br>
	at java.lang.Thread.stop(Unknown Source)<br>
	at de.tudarmstadt.ukp.dkpro.core.annotator.TreeTaggerPosLemma.process(TreeTaggerPosLemma.java:198)<br>
	at org.apache.uima.analysis_component.JCasAnnotator_ImplBase.process(JCasAnnotator_ImplBase.java:48)<br>
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.callAnalysisComponentProcess(PrimitiveAnalysisEngine_impl.java:375)<br>
	at org.apache.uima.analysis_engine.impl.PrimitiveAnalysisEngine_impl.processAndOutputNewCASes(PrimitiveAnalysisEngine_impl.java:297)<br>
	at org.apache.uima.analysis_engine.impl.AnalysisEngineImplBase.process(AnalysisEngineImplBase.java:218)<br>
	at org.apache.uima.collection.impl.cpm.engine.ProcessingUnit.processNext(ProcessingUnit.java:892)<br>
	at org.apache.uima.collection.impl.cpm.engine.ProcessingUnit.run(ProcessingUnit.java:577)<br>

----------------
<br>
Antonymie:<br>
Da wolltest du mir zuschicken was auch immer du hast.<br>
<br>

*TZ:* Es hat ziemlich viele Abhängigkeiten. Bin noch dabei es zusammenzustellen. Bitte nochmal in ein paar Tagen nachfragen.
-- Main.SimonKulessa - 26 Oct 2008

----------------
---++ SpellChecker<br>
<br>
Mich würde interessieren was genau der SpellChecker macht. <br>
Ich hatte angenommen das er einfach überprüft ob das gelesene Token in der dict-Datei vorhanden ist oder nicht. Da aber auch Token überleben die nicht in der Datei vorhanden sind, scheint das ja nicht ganz so einfach zu sein.<br>

-- Main.SimonKulessa - 19 Nov 2008


%META:FILEATTACHMENT{name="SQLDiffReader.xml" attachment="SQLDiffReader.xml" attr="" comment="SQLDiffReader Component Description" date="1224424263" path="SQLDiffReader.xml" size="3219" stream="SQLDiffReader.xml" tmpFilename="/var/tmp/CGItemp29245" user="SimonKulessa" version="1"}%
