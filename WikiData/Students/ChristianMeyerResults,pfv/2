%META:TOPICINFO{author="ChristianMeyer" date="1231421873" format="1.1" reprev="2" version="2"}%
%META:TOPICPARENT{name="ChristianMeyer"}%
---+!! Results

%TOC%

---++ Passage Extraction
---+++ Duplicate Document Remover
Remove documents, that are identical (i.e. same MD5 hash) to at least one other document of the retrieved collection.
| *data* | *removed* | *remaining* |
| defQ-0 | 2d, 5p, 13s | 58d, 453p, 1388s |
| defQ-1 | 8d, 8p, 32s | 52d, 286p, 1269s |
| defQ-4 | 6d, 12p, 28s | 54d, 372p, 2402s |
| defQ-9 | 0d, 0p, 0s | 60d, 594p, 2107s |
| defQ-10 | 3d, 3p, 3s | 39d, 147p, 453s |
| defQ-14 | 2d, 2p, 25s | 58d, 310p, 952s |
   <small>d = document, p = paragraph, s = sentence</small>

---+++ Paragraph Filter
Remove paragraphs having a small similarity score. Used measures are Cosine (threshold = 0.065), Leacock/Chodorow (t = 0.513) and Resnik (t = 0.06); a paragraph is removed if at least one of the measures drops below the threshold (exception: paragraphs without a score are kept, i.e. paragraphs having only tokens, that are not in <nop>WordNet). Goal is to not filter relevant paragraphs (filtered-relevant).
| *data* | *filtered* | *filtered-relevant* | *precision* | *remaining* | *remark* |
| defQ-0 | 206p, 455s | 1p, 1s | 99.51% | 58d, 247p, 933s | training data |
| defQ-10 | 96p, 286s | 6p, 14s | 93.75 % | 39d, 51p, 167s | validation data |
   | defQ-14 | 143p, 391s | 3p, 6s | 97.90 % | 58d, 167p, 561s | validation data |
<small>d = document, p = paragraph, s = sentence<br />
precision = (filtered  filtered-relevant) / filtered</small>

---+++ Sentence Selector
Select relevant sentences with a high similarity score. Sentences in filtered paragraphs are not processed. Used measures are <nop>AltaVista-based PMI (threshold = 0.15) and Wikipedia-based ESA (threshold = 0.017). Both similarity scores have to be above the threshold to select a sentence. Goal is to select many relevant sentences, while not filtering too much.
| *data* | *filtered* | *filtered-relevant* | *precision* | *selected-relevant* | *recall* | *remaining* | *remark* |
| defQ-0 | 194s | 4s | 97.93 % | 106s | 96.36 % | 58d, 247p, 739s | training data |
| defQ-10 | 21s | 10s | 52.38 % | 70s | 87.50 % | 39d, 51p, 146s | validation data |
| defQ-14 | 72s | 2s | 97.22 % | 61s | 96.82 % | 58d, 167p, 489s | validation data |
<small>d = document, p = paragraph, s = sentence<br />
precision = (filtered  filtered-relevant) / filtered<br />
recall = selected-relevant / (filtered-relevant + selected-relevant)</small>

---+++ Passage Extent Determination
To improve results of the Sentence Selector, a HMM-based technique is applied, that takes advantage of the (natural) distribution of relevant passages: relevant passages are found more likely near other relevant passages, and irrelevant near other irrelevant passages. The HMM holds the two states RELEVANT and IRRELEVANT with transition probabilities a(R,R) = 0.87, a(R, I) = 0.13, a(I, R) = 0.04, a(I, I) = 0.96 [He04]. As symbols, the sentence similarity score is used. Emission probability is the average of scaled PMI and scaled ESA similarity, where scaled means applying a monotoneous function with f(0) = 0, f(threshold) = 0.5, f(1) = 1 and 0 <= f(x) <= 1. The results below use a function determined with quadratic spline interpolation.
| *data* | *filtered* | *filtered-relevant* | *precision* | *selected-relevant* | *recall* | *remaining* | *remark* |
| defQ-0 | 374s (+180s) | 3s (-1s) | 99.19 % (+1.26 %) | 107s (+1s) | 97.27 % (+0.91 %) | 58d, 247p, 559s | training data |
| defQ-10 | 22s (+1s) | 14s (+4s) | 36.36 %(-16.02 %) | 66s (-4s) | 82.50 % (-5.00 %) | 39d, 51p, 145s | validation data |
| defQ-14 | 29s (-43s) | 2s (+0s) | 93.10 % (-4.11 %) | 61s (+0s) | 96.82 % (+0.00 %) | 58d, 167p, 532s | validation data |
<small>d = document, p = paragraph, s = sentence<br />
precision = (filtered  filtered-relevant) / filtered<br />
recall = selected-relevant / (filtered-relevant + selected-relevant)<br />
values in brackets specify variations based on Sentence Selector results<br />
[He04] He, D./Demner-Fushman, D. et al. Improving Passage Retrieval Using Interactive Elicition and Statistical Modeling, In the proceedings of Text REtreival Conference (TREC) 2004.</small>

-- Main.ChristianMeyer - 08 Jan 2009