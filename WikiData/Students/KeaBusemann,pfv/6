%META:TOPICINFO{author="busemann" comment="" date="1623173771" format="1.1" reprev="5" version="6"}%
%META:TOPICPARENT{name="StudentsList"}%
Weekly Reports 

-- Main.KevinStowe - 2021-04-09

---+!! 23.04. - 29.04.

This week I have been setting up the following paired metrics:

BLEU, ROUGE, METEOR, TER, MoverScore, SentBERT

For the BLEU score I've used two different options: the concrete one and a smoothing function. Three metaphors in the dataset had zero n-grams, which led to a score of 0.0. With the smoothing funtion this can be avoided, but the scores are in general higher than the not smoothed ones.
Concerning the MoverScore I had to run the model on my CPU, because the Intel GPU doesn't support this as far as I know.
For the SentBERT embeddings I computed the cosine similarity.

Additionally, I started researching Perplexity, more on that is following next week.  

---+!! 30.04. - 06.05.

I trained a GPT2 Model to predict the Perplexity scores.
Also I have started setting up the linear regression model for metaphor novelty.

---+!! 07.05. - 13.05.

I set up the baseline models for linear regression on metaphor novelty und the classification for binary metaphors. 

---+!! 14.05. - 20.05.

This week I tried to improve the models and spend some time bugfixing. My main plan was to set up the binary classifier with a LSTM layer, but until now it doesn't work.

---+!! 21.05. - 03.06.

The binary classifier gets an accuracy of 91% on the test set (vuamc binary data) on classifying single words as metaphoric or not. I'm just using two simple Dense layers after one Flatten layer. To get the score of a whole sentence, each word is classified and the average over all word classes is taken.
The novelty model gets a MAE score of 0.141 on the test set on predicting the score for metaphoric words. To get the score of a whole sentence, for each word the score is predicted and the average over all scores is taken.
For both models, the best feature combination is the word embedding of the word to be classified together with the sentence embedding of the context (between punctuations). For the embeddings I'm using the "paraphrase-MiniLM-L6-v2" model from SentenceTransformers. 
