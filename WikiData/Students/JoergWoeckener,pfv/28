%META:TOPICINFO{author="eger" comment="" date="1551967733" format="1.1" reprev="27" version="28"}%
%META:TOPICPARENT{name="StudentsList"}%
Start date: 26.10.2018

End date: 26.03.2019


---++ Meeting Minutes 06.03.2019
   * Link to the training data for MTL
   * use more poems for English (between 10 and 20k) and indicate the size of your training sets
   * fix MTL training
   * histogram of rhyming and alliteration levels

---++ Summary 28.02. - 06.03.
   * MTL is working
   * Side Information is now relative to quatrain length
   * Lots of training/generating/evaluating for the thesis
      * Textgrid(german) for sentiment and temperature


---++ Meeting Minutes 21.02.2019
   * what are training sizes (# of quatrains)?
   * what are training distributions (how many negative poems / how many poems with alliteration level alpha / ....)?
   * why not include early stopping based on perplexity?
   * are poems with higher alliteration level longer?
   * we talked about the MTL model %IMAGE{"RNN_MTL_LM.jpg" size="200"}%
   * finally: think about analysis of whether system really understands alliteration or merely learns lexical associations

---++ Summary 15.02. - 21.02.
   * Evaluation of models with both real value and embeddings as side info on
      * Length
      * Alliteration
      * Sentiment (still computing)
      * Rhyme (Still computing)
 

---++ Meeting Minutes 15.02.2019
   * Run all the experiments for alliteration, sentiment, rhyme, long/short, in a batch:
      * 1000 generated quatrains, 0-1 interval at test time with 0.1 increment
      * make nice plots; please also plot the training distributions
      * do a bit of manual analysis for the extremes (i.e., 0 and 1): how do you rate the quality of the poems?
   * Repeat with 2,3 different temperature values
   * If everything works out, we can move on to MTL
   * Working with nohup and other tools, see slack

---++ Summary 08.02. - 15.02.
   * Side info can be fed in as real numbers
      * For alliteration (trained with inputs between 0 and 1)
         * Input 0 --> 113 (in 100 generated quatrains)
         * Input 0.5 --> 115
         * Input 1 --> 111
         * Input 90 --> 143
         * Input 180 --> 147
         * Input 1000 --> nonsense 
      * For rhyme (trained with inputs between 0 and 1)
         * Input 0.1 --> Average rhyming word pairs: 2.9 (in 100 generated quatrains)
         * Input 1 --> 3.5 
         * Input 10 -->  6.2
   * Sentiment anaylsis
      * Wordlists and Aylien do not agree.
      * Tested on 960 quatrains: 

---++ Meeting Minutes 07.02.2019
   * Finish alliteration and rhyming and sentiment by next week
      * adapt to real numbers, train, generate and evaluate (maybe 500 quatrains instead of 100); make examples and statistics - e.g. distribution of rhyme/alliteration density
      * Sentiment: take 500 random quatrains and label them by aylien, then compare with word list
   * Do more related work writing by next week:
      * ACL/NAACL/EMNLP papers are more important than workshop
      * describe a few important papers in detail
      * for the rest of the papers, compare to how the papers you read deal with related work
      * don't forget the non-neural generation models
      * focus on poetry generation and analysis
      * can also write on general sentiment/emotion analysis/detection
   * In 2 weeks, we'll do the Multi-task learning quickly

---++ Summary 01.02. - 07.02.
   * Tagged Deepspeare and Chicago corpus with density for alliteration and rhyme
      * the tag is the number of alliterating words within a quatrain (ranges from 0 to 16)
      * during generation the density value can be used as an input to influence generation
      * input "0" yields 98 alliterating words in 100 generated samples
      * input "6" yields 126 alliterating words in 100 generated samples
      * input of higher numbers like "14" yield 106 allitterating words in 100 generated samples
   * started work on thesis
  

---++ Meeting Minutes 31.01.2019
   * run experiments with "alliteration density", "rhyme density" and sentiment
      * Give examples of most rhyming, most alliterating quatrain
   * Try to find one additional sentiment tool besides word lists
      * if after 24h you found nothing usable, forget it and work with word lists
      * e.g. try asking the nvidia guys again
      * or this one: https://github.com/words/polarity
   * Write related work or your unidirectional model until next week
   * After that, do at least 50% writing per week
      * Give examples in thesis
   * We also discussed the multi-task setup

---++ Summary 25.01. - 31.01.
   * Update Textgrid Corpus with file from Thomas
   * Tag training data with alliterations and generate
      * Tested on Deepspeare and Chicago corpora 
   * Installed nvidia sentiment discovery


---++ Summary 18.01. - 24.01.
   * Generation mode works now. Results in slack
      * Tested on short/long verses
      * Tested with generating quatrains  
   * Prepared slides for midterm presentation
   * Temperature is implemented
  


---++ Meeting Minutes 17.01.2019
   * In general: you have to visit the UKP seminar on Tuesdays from time to time
   * This week try to finish:
      * plots of train/dev/test perplextiy of conditional model
      * Remove the _n and _p underscores from the label words
      * Look at 10 generated verses: are they reasonable?
      * How long are the _n and _p verses?
      * Implement temperature when sampling

   * Next week:
      * prepare the slides: 15-20min talk, 10 min Q&A
      * send us slides at least 1 or 2 days in advance
      * Example slides: https://docs.google.com/presentation/d/1YjI2q-Ab5ZxQrfFAdkFXoV9YblJao9UGDB097MrGWFI/edit?usp=sharing

   * Afterwards:
      * look at sentiment and G2P again
      * implement alliteration
      * implement BERT
      * continue with the writing
      * Multi-Task with Alliteration/Rhyme?

---++ Summary 11.01. - 17.01.
   * Generate sequences on K40 Server with different data sets and settings.
      * Results are mediocre --> should check for bugs, and optimization
      * (just had some better results this morning with 50/50 distribution of short and long verses and shuffling of training data)

---++ Summary 04.01. - 10.01.
   * Perplexity evaluation is finally working
   * I implemented the dummie approach for condititoned text generation (duplication of word vectors)
   * I also implemented the approach to concatenate side information to the input vectors 
   * K40 is now running with Tensorflow 
   * Todo:
      * Keep up work on Sentiment Analysis and Alliteration Detection
      * Do some larger scale runs with Nils model on K40

---++ Summary 20.12. - 03.01.
   * Implemented https://github.com/cmusphinx/g2p-seq2seq for g2p conversion to identify aliterations
      * works in english with pretrained model: 
      * tried to train it on german dataset but results are very bad (any given input word gets associated to some random translation from training set). Training is resource hungry, I should try it on K40 instead of my own gpu
         * SE: strange. Which data are you using? Which model?
   * Tested Aylien Text API on english and german poems to compare sentiment ratings with the word lookup approach. (Results in slack)
      * SE: You still miss the correlations. Does Aylien.API work for German at all?
   * Created bar plots and moving-average line plots for sentiment over time analysis 
      * SE: so, what do you conclude from this?

   * My personal TODO list:
      * train g2p tool on german data set on K40 (and generally make K40 work). I tried different configurations of tensorflow versions but either CUDA or CUDNN causes errors
         * SE: Ok
      * Perplexity evalution is still making problems with Nils' language model. Using Keras/tf built in calculation causes memory leak (at least I now know why) but Numpy calculation is slow
         * SE: what causes the memory leak?
      * Thinking about approaches for conditioned text generation. Basic idea (concatenation to input vector or hidden state) is clear but I think I need some input on how to implement this. 
         * SE: for the hidden state (which is the better solution I think), you need to look up how that works in keras. For the initial state, it's quite trivial.
      * find third and good working sentiment anaylsis tool
         * SE: Ok



---++ Meeting Minutes 20.12.
   * As conditioning/initial states: rhyme scheme, alliteration level, sentiment: "Stanislav Lem System"
   * Implement an alliteration model: 
      * use G2P or another rule-based approach
   * Focus on sentiment classification:
      * use multiple tools:
         * word lists
         * https://docs.aylien.com/textapi/sdks/#python-sdk
         * search for at least one more
      * give us examples of "best" and "worst" poems
      * can locate sentiment temporally or geographically
      * can also make it more fine-grained with a six-point list (joy, anger, etc.)

---++ Summary 13.12. - 19.12.
   * Nils joint model uses perplexity loss and evaluation is now measured with perplexity instead of accuracy
      * for evaluation I use two different datasets: one with samples from the training data and one with unseen data
      * while perplexity is continuously going down on the training data, it is rapidly going up after only three epochs on unseen data. Even with a model that only has one layer with 100 units.
         * SE: use more data
      * also I run into memory issues after a few epochs with validation (memory adds up with each evaluation and doesn't get released)
         * SE: file an issue and/or send Nils an email
   * I checked the sentiment scores by reading the most positive and negative rated poems. 
      * I think it worked good for german poems. 
      * English poems tend to be negative and ratings are not comprehensible (eg a sonnet with -40 should be very negative but [...]
         *  SE: give examples, otherwise we can't judge
   * I created a new reader for the datasets. It's now based on dictionaries instead of lists and therefore much faster.

---++  Minutes 13.12.2018
   * Perplexity instead of accuracy
   * Start with "\<sos\>", end with "\<eos\>"
   * Generate longer sequences - e.g., tuplets. Do they rhyme?
   * Use More data 
   * Look into sentiment again: 
      * does sentiment make sense?
      * look at top10, worst10, and agreement between different sentiment labelers
      * If sentiment is fine, you can add a positive/negative bit to the hidden layer or to the embedding layer
   * Alternatively/additionally: which classification task could we do?
      * end rhyming together with language model?
         * internal rhyming should also be fine
      * metre classification? on character level together with syllabification?
         * or only initial word metre classification?
         * or generating on syllable level and then classifying there?
   * Read the DeepSpeare paper 3 or 4 times:
      * do they classify metre, rhyme jointly with the language model or indepenedently?
      * how do we differ from their approach? do we do the same but more stupidly?


---++ Summary 06.12. - 12.12.
   * I tried Mallett for topic modelling. The code works but results are mediocre. Maybe it's a problem with hyperparamter tuning (filtering 'most common words' vs. 'most important words')
   * Most of the time I worked on Nils' baseline model. Current results are on Slack.



---++  Minutes 06.12.2018

   * turingtest.netzerei.at: keep in mind for evaluation in January or so
   * Put data on apu, plus the reader
   * Try out other data for DeepSpeare; play around with model architecture, parameters, etc.
   * Try to limericks (online?) or be general
   * double-dactyl: form on a particular poem
   * feed in (sentence) embedding as initial state of a RNN language model
      *  RNN
   * Mallet for topic modelling


---++ Summary 19.11. - 05.12.
   * Today(05.12.) I got the bug fixed and I can finally create environments or install things on the ukp-servers (they renamed my account to woeckener instead of wöckener)
      * SE: ok
   * So I tried to run Deepspeare but it does not run on GPU because of a CUDA version error (deepspeare is built with archaic tf 0.12 which only works with cuda 8 but cuda 9 is installed). I tried to run newer code which didn't work as well because it requires cudnn > 7. Also Marek Rei's Sequence Labeler Code doesn't work on GPU (libcublas.so.8.9 error). So I filed another bug.
      *  SE: ok. Make sure the language model works and make sure the bidirectional part doesn't interfere. 
   * Instead I ran deep speare on my cpu. Results are in slack.
      * SE: find out why temperature means at some point
      * SE: find out what annotations means
   * I updated the 'data', and 'related work' section in the thesis.
      * SE: will give you feedback next week
   * I also spent some hours installing Gramophone which just didn't work in the end. Documentation is sketchy or wrong. And the whole code gets revised soon (Kay didn't provide a date but he' working on it).   
      * SE: send me the data.  
   * For the experiments I looked into some other codebases and thought about how to apply it to poem generation. Well. I'd like to discuss this tomorrow. :)


---++ Meeting Minutes 29.11.2018
   * Besides the outstanding issues from last week (see below), you can start a bit looking at language generation softwares and try to make them run on UKP machines
      * E.g., try out DeepSpeare on GPU and see how fast it goes
      * Ideally, you also try out at least one more architecture, e.g., look at the Marek Rei ACL-2017 paper 
         * or classical language model
         * or GAN

---++ Summary 22.11. - 28.11.
   * I updated the related work section in the thesis and read a few papers again and more detailed. That was quite enlightning and I have a clearer idea of what we can do in the experiments . The summarization is more or less in the related work section + I updated the spreadsheet on google drive
      * SE: Great. Did it give you concrete new ideas?
      * JW: Yes, we can discuss this later on Slack.
      * SE: Btw. In the overleaf you write (roughly) "I'll not discuss non-neural approaches to poetry analysis/generation". I would indeed include a few relevant ones. Btw. sometimes it's sufficient to skim over a related work paper rather than read it entirely.
      * JW: Ok, I can add some non-neural approaches. Some are named in papers I read so this is fine. 
   * I trained a rhyme classifier and built an inference mode for it, so we can use it "easily"
      * SE: Great, nice to hear
   * I used wordlists for sentiment analysis. It's just an easy lookup + count pos/neg matches. Came to mind it's maybe too simplistic… Currently working on making bar plots to visualize the results/distribution
      * SE: Why do you think it's too simplisitic? Is there some related work that is doing this? Yea, Would be really nice to see some results.
      * JW: Well, many results are exactly zero. These are maybe short poems with unusual wording or just very neutral sentiment. Also the english poems tend to be negative with some poems having a very strong negative rating (-800 or sometimes more) but there is no outlier in positive direction. The german poems seem to be more balanced. I'm sure there are more sophistiacted approches. But on the other hand it actually is sufficient to divide positives from negatives. 
   * added a field "author" to the data and added a filter method
      * SE: nice, also year?
      * JW: Release date was already included (... if available, sometimes it's not included in metadata)
   * added a filter to get sonnets for all poems
   * Talking of bar plots… I created bar plots of time period distribution. Find an example attached to this mail.
      * SE: nice, where can I find them?
      * JW: I attached it to my post... but I'll send it to you on Slack  
   * I'm in contact with Kay Würzner, the creator of Gramophone. The tool is not very easy to use. I installed the requirements (one needed gcc compiling) but it turned out that the code on github is actually made for a web app and currently not working. Though it should be possible to run it on the console or even within python but I couldn't get it done. ALSO I'm not sure how important it is in the end. If we use it for rhyme detection we have another strong tool (~95% accuracy) working. For english we can still use the CMU dict if its about grapheme translation, which is quite often used in other works. If we want to use it for meter detection it may not be overly important as the guys from deepspeare claim that even their vanilla language model recognized meter implicitly.
      * SE: would still be nice if we have G2P for German (CMUdict doesn't do that) as well as stress for both English and German. What does K.Würzner say? Does he have a clue why it does not work?
      * JW: I'll give it another try :) 
   * I also contacted Arthur Jacobs for a word list more suitable for poems. He doesn't
      * SE: doesn't?
      * JW: ... have a list at hand. But we'll work something out maybe. . 
   * To do (maybe tomorrow): - make sentiment plots / probably implement another more sophisticated option for sentiment analysis - push code and files to TU servers
      * SE: Yes, I would like to see the data and apu and run your reader on it, that's doing G2P, syllabification, etc.

---+!! Meeting Minutes 22.11.2018

   * Please try to finish the item points in this week by next week, so we can move on to generation.
   * Also please send me a gitlab link to your PoetryReader and put all the data on apu


   1 - Assign poems a date in corpora
   2-  limericks, .... ; *sentiment* analysis of poems
      * sentiment wortlisten (Arthur Jacobs, see email, other sources for sentiment classification are also possible)
         * https://docs.aylien.com/textapi/sdks/#python-sdk
         * There are many sentiment labeled datasets out there, but not for poetry domain and not for our epochs, presumeably
      * or: sentiment annotated datasets
      * sentiments: humor, negativ, positiv
   3 - filter by author
   4- do we know authors as meta-data?
   5 - G2P: http://kaskade.dwds.de/gramophone/
   6 - Put code on gitlab, put data on apu
   7 - Related work (finish ASAP)
      * Poetry Analysis
      * Poetry Generation
      * (Language Generation)
   8 Language Model
   9 TU Design
   10 Tabelle fehlen
   11 Related work
   12 - Use supervised rhyme detector of Thomas Haider to assign rhymes for poems not rhyme labelled



-- Main.SteffenEger
      * give us examples of "best" and "worst" poems
      * can locate sentiment temporally or geographically
      * can also make it more fine-grained with a six-point list (joy, anger, etc.)

---++ Summary 13.12. - 19.12.
   * Nils joint model uses perplexity loss and evaluation is now measured with perplexity instead of accuracy
      * for evaluation I use two different datasets: one with samples from the training data and one with unseen data
      * while perplexity is continuously going down on the training data, it is rapidly going up after only three epochs on unseen data. Even with a model that only has one layer with 100 units.
         * SE: use more data
      * also I run into memory issues after a few epochs with validation (memory adds up with each evaluation and doesn't get released)
         * SE: file an issue and/or send Nils an email
   * I checked the sentiment scores by reading the most positive and negative rated poems. 
      * I think it worked good for german poems. 
      * English poems tend to be negative and ratings are not comprehensible (eg a sonnet with -40 should be very negative but [...]
         *  SE: give examples, otherwise we can't judge
   * I created a new reader for the datasets. It's now based on dictionaries instead of lists and therefore much faster.

---++  Minutes 13.12.2018
   * Perplexity instead of accuracy
   * Start with "\<sos\>", end with "\<eos\>"
   * Generate longer sequences - e.g., tuplets. Do they rhyme?
   * Use More data 
   * Look into sentiment again: 
      * does sentiment make sense?
      * look at top10, worst10, and agreement between different sentiment labelers
      * If sentiment is fine, you can add a positive/negative bit to the hidden layer or to the embedding layer
   * Alternatively/additionally: which classification task could we do?
      * end rhyming together with language model?
         * internal rhyming should also be fine
      * metre classification? on character level together with syllabification?
         * or only initial word metre classification?
         * or generating on syllable level and then classifying there?
   * Read the DeepSpeare paper 3 or 4 times:
      * do they classify metre, rhyme jointly with the language model or indepenedently?
      * how do we differ from their approach? do we do the same but more stupidly?


---++ Summary 06.12. - 12.12.
   * I tried Mallett for topic modelling. The code works but results are mediocre. Maybe it's a problem with hyperparamter tuning (filtering 'most common words' vs. 'most important words')
   * Most of the time I worked on Nils' baseline model. Current results are on Slack.



---++  Minutes 06.12.2018

   * turingtest.netzerei.at: keep in mind for evaluation in January or so
   * Put data on apu, plus the reader
   * Try out other data for DeepSpeare; play around with model architecture, parameters, etc.
   * Try to limericks (online?) or be general
   * double-dactyl: form on a particular poem
   * feed in (sentence) embedding as initial state of a RNN language model
      *  RNN
   * Mallet for topic modelling


---++ Summary 19.11. - 05.12.
   * Today(05.12.) I got the bug fixed and I can finally create environments or install things on the ukp-servers (they renamed my account to woeckener instead of wöckener)
      * SE: ok
   * So I tried to run Deepspeare but it does not run on GPU because of a CUDA version error (deepspeare is built with archaic tf 0.12 which only works with cuda 8 but cuda 9 is installed). I tried to run newer code which didn't work as well because it requires cudnn > 7. Also Marek Rei's Sequence Labeler Code doesn't work on GPU (libcublas.so.8.9 error). So I filed another bug.
      *  SE: ok. Make sure the language model works and make sure the bidirectional part doesn't interfere. 
   * Instead I ran deep speare on my cpu. Results are in slack.
      * SE: find out why temperature means at some point
      * SE: find out what annotations means
   * I updated the 'data', and 'related work' section in the thesis.
      * SE: will give you feedback next week
   * I also spent some hours installing Gramophone which just didn't work in the end. Documentation is sketchy or wrong. And the whole code gets revised soon (Kay didn't provide a date but he' working on it).   
      * SE: send me the data.  
   * For the experiments I looked into some other codebases and thought about how to apply it to poem generation. Well. I'd like to discuss this tomorrow. :)


---++ Meeting Minutes 29.11.2018
   * Besides the outstanding issues from last week (see below), you can start a bit looking at language generation softwares and try to make them run on UKP machines
      * E.g., try out DeepSpeare on GPU and see how fast it goes
      * Ideally, you also try out at least one more architecture, e.g., look at the Marek Rei ACL-2017 paper 
         * or classical language model
         * or GAN

---++ Summary 22.11. - 28.11.
   * I updated the related work section in the thesis and read a few papers again and more detailed. That was quite enlightning and I have a clearer idea of what we can do in the experiments . The summarization is more or less in the related work section + I updated the spreadsheet on google drive
      * SE: Great. Did it give you concrete new ideas?
      * JW: Yes, we can discuss this later on Slack.
      * SE: Btw. In the overleaf you write (roughly) "I'll not discuss non-neural approaches to poetry analysis/generation". I would indeed include a few relevant ones. Btw. sometimes it's sufficient to skim over a related work paper rather than read it entirely.
      * JW: Ok, I can add some non-neural approaches. Some are named in papers I read so this is fine. 
   * I trained a rhyme classifier and built an inference mode for it, so we can use it "easily"
      * SE: Great, nice to hear
   * I used wordlists for sentiment analysis. It's just an easy lookup + count pos/neg matches. Came to mind it's maybe too simplistic… Currently working on making bar plots to visualize the results/distribution
      * SE: Why do you think it's too simplisitic? Is there some related work that is doing this? Yea, Would be really nice to see some results.
      * JW: Well, many results are exactly zero. These are maybe short poems with unusual wording or just very neutral sentiment. Also the english poems tend to be negative with some poems having a very strong negative rating (-800 or sometimes more) but there is no outlier in positive direction. The german poems seem to be more balanced. I'm sure there are more sophistiacted approches. But on the other hand it actually is sufficient to divide positives from negatives. 
   * added a field "author" to the data and added a filter method
      * SE: nice, also year?
      * JW: Release date was already included (... if available, sometimes it's not included in metadata)
   * added a filter to get sonnets for all poems
   * Talking of bar plots… I created bar plots of time period distribution. Find an example attached to this mail.
      * SE: nice, where can I find them?
      * JW: I attached it to my post... but I'll send it to you on Slack  
   * I'm in contact with Kay Würzner, the creator of Gramophone. The tool is not very easy to use. I installed the requirements (one needed gcc compiling) but it turned out that the code on github is actually made for a web app and currently not working. Though it should be possible to run it on the console or even within python but I couldn't get it done. ALSO I'm not sure how important it is in the end. If we use it for rhyme detection we have another strong tool (~95% accuracy) working. For english we can still use the CMU dict if its about grapheme translation, which is quite often used in other works. If we want to use it for meter detection it may not be overly important as the guys from deepspeare claim that even their vanilla language model recognized meter implicitly.
      * SE: would still be nice if we have G2P for German (CMUdict doesn't do that) as well as stress for both English and German. What does K.Würzner say? Does he have a clue why it does not work?
      * JW: I'll give it another try :) 
   * I also contacted Arthur Jacobs for a word list more suitable for poems. He doesn't
      * SE: doesn't?
      * JW: ... have a list at hand. But we'll work something out maybe. . 
   * To do (maybe tomorrow): - make sentiment plots / probably implement another more sophisticated option for sentiment analysis - push code and files to TU servers
      * SE: Yes, I would like to see the data and apu and run your reader on it, that's doing G2P, syllabification, etc.

---+!! Meeting Minutes 22.11.2018

   * Please try to finish the item points in this week by next week, so we can move on to generation.
   * Also please send me a gitlab link to your PoetryReader and put all the data on apu


   1 - Assign poems a date in corpora
   2-  limericks, .... ; *sentiment* analysis of poems
      * sentiment wortlisten (Arthur Jacobs, see email, other sources for sentiment classification are also possible)
         * https://docs.aylien.com/textapi/sdks/#python-sdk
         * There are many sentiment labeled datasets out there, but not for poetry domain and not for our epochs, presumeably
      * or: sentiment annotated datasets
      * sentiments: humor, negativ, positiv
   3 - filter by author
   4- do we know authors as meta-data?
   5 - G2P: http://kaskade.dwds.de/gramophone/
   6 - Put code on gitlab, put data on apu
   7 - Related work (finish ASAP)
      * Poetry Analysis
      * Poetry Generation
      * (Language Generation)
   8 Language Model
   9 TU Design
   10 Tabelle fehlen
   11 Related work
   12 - Use supervised rhyme detector of Thomas Haider to assign rhymes for poems not rhyme labelled



-- Main.SteffenEger

%META:FILEATTACHMENT{name="RNN_MTL_LM.jpg" attachment="RNN_MTL_LM.jpg" attr="" comment="MTL" date="1550761570" size="2880767" user="eger" version="2"}%
