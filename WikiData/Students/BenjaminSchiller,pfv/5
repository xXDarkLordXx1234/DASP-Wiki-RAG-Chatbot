%META:TOPICINFO{author="hanselowski" comment="reprev" date="1507219595" format="1.1" reprev="5" version="5"}%
%META:TOPICPARENT{name="StudentsList"}%
---++ Meeting 2017-3-7

   * Done must be included in the thesis: 
      * most important sentences (cos-dist claim zu doc/evidence) 5% worse
      * Hierarchisches BiLSTM mit GloVe / eigenen word2vec (Snopes Corpus) 
       testen und falls die Ergebnisse besser sind als mit dem aktuellen Verfahren (also Embeddings initialisieren mit 0's und während dem trainieren des Models mittrainieren) 
      * Hyper-parameter tuning mit dem besten feature, Attention models
      * Daten verdoppelt durch halbieren des Textes der original documents und evidences und Erstellung eines neuen claims daraus
      * Verschiedene Attention models mit bestem Ergebnis aus 1. nochmal laufen lassen (falls keine anderen Tests laufen müssen hier ggf. auch noch tunen)
   
   * TODOs Master Thesis: 
      
      * Error analysis: missclassifieds examples to by analysed, what can be done better to classify them correctly, is there a pattern? 
          * why classification model perform so well, 
          * confusion matrix LSTM based models, classifiers, f1 ist vergleichbar recall precision might be different, analyze all metrics for the two classes not average
          * Confusion matrix: false posi,false neagtive
          * Upper bound annotation 100 Beispiele

      * Daten halbieren und LSTM und Clasifier testen: wenn LSTM noch schlechter sind die wenigen Daten ein Problem

      * Bestes Attention model visualisieren

      * Alle modelle abschließend auf Test-set laufen lassen

      * Die restlichen besten Methoden aus der FNC einbauen für das MLP, Logistic Regression etc.

      * BiLSTMs mit CNNs tauschen, damit wir auch CNNs getestet haben

      * Eine 3. Klasse "others" einbauen
      
      * Document level LSTM

      * Mehr Beispiele generieren, Beispiele mit vielen Dokumenten aufsplitten




   *  TODOs Paper: 
      * zweiter corpus
      * vergelich zu anderen methode CRF
      * related work gegenüber stellen
      * Memory Network Michael
      * Information of the domain
   



-- Main.AndreasHanselowski - 2017-02-27

-- Main.AndreasHanselowski - 2017-05-15