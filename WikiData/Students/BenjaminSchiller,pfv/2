%META:TOPICINFO{author="hanselowski" comment="reprev" date="1506084018" format="1.1" reprev="2" version="2"}%
%META:TOPICPARENT{name="StudentsList"}%
---++ Meeting 2017-3-7

   * Done: 
      * 
      
   * TODOs Master Thesis: 
      * Hierarchisches BiLSTM mit GloVe / eigenen word2vec (Snopes Corpus) / most important sentences (cos-dist claim zu doc/evidence) testen und falls die Ergebnisse besser sind als mit dem aktuellen Verfahren ( also Embeddings initialisieren mit 0's und während dem trainieren des Models mittrainieren) hyper-parameter tuning mit dem besten feature

      * Verschiedene Attention models mit bestem Ergebnis aus 1. nochmal laufen lassen (falls keine anderen Tests laufen müssen hier ggf. auch noch tunen)

      * Bestes Attention model visualisieren

      * Alle modelle abschließend auf Test-set laufen lassen

      * Extension of the corpus for examples with many documents

      * Die restlichen besten Methoden aus der FNC einbauen für das MLP, Logistic Regression etc.

      * BiLSTMs mit CNNs tauschen, damit wir auch CNNs getestet haben

      * Eine 3. Klasse "others" einbauen

   *  TODOs: 
      * error analysis
      * zweiter corpus
      * vergelich zu anderen methode CRF
      * related work gegenüber stellen
      * Memory Netorrk Michael
      * Information of the domain
   



-- Main.AndreasHanselowski - 2017-02-27

-- Main.AndreasHanselowski - 2017-05-15