%META:TOPICINFO{author="hussain" comment="save topic" date="1468410015" format="1.1" reprev="20" version="24"}%
%META:TOPICPARENT{name="StudentsList"}%
---++ 14 July 2016

---++++ Meeting Agenda
 I have worked on following tasks from last meeting.

   * Support of multivalve parameters 
A multi value parameters are displayed repeatable inputs to the user.
   * User input encoding 
Galaxy manages encoding and decoding of user input. I have tested it.
   * Refactoring of Spark Job
based on your feedback, I have removed the boilerplate code. Now spark job is quite simple, and it relies on runtime values to generate the UIMA components. https://github.com/tahirhn/dkpro-core-galaxy/blob/master/src/main/scripts/groovy/templates/sparkjob.groovy
   * Besides, I have refactored existing code to avoid repetition of code.

  As Spark and Hadoop are not accessible on university servers, I am still not finished running the code as spark job, Once hadoop and spark are accessible I will start working on it. Please note that only spark execution is left, all other component like converting the workflow into spark job, redirecting to spark from galaxy and reading and writing to hdfs are done.

    Please note that due to ongoing work with coding, I cannot submit the thesis document on 18th, I will submit you initial draft for review on 26th July. I will however send you the presentation slides by 19th July.

   I am including following workflow system for review in thesis document.

   * Apache Galaxy
   * Apache Taverna
   * Pegasus
   * Kepler
   * TextFlows
   * Triana

Latest code is available at https://github.com/tahirhn/dkpro-core-galaxy

Please note that I am aware of following issues in my code, that I intend to work on later.
   * Code is not documented
   * String is used instead of StringBuilder


---++ 05 July 2016

---++++ Meeting Agenda
   * Presenting work done so far. 
   * Discussing Thesis deliverables.


---++++ Deliverables
   * visualisation support in Galaxy (complete).
   * Custom file format to accomodate file on hadoop. (complete)
   * galaxy with Spark (80% complete).


<hr>
---++ 23 June 2016


---++++ Meeting Agenda
   * Scalable Workflows 

<hr>


---++ 14 June 2016


---++++ Deliverables
   * visualisation support in Galaxy (working on it).
   * galaxy with Spark (moved to post presentation). 

<hr>

---++ 31 May 2016
---++++ Meeting Agenda
   * Please provide DKPro Core code examples (to test them as workflow)
   * Are tagsets relevant to me?
      * REC: No. You should touch on the topic if formats in your report: the format is always XMI in our case, but not any order of components makes sense (even if we ignore tagsets and just consider inputs/outputs). E.g. component A outputs X and Y, it connects to component B which has as input X, B then connects to C which has as input Y. This would be in the pipeline. All inputs are fulfilled. But if we connect B to D and D requires Z as input, that would not work. Do you see any way to help the user here?
   * Once Spark implementation is complete, how would I test it? Would I be provided Spark cluster or something?
      * REC: please write mail to system-admin@ukp as discussed 
   * Scaling Strategy (HDFS)
   * As part of evaluation, what factors should I measure for galaxy and spark workflows.
   * Could it be the case than two or more readers or components be merged in a writer at once?
      * REC: In principle yes, but if we implement the pipeline execution as we had discussed it, this may be slightly difficult to handle. If you see a solution: good. If not, please discuss it in your report and try pointing out solutions. 
   * What are available languages for Readers and Writers? 
      * REC: language usually set as a parameter on readers, writers do usually not care 
   * Mid presentation date, 21st June.

---++++ Deliverables
   * Working implementation of DK Pro Core Workflow in galaxy.
   * possibly with Spark (need more time). 

<hr>
---++ 09 May 2016
---++++ Meeting Agenda
   *  Discussion and feedback on how to integrate spark.  

<hr>
---++ 28 April 2016
---++++ Meeting Agenda
   *  How to extend Demo implementation.
   *  Starting points for generating tool descriptions
      * https://github.com/dkpro/dkpro-core/blob/master/dkpro-core-doc/src/main/script/generateDocumentation.groovy
      * https://github.com/openminted/interoperability-mapping-conversion/blob/master/src/main/groovy/eu/openminted/interop/componentoverview/ComponentsMain.groovy 
   * Starting point for Spark-based execution backend for Galaxy: https://github.com/galaxyproject/pulsar

---++++ Deliverables
   * A demo of DKPro Core with Galaxy and Spark .


<hr>

---++ 14 April 2016
---++++ Meeting Agenda
   * Feedback on Workflow systems
   * Use of Hadoop/Spark with DKPro Core. 
   * Batch input for Workflow. 

---++++ Deliverables
   * Requirements, Overview and comparison of workflow editors [<u>Need more time</u>]

---++++ Tasks
   * Integrate DKPro Core, Galaxy and Spark for demo. 

<hr>

---++ 31st March 2016
---++++ Meeting Agenda
   * Thesis Registration
   * Following questions needs to be discussed related to DKPro Core
      1 Why Resource and Component are distributed separately in maven repository. Relationship between components and resources.
      2 Classification of components, can one be substituted for another.
      3 For workflow should I assume certain predefined components or it should be generic. How components can be listed.
      4 Order in a certain workflow is always sequential or it can be customised i.e branches etc.
      5 Scope of UIMA in workflow editor, i.e workflow will be generalised to UIMA pipeline or DK Pro Core Components.
      6 In Some of the example, some parts of UIMA pipeline were provided by user, i.e final Writer component. Does it mean user can import custom components in workflow.
      7 Workflow should be defined as UIMA compatible xml format, or some other way
   * Some references from today
      * Groovy-based scripts with DKPro Core - https://dkpro.github.io/dkpro-core/groovy/recipes/
      * DKPro Script - still simpler scripting for DKPro Core - https://dkpro.github.io/dkpro-script/
      * Auto-generated DKPro Core documentation: https://github.com/dkpro/dkpro-core/tree/master/dkpro-core-doc
---++++ Issues
   * Jabber account not working
---++++ Tasks
   *  Requirements, Overview and comparison of workflow editors

<hr>

---++  Meeting on 17 March 2016

---++++ Tasks
   * _Done_ - Brief overview of thesis and tasks to perform
   * _Initial draft submitted_ - List of features/requirements for workflow editor

<hr>

[[%ATTACHURLPATH%/TaskDescription.pdf][Thesis description]]

%META:FILEATTACHMENT{name="TaskDescription.pdf" attachment="TaskDescription.pdf" attr="" comment="" date="1459370768" size="334515" user="hussain" version="1"}%
%META:PREFERENCE{name="TOPICTITLE" title="TOPICTITLE" type="Local" value="Tahir Hussain"}%
