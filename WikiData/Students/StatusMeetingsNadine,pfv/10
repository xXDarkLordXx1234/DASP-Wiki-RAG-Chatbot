%META:TOPICINFO{author="NadineTrueschler" date="1314612225" format="1.1" reprev="10" version="10"}%
%META:TOPICPARENT{name="NadineTrueschler"}%
---+ Meetings

---++ 31.05.

   * Vorstellung und Besprechung der Bachelorarbeit, Aufbau, Aufgaben etc.

   * Verträge erhalten

---++ 08.06.

   * Abgabe der unterschriebenen Verträge

   * Klärung von Fragen

---++ 10.06.

   * Einrichten von Maven sowie kleine Einführung

   * Anschließend ML-Workshop von 10:30 bis 15:30 Uhr

---++ 05.07.
   * Besprechung für die erste Aufgabe (Corpus Creation)
   * Über Datenbank arbeiten (Pipeline)
   * Ein Corpus mit FA und GA, dazu einer mit NA
   * EIn Corpus nur mit FA, dazu einer mit NA
   * Wkipedia-Pages sollten ungefähr alle gleich lang/groß sein, wird anhand der Länge des Strings gemessen

---++ 11.07.
   * Problem bezüglich WikipediaArticleReader gelöst
   * weiteres Vorhaben besprochen (ID u. Länge in zwei verschiedene txt-Dateien speichern, weiteren Consumer wie StatWriter anlegen, der die beiden Textdateien weiter verarbeitet (initialize, hasNext, getNext - zwei Listen, eine abarbeiten, in der anderen durch Rauswerfen überprüfen, ob alle Artikel "Partner" fanden))

---++ 19.07.
   * Klassen lesen gerade Featured und Good Articles aus (FAoutput.txt und FAGAoutput.txt), darauf basierend werden dann FAGANAoutput.txt und FANAoutput.txt erstellt, also non-featured und non-good sowie nur non-featured articles
   * weitere Aufgabe: Pipeline mit Reader bauen, der diese WikiDaten ausliest. Neuer Reader (SelectedArticleReader) extens WikipediaArticleReader. Es ist das zu überschreiben, das den Iterator definiert. D.h. es ist ein eigener Iterator zu implementieren, der über die eigene Liste iteriert. Zu verändern: getNext() und initialize(). Um das Ganze zu testen, werden in die Pipeline Ausgaben eingebaut.

---++ 22.07.
   * SelectedArticleReader gezeigt
   * Als nächstes mit DKPro-Komponenten arbeiten, Features betrachten, also Statistiken (auch Revisionen von Artikeln anschauen), Readabilitymeasures sind wichtig -> scores, wie lesbar ein Artikel ist.

---++ 03.08.
   * Als nächstes Folgendes: 
   * Segmenter, der Tokens liefert
   * Tretagger für Nomen
   * für FirstParagraph gesondert StanfordParser verwenden

---++ 11.08.
   * Statistiken besprochen
   * Für Contributors bei Revisionenbetrachtung Name statt Id
   * neben Nouns auch Adjectives und Verbs betrachten

---++ 12.08.
   * Rechner im UKP-Pool konfiguriert (Maven)
   * RevisionoutputFAGANA.csv wird nun ausgegeben, Samstag, den 13.08. um 14:46 Uhr erst 921 von knapp 15000 Ausgaben

---++ 17.08.
   * RevisionStatistics-Änderung/-Verbesserung besprochen (zu lange Laufzeit gehabt)
   * Diagramme für Statistikauswertung besprochen

---++ 23.08.
   * Statistiken/Diagrammaufbau besprochen
   * als nächstes Diagramme auswerten, um Features zu definieren
   * im Anschluss Zwischenpräsentation gehabt

---++ 29.08.
   * Statistik-/Diagrammauswertung kurz besprochen
   * daraus gravierende Unterschiede raussuchen
   * als nächstes arff-Dateien erstellen, mit n-Grammen
   * Struktur der schriftlichen Ausarbeitung besprochen