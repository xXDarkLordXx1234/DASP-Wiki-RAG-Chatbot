%META:TOPICINFO{author="roehrig" comment="save topic" date="1370265072" format="1.1" reprev="2" version="6"}%
%META:TOPICPARENT{name="RouvenRoehrig"}%
---+!! Minutes
---++++ Master Thesis of Rouven Roehrig

This page contains the minutes of the weekly meetings.

---++ 04 June 2013
*Attendees*: tz, rr
   * *Improve proper noun extraction*
      1 Improve (clean) chunks:
         * Remove determiners (a, an, the) when they are the first or last token of a chunk
         * -> Reason: duplicate occurrences like "the CentraSite Administrator" and "CentraSite Administrator" will be merged.
         * Remove single numbers ("0" and "1" were detected as noun phrases)
         * Remove unigrams with word size < 2 or non-alphabetic words (will remove noise like "{" or "'")
         * Try to generate foreground corpus with lowercase only (Web1TFormatWriter has such an option)
      2 Improve filtering/selecting
         * Different threshold for uni-, bi- and trigrams
         * *With respect to the corpus size (normalize!)*
      3 You can try another algorithm:
         * e.g. the Algo described in "A Language Model Approach to Keyphrase Extraction" (Tomokiyo and Hurst, 2003)
      4 Reduce segmentation errors produced by java parameters ("{0}" and "{1}")
         * This can be done my introducing views (because a Cas cannot be changed!)
         * BUT, this seems to be an individual problem -> Don't invest in views1!
            * Simple solution: Replace them in a preprocessing step, e.g. "{0}" -> PARAM0
               * Afterwards, the can be mapped back (if necessary)
   * *Sentence probabilities* (just for fun):
      * You can calculate the sentence probabilities using the trigrams

---++ 27 May 2013
*Attendees*: lb, tz, rr
   * *Representation of anomaly in the GUI*
      * Anomalies may be displayed in the proposal list!?
   * *Accessing deployed resource (jars)*
      * Most components can accessed the resource folder (some cannot)
      * Best practice: Use DKPRO_HOME!
   * *Noun phrases*
      * How: TreeTaggerChunker
         * Pipeline requires: segmenter, pos tagger and chunker
      * Then FreqDist (*.api.frequency package)
         * Then play around the parameters and filter, e.g.:
            * Only chunks of length < n (n = tbd)
            * Only chunks that occur x times (x = tbd)
      * Generate glossary:
         * Check out Log-Likelyhood (LL) (c.f. FoLT homework 6)
         * Background corpus: tz will provide web1t Wikipedia (EN)
         * Foreground corpus: has to be generated by rr
   * How to use the noun phrases?
      * Improve clusters: e.g. replace product names (e.g. "MyWebServer" -> <PRODUCT>)
      * Improve proposals (use glossary as a dictionary)
      * Correction of existing error using the glossary

---++ 21 May 2013
*Attendees*: (lb), tz, rr

* Cluster selection
   * Durchschnittliche Ähnlichkeit zu allen Sätzen im Cluster
   * 'Base sentence' ist eher zufällig als ausschlaggebend

* Proposal selection
   * Statt dem häufigsten Satz in einem Cluster, den ähnlichsten Satz zu allen anderen
   * Centroid selection
      * Ebenfalls der ähnlichste zu allen anderen

* Clustering
   * 1. Gleiche Cluster zusammenfassen (gleich oder fast gleiche müssen eliminiert werden)
   * 2. Clustering-Algo verbessern
	z.B. 'jeder Satz geht in genau einem Cluster (wenn ähnlich genug) oder bildet einen neuen'

---++ 06 May 2013
*Attendees*: lb, tz, rr

* *System-Design*
   * Zwei Modi scheinen sinnvoll zu sein:
      1 Satz überprüfen, ggf. Vorschläge machen
      2 Allen Sätze finden und präsentieren, die eine Anomalie aufweisen
         * (unter der Annahme, dass die existierenden Sätze immer noch Fehler/Abweichen enthalten könnten)

* *Daten-Analyse*
   * Wie sehen die Cluster aus?
   * Was verändert sich?
   * Welcher Satz fällt in welchen Fall?
   * -> Analyse z.B. durch Clustering innerhalb der Cluster

---++ 29 Apr 2013
*Attendees*: lb, tz, rr

*<u>Sequence and component diagrams</u>*
   1 Rename "Dictionary" -> "General dictionary"
   2 Rename "Proper nouns" -> "Glossar" (or similar)
   3 Rename "Frame" if possible because it's ambiguous in NLP
   4 "Good phrases" -> Man könnte sich unterschiedliche qualitative Level vorstellen (muss man aber nicht)

*<u>Similarity</u>*
   * Try to reproduce and create issue with example in tracker

*<u>Clustering</u>*
   * Vorsicht mit absoluten Zahl!
   * Unbedingt das [[RouvenRoehrigSentenceClusteringGoodExample][gute Beispiel]] aufheben!
   * Spelling checker: Erkennen ist eine Sache, die richtige Korrektur eine andere.
     Durch die Standard-Phrasen ist die richtige Korrektur (mit hoher Wahrscheinlichkeit) schon gegeben.

*<u>Anomaly classification</u>*
   * Fehler in Kategorien einteilen, z.B.:
      1 Words added
      2 Words removed
      3 Words changed
   * Kategorien in Unter-Kategorien einteilen, z.B.:
      * Words changed:
         1 'Simple' spelling error
         2 Word exchanged (e.g. with a synonym or RWSE)

*<u>Verbesserung der Testdaten</u>*
   * Idee: Wenn das System steht, kann es (gemeinsam mit den Experten) gegen sich selbst getestet werden, um die existierenden Daten zu verbessern.

*<u>TODOs</u>*
   * Konkrete (kleine) Schritte definieren
   * Algorithmen weiter entwickeln
      * Wichtig: Aufgaben trennen und dann auch hier genaue Schritte definieren!
      * z.B. 1. Clustering: Reicht der aktuelle Ansatz bereits aus oder ist es so wichtig, so dass hier mehr Zeit investiert werden muss
   * Minimal-System bauen
      * In der Regel lohnt sich eine gesunde Mischung aus top-down und bottom-up Ansätzen.

---++ 22 Apr 2013
*Attendees*: lb, tz, rr

*<u>Task Description</u>*
   1 Motivation und abstract zusammenfügen.
   2 Goals ergänzen, insbesondere konkrete Ansätze nennen.
   3 Die Ziel-Definition und die Idee der Fallunterscheidung für Phrasen ist gut. Erwähne dies auch in der Task Description.
   4 Schicke uns dann die Task Description zu

*<u>Zieldefinition</u>*
   1 Was soll bei der Interaktion (user - system) genau passieren?
   2 Wann soll der Interaktionsprozess beginnen? D.h. ob die Texte schon vorliegen oder ob sie gerade geschrieben werden?
   3 Ist der Reviewer system-relevant? D.h. sind die korrekten Daten fix gegeben oder verändern sie sich (z.B. durch den Reviewer)? 
     Das muss genau definiert werden!
   4 Definiere Eingaben und Ausgaben (das System ist hier noch eine Black-Box).
   5 Erstelle ein Diagramm, der den Ablauf modelliert und formalisiert.
   6 Wenn Diagramm steht, versuche Use Cases durchzuspielen, ob das Diagramm plausibel ist oder ob noch etwas fehlt.

---++ 16 Apr 2013
*Attendees*: lb, tz, rr

*<u>Task Description</u>*
   1 Arbeitstitel
	   * Geht im Grunde in die richtige Richtung.
   2 Fokus der Task Description
	   * Viel zu viel!
	   * Versuche höchsten deine "abstraction" und "problem description" in die aktuellen task description einzubauen.
   3 Format der Quellenangabe
	   * siehe latex-Vorlage


*<u>Related work</u>*

Du kannst dir z.B. folgende Gebiete anschauen, die in eine ähnlich Richtung gehen:
   * translation memory
      * Das ist nicht dasselbe, ABER die Matching-Alorithmen könnten ähnlich sein
   * near duplicate detection
      * Auch nicht dasselbe
      * Versuchen häufig durch z.b. fingerprint schnelle Ergebnisse zu liefern, um große Datenmengen behandeln zu können

   * *Def. Paraphrase*: zwei Phrasen sind Paraphrasen gdw. die gleiche Bedeutung haben
      * Im Gegensatz zu translation memory-Algorithmen, bei denen hohe Übereinstimmungen auch gut sind, selbst wenn es eine gegenteilige Bedeutung hat.
         * z.B. "This is valid" und "This is invalid"

*<u>Abgrenzung</u>*:
   * Was sind speziellen Anforderungen in meiner Arbeit?
   * Das muss genau definiert werden!

*<u>Clustering verbessern</u>*:
   * Zunächst herausfinden, was einfache Algorithmen für das Problem leisten können
   * Dann schauen, was noch fehlt und wo investiert werden muss
      * z.B. über Synonyme

*<u>Zieldefinition</u>*:
   1 Welche Art der Hilfe möchte ich geben?
   2 Was fehlt noch?

---++ 04 Apr 2013
*Attendees*: lb, tz, rr
   * Transponder is set up for A326 (D017 should be activated too)
   * New meeting date: *Mo. 11 am*
   * DKPro: Hint: Every AnalysisComponent implements collectionProcessComplete
   * Error message analysis:
      * rr: Data analysis: I've used DKPro to generate statistics (word and sentence diversity) and paired sentences based on an edit distance (Levenshtein) below 10.
      * tz: Paired sentences (that rr generated) are soft clusters
      * Try to find better clusters using (for instance): EditDistance on words, NGramOverlap or similar measures
      * Plagiarism detection is similar: Read papers about plagiarism detection!

---++ 28 Mar 2013
*Attendees*: lb, rr
   * lb: There are three construction sites: DKPro (programming), literature work and data analysis
      * You should focus on literature work and data analysis first
   * lb: Summarize your literature work
   * lb: Do some data analysis, e.g. lexical diversity, 'how many times occurs the same sentence?' etc.
   * lb: Check out the similarity package (can be used without DKPro)

-- Main.RouvenRoehrig - 12 Apr 2013