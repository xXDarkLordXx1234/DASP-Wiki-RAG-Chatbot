%META:TOPICINFO{author="MateuszParzonka" date="1285371882" format="1.1" reprev="5" version="5"}%
%META:TOPICPARENT{name="MateuszParzonka"}%
%TOC%

---++++++ 24 Sep 2010
First baselines for "pure" candidate extraction (all micro):
   * NGrams:  P=0.14 R=81.5 F=0.02    
      * Slightly worser recall. But we have a ten-times higher precision then C&M do. Maybe to strong filtering on our side.
   * NChunks: P=1.71 R=55.3 F=3.32    
      * C&M use NP-Chunks, we use N-Chunks. So we have different (and worse) results.
   * NERHeur: P=13.11 R=47.37 F=20.54
      * Our heuristic seems to be better then C&M. They have an f-measure of 18.08
 
---++++++ 23 Sep 2010
Heavy refactoring. Decided to separate the concerns of creating index entries and evaluation them into ExtractionPipelines and a EvaluationPipelines.

---++++++ 22 Sep 2010
Extracted the "unproblematic" subset from the main data set following Csomai & Mihalcea.

---++++++ 21 Sep 2010
Processing and evaluation of collections is working.

---++++++ 18 Sep 2010
Wrote PRF-Evaluator for back-of-the-book-indexing using gold index entries.

---++++++ 17 Sep 2010
Pipelines are now jUnit-testable.

---++++++ 15 Sep 2010
Wrote base pipeline for testing and experiments.

---++++++ 13 Sep 2010
Split initial jCas into segments with demultiplier and applied a simplified LexRank to the sub-CASes. Wrote a AnnotationPrinter to visualize the results.

---++++++ 12 Sep 2010
Played around with LexSemRank, seems to be quite slow. Using the  3,2GB "wikipedia_lemma_en" esa cached index.

---++++++ 10 Sep 2010

Played around with TextRank.

---++++++ 09 Sep 2010

Research about State-Of-The-Art Keyphrase Extraction. 

---++++++ 08 Sep 2010

Checked in project.