%META:TOPICINFO{author="NiklasJakob" date="1175356547" format="1.1" version="2"}%
%META:TOPICPARENT{name="NiklasPaperSummaries"}%
---++ Summary of: "Comparing Lexical Chain-based Summarisation Approaches Using an Extrinsic Evaluation"

   * A new method of building extractive summaries of documents using lexical chains is presented. Contrary to other attempts they evaluate their weighting and extraction schemes using an extrinsic or task-based evaluation technique. It is based on the TDT story-link detection task [See Allan J. 02 "Introduction to Topic Detection and Tracking"] where the quality of a document sumarisation is evaluated with respect to how well a story link detection system can determine if a pair of document summaries are similar or dissimilar.
   * The lexical chaining algorithm uses WordNet as a knowledge source and groups the semantic relations in the categories "extra-strong" (term repetitions), "strong" (synonyms, shared hyponyms/holonyms, meronym/holonym) and "medium-strong" (the link between the synsets of the words is longer than one).
   * Their algorithm uses a greedy lexical chaining approach, which means that a word's sense is determined only by the senses of words that occur before it in the text. It assigns POS tags to the input document and works with nouns, compound nouns and proper nouns. Unlinke previous chaining approaches, their algorithm creates two disjoint sets of chains: noun chains and proper noun chains. They believe that finding relations between proper nouns is essential for modelling the topical content of any news story. Another new feature is that their algorithm takes repetitions of works in consideration when calculating the chain score. The chain score is the sum of each score assigned to each word pair in the chain. Each word pair's score is calculated as the sum of the repetitions of both words multiplied by the relationship score between them.
   * The relationship scores for the nouns are defined as: synonymy - 0.9, hyponymy/hyperonymy - 0.7
   * The relationship scores for the proper nouns are defined as: exact match - 1.0, partial match - 0.8, fuzzy match - 0.7
   * Since they want to identify whole sentences which summarise the given text, a score is calculated for each word of the sentence and those scores are then summed up. A word's score is a scaled version of its chain's score whereas the scaling factor is the minimum distance between a word and its predecessor or successor in the chain. The idea is that general topics span large section of a document whereas subtopics tend to populate smaller parts. Therefore they increase the score of a word if semantically related words are close by. Finally the sentence score is normalized by its length and the number of chain words it contains.
   * In the evaluation process they make use of the Story Link Detection Task by the TDT research initiative. This tool has to judge whether a text and its summary are rated as on-topic / similar or off-topic / dissimilar. The idea behind that evaluation is that if the SLD system will perform well on summaries which have retained the original document's core message and perform poorly on summaries which failed to recognize the the central theme of the original document.
   * Furthermore they compare their algorithm called LexSum to: a slightly modified Barzilay&Elhadad implementation, a RANDOM algorithm which just selects random sentences as summaries, a LEAD implementation which just extracts summaries from the lead paragraph of the document and a TF-IDF implementation. A graph has been created visualising the false alarms and the misses of all implementations running at a 50% summary compression rate. As expected the RANDOM implementation has the worst performance, followed by the LEAD implementation. The Barzilay&Elhadad implementation generated the best results, slightly outperforming the authors' LexSum algorithm. Both those lexical chain based algorithms perform siginificantly better than the TF-IDF approach.
   * Finally the authors sum up that lexical chain based summarisation systems generally perform better than LEAD or TF-IFS based systems, which justifies the additionaly required computation. Since the results of their LexSum system and the Barzilay&Elhadad implementation are pretty similar, the authors conclude that the effect of the weighting schemes has only little effect on the summaries. They are content with the performance of their evaluation method since it was sensitive enough to show significant differences between the different systems. As future development the authors state their interest in carrying out an intrinsic evaluation of the summarisation systems and compare those results to the automated evaluation presented in this paper.