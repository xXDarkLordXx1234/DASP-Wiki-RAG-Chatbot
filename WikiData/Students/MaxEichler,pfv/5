%META:TOPICINFO{author="meichler" comment="" date="1554307763" format="1.1" reprev="1" version="5"}%
%META:TOPICPARENT{name="StudentsList"}%
---+!! Bachelor Thesis: Developing an Inspector for Multilingual Word Representations

*Start date:* 2019-02-06

*Supervisor:* Dr. Gözde Gül Şahin

---++ 2019-04-03

   * AllenNLP archive_model only saves the final model
      * The parameter files_to_archive allows to supply a dictionary of additional files
      * This raises file size and execution time substantially
      * To get and analyze all epochs custom code by the user or submission of a manual zipped archive would be required which is more error-prone
      * See [[https://github.com/maexe/linspector-proposal/blob/master/get_representation.py]]
      * Once all metrics_epoch_x.json and model_state_epoch_x.th files are available it would be easy to select e.g. 3 epochs with the biggest jump in accuracy by looking at the metric files
   * A Django application with Apache and mod_wsgi is up and running
      * [[http://linspector.ukp.informatik.tu-darmstadt.de/static/hello.html]] (reachable from within the UKP network)
      * Documented server setup [[https://github.com/maexe/linspector-proposal/blob/master/docs/django.md]]
   * Started experiments for Portuguese, UD, fastText to understand LINSPECTOR

---++ 2019-03-28

   * Found a way to get all modules of a model so the user can select one for probing
   * Looked at different language candidates
   * As suggested Arabic (9), Armenia (9), Czech (5), French (7), Hungarian (8), and Portuguese (8) seem to be the best candidates (# of probing tests in brackets)
      * Only French and Portuguese share a family so one of these could be eliminated
      * Except for Hungarian all candidates are fusional languages
         * With Finnish and Turkish the most reasonable agglutinative candidates were already tested
         * Quechuan languages are also agglutinative and provide a high coverage of probing tasks but are low resource (only fastText and no Wikipedia)
      * Did not find pre-trained embeddings for all candidates (except fastText) but all have 100,000+ Wikipedia articles
      * All candidates have POS, DEP, NER and other corpora + Arabic and Czech have SNL

---++ Meeting 2019-03-19

   * Decided on PyTorch hooks to get representations
   * Find a way to select all given layers from a model
   * Start with a linear classifier, try decision trees later on for probing tasks
      * Check the model config and lowercase tokens if they aren’t already
      * Dynamically adjust the model config based on embedding size
   * Analyse automatically which epochs should be probed (like up to 3 in total)
   * Think about how to visualize results without doing downstream tasks (too expensive)
   * Think about alternatives for UI, parameters, and visualization so we can provide options to researchers in a minor UI study
   * Think about and document how others could extend the project to sentence embeddings in the future
   * Build a framework to run experiments
      * More details in a future email form Gözde
   * Server access to barney and krusty was granted

---++ 2019-03-18

   * Finished PyTorch tutorials as discussed
   * Looked at AllenNLP dataset readers and how to implement a custom reader
      * Seems fairly easy, basically applying a combination of string operations
      * A reader is used to create a vocabulary which is fed as a default param to each model
   * Found PyTorch hooks to get the representation input and output of a torch.nn.Module which seems like a elegant solution to probe individual layers
      * Build a demo based on AllenNLP SimpleTagger for POS and intrinsic vocabulary
      * See [[https://github.com/maexe/linspector-proposal/blob/master/get_representation.py]]

---++ Meeting 2019-03-11

   * Discussed and decided on AllenNLP as an implementation basis based on tech demo
   * Overview of existing code, how probing is currently implemented, and how a future implementation should look
   * Decided on early May for midterm, and early to mid June for final presentation
   * Tasks:
      * Find out how AllenNLP reads files
      * Convert vocabulary in 2-3 file formats
      * Make AllenNLP SimpleTagger work for German and Case
      * Use [[https://github.com/gozdesahin/dataset_compilation/blob/master/data_util/get_intrinsic_vocab.py]] to write a file and check how simple tagger reads this
      * Get encoding from AllenNLP seq2seq encoder from this model
      * Go through "Deep Learning for NLP with Pytorch" first 4 tutorials [[https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html]]

---++ 2019-02-26

   * Got to know the basics of the AllenNLP framework
   * Tested the possibility of extending AllenNLP models with additional parameters (=probing_layer=, =lang=)
   * Engineered a small tech demo and drew a flow chart with a potential solution ([[https://github.com/maexe/linspector-proposal]])
   * I will have to look further into probing and how to handle static embeddings

---++ Meeting 2019-02-20

   * Discussed thesis discription and timeline
   * Overview of AllenNLP
   * Tasks:
      * Setup working environment ([[https://github.com/allenai/allennlp]], [[http://github.com/gozdesahin/dataset_compilation]])
      * Decide whether to use AllenNLP or own interface
      * Is AllenNLP extendable?
      * Provide an abstract idea whether AllenNLP is feasible for WP1

---++ 2019-02-20

   * Scanned and read papers from Google Scholar, RepEval, RepL4NLP, and ICLR
   * Added some of them to Mendeley with a summary
   * Yaghoobzadeh et al. (2018) and Bacon and Regier (2018) had some (possibly) interesting ideas for tasks
   * Put Zhang and Bowman (2019) and Ettinger et al. (2016) on my reading list
   * Found that I should read up on ELMo and AllenNLP

---++ Meeting 2019-02-06

   * Finished paperwork
   * Discussed papers
   * Got first overview of project and datasets
   * Tasks: Read and gather additional papers

---++ 2019-02-06

   * Read all the stared papers in Mendeley, added summaries to each
   * Had no real issues reading them except for having to look up some linguistic words
   * Most interesting papers to me where Köhn (2016) and Burlot et al. (2018) for their multi lingual approaches + Conneau et al. (2018) as an introduction to probing tasks
   * I did not found Tsvetkov et al. (2015) that useful
   * Currently looking at Köhn (2015) and Burlot and Yvon (2017) for additional multilingual evaluation systems

---++ Meeting 2019-01-23

   * Finalized web server requirements
   * Project will be open source on GitHub
   * Discussed paperwork
   * Tips on how to find good papers (overview of search engines, workshops, conferences)
   * Tasks:
      * Read papers in Mendeley and add a note “which dataset", "which language(s)", "which evaluation method(s)", and "conclusion"
      * Search additional relevant papers
      * Think about advanced probing tests
      * Print and sign paperwork

---++ Meeting 2019-01-17

   * Organization of thesis at UKP Lab
   * Introduced to topic
      * Word embeddings
      * Evaluation methods
      * Probing tests
      * Potential definition of work packages
   * Tasks: Gather requirements for web server

-- Main.MaxEichler - 2019-03-11
