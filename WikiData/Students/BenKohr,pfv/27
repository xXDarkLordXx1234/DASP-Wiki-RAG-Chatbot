%META:TOPICINFO{author="kuznetsov" comment="reprev" date="1494497239" format="1.1" reprev="27" version="27"}%
%META:TOPICPARENT{name="StudentsList"}%
---+!! Ben Kohr (Bachelor thesis)

---++ Links
   * Repo: https://git.ukp.informatik.tu-darmstadt.de/kuznetsov/BenKohr_BA_SRI
   * Overleaf: https://www.overleaf.com/9080638sxrmhsvkghzv


---++ Things done (this week, 04.05 - 11.05.)
   * Words now only are nolinks, if they have the same sentence id and verb id
   * Added NO_LINK constant
   * Treated NO_LINK as special value for CW (Biemann): Now, Integer.MIN_VALUE indicates these NO_LINKs. They are less frequently taken chosen as voted class.
   * Treated NO_LINK as special value for CW (Lang/Lapata): In addition to CW (Biemann), if one node is only connected to NO_LINK-distant nodes, it must not vote.
   * Treated NO_LINK as special value for KMEANS: NO_LINK nodes have Integer.MAX_VALUE distance in that case. This probably does not make a huge difference, as all nodes are jus compared to the cluster center nodes and just in very few cases there is such a distance occurence, but it still takes the knowledge into account.
   * Treated NO_LINK as special value for COP-KMEANS: NO_LINKs between Arguments result in cannotLink-Elements, before clustering is done.
   (For DBSCAN, in my opinion there is no "good" way to (intuitively) add the information of NO_LINKs)
   * Added stop criterions to reduce number of iterations significantly for CW (Bieman, L&L): Number of changes / change wishes of nodes determine level of change; low level of changes results in a stop of the algorithm.
   * Added stop criterions to reduce number of iterations significantly for ClassicKMeans and CopKMeans: differences between old and new centroids is determined and may result in a stop, if they are similar.
   * Added usage of child node if node is a preposition (configurable for the reader)
   * Better communication between the reader, the clustering algorithms (on one side) and the Evaluation (on the other side). The specialities of the reader (verbs with no arguments), DBSCAN (Ourliers) and COPKMeans (Unable to construct clusters) caused problems during evalutaion which are (hopefully) solved now.
   * I edited the Pipeline class for supporting several individual pipeline runs. One of the next steps will be refactoring the Pipeline as due to adding aspect after aspect to it, it's pretty complex now and configuration management is not easy anymore. I still hope these results are correctly configured and determined by the system: In [[%ATTACHURL%/Results.zip][this]] ZIP archive I inserted the output for the whole CoNLL (all CoNLL files in one single file) with all five algorithms (Chinese Whispers original, CW Lang/Lapata, DBSCAN, KMeans, COPKMeans) with configurations as in the current Pipeline.java file on the original lemma usage ("...original lemma..." in the file name) and the next lemma usage ("...next lemma..."). The output contains the processing steps, the time and the evaluation metrics. I also ran the program to determine the clustering results for single verbs (those in the Lang/Lapata paper). As mentioned, I will improve the Pipeline class in terms of readability and efficency as soon as I have the time for it.
   * I made a new processing core of the project which is (in my optinion and, and, if written correctly) much more understandable and flexible. Next step is to make it faster. Currently, e.g. the single verbs are clustered individually while their results could be stored during the clustering of all verbs and used later on. Some results of the "new" Pipeline are collected here and they seem to be as in the "original" pipeline (but with some randomness aspects, due to the algorithms): [[%ATTACHURL%/Result2.zip][These are the results.]]
 

---+++ Questions BK (this week, 04.05 - 11.05.)
   * Currently, I just take the "IN" prepositions to switch to the child node. Should I use others, too, for example the "TO" POS tag?
      * IK: Well I would do the "TO" too, but see if it's easy or not. If not, drop it for now.

---+++ Notes IK:
   * So can the no-link'ed elements get merged in COP-KMEANS / KMEANS?
   * Let's go through all parameters again
   * Randomness - fix the seed!
   * Lemma comparison - lowercase?..
   * Result2.xip - add clustered arguments?
   * Print full argument signature (all the features you use to get the distance, e.g. path, lemma, POS etc.)

---++ Meetings

---+++ 20.04.2017
   * TODO(IK): <del>hand in the CoNLL-2008 data</del>
   * TODO(IK): schedule talks

---+++ 13.04.2017
   * Infrastructure setup
   * Questions regarding implementation

---+++ 6.04.2017
   * _Cancelled: EACL_

---+++ 1-30.03.2017

   * Topic introduction
   * Task description
   * Administration

---++ Things done and questions per week

---+++ 28.04 - 04.05.2017
Things done:
   * Implemented and integrated dependency finding between two given nodes
   * Implemented and integrated voice detection from the recipe
   * CoNLL-Reader timing test on the corpus
   * Improved CoNLL reading speed (I got rid of some readers, the tests are still working, the output file ([[%ATTACHURL%/newoutput.txt][newoutput.txt]]) seems to have the identical arguments (String representation), but now the reading for "say" takes only 0.7 minutes instead of 172 minutes).
   * Implemented the confidence aspect of Lang and Lapata to the Chinese Whispers Algortihm. Now, confidence usage can be added or not via a boolean.
   * Added support for all verbs: All verbs contained and marked in the corpus are searched and arguments are detected per verb.
   * small enrichements of the Pipeline class (mode for CoNLL: one verb, list of verbs, all verbs; evaluation)
   * Speed improvement for finding all verbs and constructing arguments for each verb: From (probably much) more than 105 minutes (I aborted it...) to now only 2.3 minutes (I degugged it and it seems to be working, please feel free to take a look at it, I certainly will add more tests, but it seems to be correctly working). This is the attached output for the reading of all verbs: [[%ATTACHURL%/output_allverbs.txt][output_allverbs.txt]]
   * Added tests for evaluation metrics and the reading of all verbs
   * Now, the Reader only retrieves verbs (POS: V...)
   * Improved reader code
   * Implemented the similarity function by Lang and Lapata (based on sentences numbers)
      * IK: what if there are several Arg0 in the sentence, but they belong to different predicates?

Questions:
   * [ANSWERED] If I remember right, you said that we focus on verbs only, not on predicates for clustering. Does this mean I have to mention that explicitely in the Latex paper (when there is time for that, later)? And also, in the CoNLL file often nouns (predicates) get a frame association, too. Shall we exclude them, because they are not verbs? 
   * [ANSWERED] Lang and Lapata used a function with range [-1, 1] union -inf. How should I adapt this, when given arguments with 5 oder six discrete features? I currently implemented a dummy function which only produces the result of the "normal" argument similarity and I would have to change some constructors and functions (which currently expect integer values) to double value usage. 
   * My distance/similarity function produce integer values, but the class Integer does not offer a -Inf. The class Double does (Double.NEGATIVE_INFINITY). I instead chose Integer.MIN_VALUE (to not have to change alle constructor signatures and methods affected by the distance/similarity functions). Is this also okay or does it have to be the negative infinity by class Double?
      * IK: hm, that should be fine (given the distance function, you will never come anywhere close to Integer.MIN_VALUE), but those minimum values should be treated differently anyway, because _you don't want them to vote at all_. I would suggest, let it be Integer.MIN_VALUE, but store it separately as a constant. It's basically just a way to store the NO-LINK value. Let's talk about this.


---+++ 20. - 27.04.2017
Things done:
   * Downloaded CoNLL (link can be removed!)
   * Implemented a first version of the CoNLL Reader
   * First version of evaluation metrics, integration into the pipeline
   * First try of dependency graphs, necessary data structures implemented
   * Tests for CoNLL and the evaluation
   * Fixed the FIXMEs
Questions:

   * There are some warning when I don't silence System.err in the Pipeline by DKPro. Maybe they aren't important, I'm not sure. What is your opinion? ([[%ATTACHURL%/warnings.txt][warnings.txt]])
      * IK: ignore
   * I don't have Outlook or something similar. In case the UKP meetings are each Tuesday, could you tell me the time and the place?
      * IK: see email
   * How to distinugish between agentive and non-agentive verbs?
      * IK: They have a hint in the paper, agentive are the ones that take Arg0 as subject I guess. You will need dependency trees for that.
   * How to distinguish between active and passive voice? I thought about using the POS tags, but I guess they don't give this information.
      * IK: Yes, that's one of the underspecified parts of the paper, POS tags are not enough. The same POS can mark passive ("The movie was banned") and active ("The government has banned the movie") voice. You will need dependency tree for that, so focus on that first.
   * Please feel free to look over the current version (I guess this is better than informing you on Mondays, even if the version slightly changes afterwards), especially over the CoNLL Reader. I stepped through it (with the Debugging Tool) and tested it on the CONLL data and it seems working for me (except the todos, of course, see the two list items above), but maybe I understood something wrong or made a mistake...
      * I'll have a look
   * Does the syntactic path always lead from a node to the sentence's root?
      * No, a syntactic path leads from node A to node B, sometimes (rarely!) passing through the root. I think I understand what confused you here. I will explain on our meeting. In short, linguistically speaking the main predicate is a root. However, the dependency parsing algorithms require each node in the sentence to have a parent (it's just easier to formulate this way), so they add an abstract node "ROOT" which is the parent of the actual root. So: informally speaking, if you're dealing with the main predicate, your paths would be from the root to the arguments. However, _strictly_ speaking - no, you're not going through the root node, just through the main predicate whos parent is the abstract root. If it's still unclear, I'll give an example on Thursday.
   * Is it possible to move the weekly meetings on Thursday from 13:00 to 12:00?
      * Yes, let's move to 12:00. We won't get the nice room anymore though, but it should be fine.


%META:FILEATTACHMENT{name="warnings.txt" attachment="warnings.txt" attr="h" comment="" date="1492890276" path="warnings.txt" size="667" user="kohr" version="1"}%
%META:FILEATTACHMENT{name="newoutput.txt" attachment="newoutput.txt" attr="" comment="" date="1493466071" path="newoutput.txt" size="40623" user="kohr" version="1"}%
%META:FILEATTACHMENT{name="output_allverbs.txt" attachment="output_allverbs.txt" attr="" comment="" date="1493553829" path="output_allverbs.txt" size="1965805" user="kohr" version="1"}%
%META:FILEATTACHMENT{name="Results.zip" attachment="Results.zip" attr="" comment="" date="1494417520" path="Results.zip" size="875501" user="kohr" version="1"}%
%META:FILEATTACHMENT{name="Result2.zip" attachment="Result2.zip" attr="" comment="" date="1494478594" path="Result2.zip" size="1285048" user="kohr" version="1"}%
%META:FILEATTACHMENT{name="chp3A10.10072F978-3-540-72530-5_25.pdf" attachment="chp3A10.10072F978-3-540-72530-5_25.pdf" attr="" comment="C-DBSCAN paper" date="1494497238" path="chp%253A10.1007%252F978-3-540-72530-5_25.pdf" size="331048" user="kuznetsov" version="1"}%
%META:PREFERENCE{name="TOPICTITLE" title="TOPICTITLE" type="Local" value="Ben Kohr"}%
