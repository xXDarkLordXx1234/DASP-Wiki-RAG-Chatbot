%META:TOPICINFO{author="TorstenZesch" date="1285143133" format="1.1" version="5"}%
%META:TOPICPARENT{name="MateuszParzonka"}%
%TOC%

---++++++ 21 Sep 2010 (TZ/NE)
   * Discussed UIMA-specific topics:
      * Testing of Pipelines and testing of Annotators. 
      * Introduced implementation of automatic pipeline testing. 
      * Received demo code for Annotator testing.
   * Discussed filtering of common words and common phrases:
      * Discussed using TF-IDF for common word filtering.
      * Discussed using a web search count for common word filtering and a common phrase metric.
      * UKP has the Web 1T 5-gram Version 1 (1-5-grams and frequency counts from Google) which could be used too.
         * *TZ:* access to Web 1T is the best choice (although using tf.idf should also be tested)
            * http://get1t.sourceforge.net/
            * http://groups.google.com/group/digitalpebble/browse_thread/thread/60205a72a66570a6
            * http://hlt.fbk.eu/en/node/81
            * http://webascorpus.sourceforge.net/PHITE.php?sitesig=FILES&page=FILES_10_Software&subpage=FILES_50_Google_N-Grams
            * V2 is already announced http://www.lrec-conf.org/proceedings/lrec2010/slides/233.pdf
            * Please have a look at the different choices and decide which is the best and whether it can be used for our purposes
               * Java is preferred, but if some other program is much faster (and better), everything would be ok (even Perl :) )
   * Discussed segmentation:
      * Discussed possibility of a rule-based segmenter exploiting the syntactic structure of a book for topical segmentation.
      * Segmenters for experiments could be: 
         * jTextTile 
         * C99
         * SentenceSegmenter (as baseline) 
         * Rule-based book segmenter (optional)
   * Discussed Keyphrase Extraction:
      * Keyphrase extraction should be limited to TextRank (OccurenceGraph & PageRank) for now. 
      * LSG is too expensive in this phase. 
      * Other extractors exist but will be discussed later.
         * *TZ:* tf.idf ranking based on the baseline candidates should also be used
   * Next step: 
      * Implement baseline system following Csomai & Mihalceas approach using n-grams, NP-chunks and (heuristic) Named Entity Recognition their original data set.

---++++++ 14 Sep 2010 (TZ)
   * Discussed pipeline layout: 
      * Pipeline should consist of Keyphrase Extraction on subCASes followed by a postprocessing step that filters suitable index entry candidates.
      * Rather focus on Keyphrase Extraction than Named Entity Recognition.
      * Discussed possibility of using "global" information to enhance postprocessing step.
   * Discussed technical details: 
      * Looked at (de)multiplication for subcas-processing. Awaiting demo code for proper UIMA-Settings when (de)multiplying.
   * Next steps:
      * Attapt _KeyphraseEvaluatorApproximate_ to evaluate BOTBI-Pipeline with recall, precision, f-measure
      * Write simple pipeline that processes a whole book and evaluate index entries with gold standard