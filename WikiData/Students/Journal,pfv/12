%META:TOPICINFO{author="BaseUserMapping_999" date="1360762007" format="1.1" version="12"}%
%META:TOPICPARENT{name="StefanHenss"}%
---+ Journal

Start Date: 15.10.2012<br />
End Date: 15.04.2013

---++ Current and Past Entries

| *Week* | *Original Plan / Milestone Log* |
| 6 | 1st milestone: beating reasonable baselines for each component; design of major features, changes to algorithms and new machine learning techniques, notes on reinforcement learning resources. |
| 4-5 | Implementation of competitive state-of-the-art technology; notes on summarization papers. |
| 3 | Implementation of evaluation functions and benchmarks; implementation of further features for all tasks; preparations for implementing competitive systems; notes on all keywords-related papers. |
| 2 | Formalization of decision processes; collection of benchmarks and baselines; design of additional evaluation functions; design and implementation of an evaluation and reporting framework; notes on all web crawling papers. |
| 1 | Migration of current notes into Wiki; thesis outline; patent search and collection of related work; software and code repository setup. |
| | 18.10.: Frameworks for dossier extraction and single-/multi-document summarization completed; no features yet. |
| | 11.10.: First working version of keyword assignment and its evaluation. Again, proper features will be required for good results. |
| | 8.10.: Working version of crawler incl. multiple reinforcement learning algorithms and experimentation/evaluation framework. Now requires sophisticated features. |

---++ Future Plan

| *Week* | *Plan* |
| 7-12 | Implementation of major software components, including the development of features and tuning existent software; incorporation of further datasets. |
| 13 | 2nd milestone: beating the majority of competitors for all components; mid-term presentation; further planning and design of changes and additions; preparation for thesis. |
| 14-21 | Further software refinements; writing thesis; optional: implementation of clustering approach; if required: migration to DKPro. |
| 22 | 3rd milestone: First complete version of thesis and software; further planning. |
| 23-25 | Final refinements and design of the presentation; backup slots for delays and unforeseen requirements. |
| 26 | Delivery of thesis and presentation. |

---++ Detailed Reports

---+++ Week 6, 2.11.
   * New crawler evaluation method:
      * For topic discovery capabilities, we can crawl the open web and just compute similarity metrics w.r.t. to the expected documents. In a second step, we have to check if we'd then be able to discriminate between those vaguely similar documents and exact matches: 
      * Since there are 80+ domains with at least 30 documents in the DIPF database, we can test if those are retrieved when crawling those domains. This is especially hard since we have to navigate around very similar documents. For general search capabilities, we can crawl the open web and just compute content similarity.
      * Further work on the crawler done (e.g., exception handling and URL filtering and normalization).
   * Integrated the SemEval-2 Keyphrase Extraction Track dataset including further work on the keywords module.
   * Added further competitive approaches: MAUI, PageRank, LexRank and its extension from the "Dragon Toolkit".
   * Annotations/descriptions of components for the generated reports.
   * Rest of the week:
      * Further improvements of all components (new features etc.)
      * Framework for graph-based baselines for keyword and summary extraction (combinations of edge weighing and node importance algorithms like PageRank, HITS, etc.).
      * Research into advanced reinforcement learning techniques such as genetic RL.
      * More information for the reports and inclusion into website.

---+++ Weeks 4-5, 5.11.
   * Integrated the DIPF's redactional content database.
   * Replaced interfaces to Stanford NLP and OpenNLP with DKPro interfaces, including the models mechanism.
   * Set up DKPro resource-based similarity measures (Wiki, WordNet).
   * Implemented competitive approaches, including noteworthy systems: lexical chains, various graph representations of content, and corpus-based similarity measures.
   * Added framework for defining and combining features sets, including documentation capabilities.
   * Started working on a proxy service for crawling.
   * A few general improvements in all 5 topics to keep up with baselines and competitive systems.
   * Further efforts in performance, memory and caching for now 3,000,000+ predictions in each of the 10 parallel runs of cross validation.
   * Rest of the week:
      * Update Wiki with methodological updates, new datasets, paper notes and newly found papers, and new insights (especially crawling).
      * Work on reporting framework to automate summarization of pipeline elements and feature sets.
      * Automating updates of simulation results and reports for evaluation website.

---+++ Week 3, 29.10.
   * Implemented term similarity using term document matrices based on variable frequency measures.
   * Baselines: Random Selection, First N Candidates Selection, Similarity-Based Selection, Term Frequency Selection, Optimal Selection Baseline, framework for Supervised Learning baselines.
   * Additional evaluation functions for ranking and metrics based on term distribution / term similarity measures.
   * Building a web graph around the Bildungsserver URLs is still in progress since crawling search engines for backlinks gets us blocked after a few dozen requests.
   * General improvement on the current framework (mainly data preprocessing) and the state of the single approaches (e.g., term similarity features).
   * Implementation of remaining baselines and metrics for document summarization.
   * Redesign of evaluation website to deal with the larger quantities of evaluation functions.
   * Notes on all keywords-related papers

---+++ Week 2, 22.10.
   * There are 1000s of model updates and at least 100,000 state-action-value predictions for one simulation of keyword assignment using RL:
      * Remodeled framework to optimize balance between reusing in-memory data and not running out of memory.
      * Made a few 3rd-party regression algorithms use my own data objects to avoid overhead from the adapters to their original libraries.
   * Implemented framework to be able to centrally define and combine configurations/parameters for data/features, model/approach and simulation.
   * Almost completed website for comparing performance on each task and over time (link follows).
   * Collection and design of benchmarks/baselines/objective functions for all tasks.
   * Add Wiki pages for all tasks and update methodology on current pages.
   * Notes on focused crawling papers.

---+++ Week 1, 15.10.
   * Initial collection of related work.
   * Completed framework for extraction and summarization, including process formulation for all 5 tasks.
   * Implementation of more features for web crawling and keyword assignment.
   * Implemented solutions for PDF parsing errors and spelling/encoding issues.
   * Transfer of relevant past notes into Wiki.