%META:TOPICINFO{author="dallmann" comment="" date="1576602289" format="1.1" reprev="8" version="9"}%
%META:TOPICPARENT{name="StudentsList"}%
---+!! Master Thesis: Employing Graph Neural Networks for Text Production from Knowledge Graphs

*Start date*: 22.11.2019

*End date*: 22.05.2020

*Supervisor*: Leonardo Ribeiro

*Midterm Talk*: 

*Final Talk*: 

---+++ Meeting 18.12.2019
---++++Last steps
   * Run all current AGENDA and WebNLG input methods with GIN, GAT and GGNN
   * Train AGENDA and WebNLG with other GNNs (ArmaConv, SGConv)
   * Try to create new dataset
   * Fix Moverscore issues
---++++Questions
   * Does new dataset really make sense?
      * show current predictions and statistics
      * extracted 2019 computer science papers from Arxiv (63250) --> only about half has an abstract in the metadata --> entity/relation extraction with Dygie++ model, pretrained on Scierc data (500 papers from AI conferences) --> some relation extractions do not make sense at all (approximately once an abstract has more than 20 relations, the quality of the relations does not seem to be good)
         * problems for example with abstracts where formula are used
         * in other data points, there are no predicted relations or entities 
   * Create embedding with BERT or SciBERT?
      * How to do it with a graph? --> as it would be usually a sentence as input so that BERT can use the context
---++++Next steps?
   * Maybe train new dataset?
   * Adapt models?
   * Changing input method to only one file?

---+++ Meeting 06.12.2019
---++++Last steps
   * Debugging encoder to enable learning with features 
   * Using WebNLG dataset as further input dataset 
   * Running several experiments with different input methods
---++++Questions
   * learning with features leads to worse results
      * possible approaches to debug this issue?
   * MoverScore works with the test set but not with the dev set
      * dimension error -> What could be the issue? Dev and test set are preprocessed the same way 
---++++Next steps?
   * Starting with the best input method and run with different GNNs (predefinded ones from Pytorch Geometric)
   * Processing Wikibio dataset
   * Fix Moverscore and dev set issue
   * Debug learning with features


---+++ Meeting 29.11.2019
---++++Last steps
   * Evaluation script using MoverScore, Multi-BLEU and Meteor
   * Trying to run models with batch size 20
   * Implement input method using features
---++++Questions
   * Training with batch size 20 always leads to an out-of-memory error --> even when trying to block 64G memory
      * How to solve this issue?
      * calculating loss function is currently the point where the OOM error occurs
      * single tensors itself are not so large 
      * calling garbage collector and empyting cache before does not help completely 
   * Validation also using MoverScore --> takes quite long (~5 min) to calculate? --> not do it for every validation step? or use data sampling?


---+++ Meeting 22.11.2019
---++++Last steps 
   * Getting scripts run with Slurm 
   * Train on AGENDA dataset with different preprocessing methods and gin/ggnn models 
   * Train on Visual Genome dataset  
   * Start writing theoretical chapters about datasets/ GNNs 

---++++Questions/ Next Steps 
   * Discuss on how to further structure the next steps. 
      * Trying different GNNs on all ways of preprocessing? 
         * Also take older NNs (from Pytorch-Geometric)? 
      * Or determine a good preprocessing way first? 
         * Understanding of creating a vector-based input still difficult 
   * AGENDA dataset 
      * Approach to use the node classes as well? --> e.g. put them as nodes in the graph as well? 
   * How to avoid CUDA out-of-memory error?  
      * How to determine the best amount of storage to reserve for training? 
   * How to determine the initial parameters intelligently? 
   * Official registration of thesis --> forward form to IG!?

---+++ Meeting 29.10.2019
---++++ Next Steps
   * Get model running on Slurm using AGENDA dataset
   * Try different dataset input options (LSTM, various linearisation methods)
   * Start writing theoretical chapters



-- Main.AlinaDallmann - 2019-10-28
