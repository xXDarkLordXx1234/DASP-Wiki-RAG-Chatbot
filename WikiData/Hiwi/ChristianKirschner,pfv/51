%META:TOPICINFO{author="ChristianKirschner" date="1324474980" format="1.1" version="51"}%
%META:TOPICPARENT{name="WebHome"}%
<!--
   * Set ALLOWTOPICVIEW = Main.ChristianKirschner,Main.UkpGroup
   * Set ALLOWTOPICCHANGE = Main.ChristianKirschner,Main.UkpGroup
//-->

---+ Christian Kirschner's Work

---++ Project Plan (tentative)

   * *<span class="green">Part 1</span>*
      * <span class="green">Read task description (CICLing sec. 4; IGI sec. rel. anchoring)</span>
      * <span class="green">Read annotation guidebook</span>
      * <span class="green">Familiarize with task</span>
   * Part 2
      * <span class="green">Look into Wiktionary; structure and API access</span>
      * <span class="green">Which dimensions are necessary/important to consider for a dataset?
         * This will be a core question to be discussed</span>
      * <span class="green">Include Wikisaurus?</span>
      * <span class="green">Develop a well-balanced reference dataset for the English relation anchoring task (maybe also for the German?) [with !ChM]</span>
      * Update the annotation guidebook
   * Part 3
      * Annotate the data [@ChM find additional annotator(s)]
      * Evaluate the dataset [with !ChM]
   * Part 4
      * <span class="green">@ChM Update the anchoring framework</span>
      * <span class="green">Get the framework to work, familiarize with code</span>
      * Run the existing methods with old and new data
      * Analyze errors
         * What do we need to solve?
         * What can be improved?
            * This will be a core question to be discussed
   * Part 5
      * Try and develop heuristics (come up with fancy names for them)
         * existing return relation
         * target gloss contains source word
         * matching domain (@ChM: further think about that)
      * Try and develop new methods, ideas:
         * PPR?
         * Graph-based method (Navid?)
         * PROX?
         * Milne/Witten?
   * Part 6
      * @ChM: get cross-lingual dataset ready
      * Select translation API and translate glosses
      * Experiments on cross-lingual dataset

---++ GoldStandard Generation

   * On the one hand the GoldStandard should build up in a way that weaknesses of disambiguation algorithms can be detected, on the other hand it should be quite representative. Therefore we are going to use the following criteria:
      * Part of speech
      * Relations
      * Number of candidates
      * Labels

---++ Heuristics

   1 Wenn ein Sense eine Relation (z.B. Hyperonym) auf einen anderen Artikel hat und einer der Kandidaten wiederum eine Relation (z.B. Hyponym) zurück zum Ausgangsartikel besitzt, so ist dieser Kandidat höchstwahrscheinlich positiv zu annotieren. Dies funktioniert mit Synonym-Synonym, Antonym-Antonym, Hyperonym-Hyponym und Hyponym-Hyperonym Relationspaaren. Auf dem deutschen Datensatz ist die Heuristik bei 11,5% der Paare anwendbar und hat eine Precision von 96,4%. Auf dem englischen Datensatz ist die Heuristik bei 3,3% der Paare anwendbar und hat eine Precision von 85,7%. 
   2 Wenn eine Instanz nur einen möglichen Kandidaten hat, wird dieser positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 21,6% der Paare anwendbar und hat eine Precision von 96,6%. Auf dem englischen Datensatz ist die Heuristik bei 12,8% der Paare anwendbar und hat eine Precision von 98,6%. 
   3 Wenn ein Kandidat im Gloss das Lemma der Instanz enthält, wird das Paar positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 1,5% der Paare anwendbar und hat eine Precision von 94,4%. Auf dem englischen Datensatz ist die Heuristik bei 4,6% der Paare anwendbar und hat eine Precision von 81,0%. 

 * Heuristik 1: <br />
     <img src="%ATTACHURLPATH%/heuristik1.png" alt="heuristik1.png" width="400" height="350" />

---++ Boni

   1 Der Score des ersten Kandidaten jeder Instanz erhält einen Bonus indem der berechnete Score verdoppelt wird (+ einer kleinen Konstante 0.01, damit er nicht bei 0 verbleibt). Die FirstCandidateBaseline hat alleine eine Precision von 81,19% (deutscher Datensatz) bzw. 77,53% (englischer Datensatz).

---++ Results

---+++ Experimente auf dem deutschen Datensatz:

Alle Paare positiv annotieren (Schwellenwert 0): Die Ergebnisse treten auch bei Lesk ohne Nutzung von Heuristiken auf, da auch hier der optimale Schwellenwert bei 0 liegt, sowie bei völlig zufälliger Annotation der Paare (RandomBaseline). 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,48773 ( 596/1222) | 0,48773 ( 596/1222) | 1,00000 ( 596/ 596) | 0,65567 | ALL | 
| 0,89655 (  26/  29) | 0,89655 (  26/  29) | 1,00000 (  26/  26) | 0,94545 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,48000 (  36/  75) | 0,48000 (  36/  75) | 1,00000 (  36/  36) | 0,64865 | N-2-HAS_SYN | 
| 0,35849 (  38/ 106) | 0,35849 (  38/ 106) | 1,00000 (  38/  38) | 0,52778 | N-2-HAS_ANT | 
| 0,33913 (  39/ 115) | 0,33913 (  39/ 115) | 1,00000 (  39/  39) | 0,50649 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,28846 (  30/ 104) | 0,28846 (  30/ 104) | 1,00000 (  30/  30) | 0,44776 | V-2-HAS_SYN | 
| 0,36301 (  53/ 146) | 0,36301 (  53/ 146) | 1,00000 (  53/  53) | 0,53266 | V-2-HAS_ANT | 
| 0,26389 (  38/ 144) | 0,26389 (  38/ 144) | 1,00000 (  38/  38) | 0,41758 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,65455 (  36/  55) | 0,65455 (  36/  55) | 1,00000 (  36/  36) | 0,79121 | A-2-HAS_SYN | 
| 0,50000 (  17/  34) | 0,50000 (  17/  34) | 1,00000 (  17/  17) | 0,66667 | A-2-HAS_ANT | 
| 0,25581 (  11/  43) | 0,25581 (  11/  43) | 1,00000 (  11/  11) | 0,40741 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,50000 (  19/  38) | 0,50000 (  19/  38) | 1,00000 (  19/  19) | 0,66667 | R-2-HAS_SYN | 
| 0,22917 (  11/  48) | 0,22917 (  11/  48) | 1,00000 (  11/  11) | 0,37288 | R-2-HAS_ANT | 
| 0,26923 (  14/  52) | 0,26923 (  14/  52) | 1,00000 (  14/  14) | 0,42424 | R-2-HAS_HYPO/HAS_HYPER | 

Nur die Heuristiken 1-3 (alle anderen negativ annotiert):
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,75941 ( 928/1222) | 0,96037 ( 315/ 328) | 0,52852 ( 315/ 596) | 0,68182 | ALL | 
| 0,82759 (  24/  29) | 0,88889 (  24/  27) | 0,92308 (  24/  26) | 0,90566 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,60000 (  45/  75) | 1,00000 (   6/   6) | 0,16667 (   6/  36) | 0,28571 | N-2-HAS_SYN | 
| 0,72642 (  77/ 106) | 1,00000 (   9/   9) | 0,23684 (   9/  38) | 0,38298 | N-2-HAS_ANT | 
| 0,68696 (  79/ 115) | 0,80000 (   4/   5) | 0,10256 (   4/  39) | 0,18182 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,75962 (  79/ 104) | 1,00000 (   5/   5) | 0,16667 (   5/  30) | 0,28571 | V-2-HAS_SYN | 
| 0,71233 ( 104/ 146) | 1,00000 (  11/  11) | 0,20755 (  11/  53) | 0,34375 | V-2-HAS_ANT | 
| 0,75000 ( 108/ 144) | 0,66667 (   4/   6) | 0,10526 (   4/  38) | 0,18182 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,58182 (  32/  55) | 1,00000 (  13/  13) | 0,36111 (  13/  36) | 0,53061 | A-2-HAS_SYN | 
| 0,67647 (  23/  34) | 1,00000 (   6/   6) | 0,35294 (   6/  17) | 0,52174 | A-2-HAS_ANT | 
| 0,76744 (  33/  43) | 0,66667 (   2/   3) | 0,18182 (   2/  11) | 0,28571 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,47368 (  18/  38) | 0,00000 (   0/   1) | 0,00000 (   0/  19) | 0,00000 | R-2-HAS_SYN | 
| 0,81250 (  39/  48) | 1,00000 (   2/   2) | 0,18182 (   2/  11) | 0,30769 | R-2-HAS_ANT | 
| 0,75000 (  39/  52) | 1,00000 (   1/   1) | 0,07143 (   1/  14) | 0,13333 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, mit Heuristiken 1-3, ohne Bonus, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,76923 ( 940/1222) | 0,84735 ( 383/ 452) | 0,64262 ( 383/ 596) | 0,73092 | ALL | 
| 0,86207 (  25/  29) | 0,89286 (  25/  28) | 0,96154 (  25/  26) | 0,92593 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,68000 (  51/  75) | 0,83333 (  15/  18) | 0,41667 (  15/  36) | 0,55556 | N-2-HAS_SYN | 
| 0,83962 (  89/ 106) | 0,95652 (  22/  23) | 0,57895 (  22/  38) | 0,72131 | N-2-HAS_ANT | 
| 0,66957 (  77/ 115) | 0,53846 (   7/  13) | 0,17949 (   7/  39) | 0,26923 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,79808 (  83/ 104) | 0,69565 (  16/  23) | 0,53333 (  16/  30) | 0,60377 | V-2-HAS_SYN | 
| 0,72603 ( 106/ 146) | 0,88235 (  15/  17) | 0,28302 (  15/  53) | 0,42857 | V-2-HAS_ANT | 
| 0,70139 ( 101/ 144) | 0,40000 (  10/  25) | 0,26316 (  10/  38) | 0,31746 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,60000 (  33/  55) | 0,79167 (  19/  24) | 0,52778 (  19/  36) | 0,63333 | A-2-HAS_SYN | 
| 0,67647 (  23/  34) | 0,80000 (   8/  10) | 0,47059 (   8/  17) | 0,59259 | A-2-HAS_ANT | 
| 0,67442 (  29/  43) | 0,40000 (   6/  15) | 0,54545 (   6/  11) | 0,46154 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,60526 (  23/  38) | 0,75000 (   6/   8) | 0,31579 (   6/  19) | 0,44444 | R-2-HAS_SYN | 
| 0,77083 (  37/  48) | 0,50000 (   3/   6) | 0,27273 (   3/  11) | 0,35294 | R-2-HAS_ANT | 
| 0,67308 (  35/  52) | 0,33333 (   3/   9) | 0,21429 (   3/  14) | 0,26087 | R-2-HAS_HYPO/HAS_HYPER | 

FirstCandidateBaselineMethod (ohne Heuristiken):
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,78642 ( 961/1222) | 0,81192 ( 436/ 537) | 0,73154 ( 436/ 596) | 0,76964 | ALL | 
| 0,86207 (  25/  29) | 0,89286 (  25/  28) | 0,96154 (  25/  26) | 0,92593 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,60000 (  45/  75) | 0,60000 (  18/  30) | 0,50000 (  18/  36) | 0,54545 | N-2-HAS_SYN | 
| 0,76415 (  81/ 106) | 0,72414 (  21/  29) | 0,55263 (  21/  38) | 0,62687 | N-2-HAS_ANT | 
| 0,82609 (  95/ 115) | 0,82759 (  24/  29) | 0,61538 (  24/  39) | 0,70588 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,67308 (  70/ 104) | 0,42857 (  12/  28) | 0,40000 (  12/  30) | 0,41379 | V-2-HAS_SYN | 
| 0,69178 ( 101/ 146) | 0,61111 (  22/  36) | 0,41509 (  22/  53) | 0,49438 | V-2-HAS_ANT | 
| 0,88889 ( 128/ 144) | 0,80556 (  29/  36) | 0,76316 (  29/  38) | 0,78378 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,58182 (  32/  55) | 0,84211 (  16/  19) | 0,44444 (  16/  36) | 0,58182 | A-2-HAS_SYN | 
| 0,70588 (  24/  34) | 0,73333 (  11/  15) | 0,64706 (  11/  17) | 0,68750 | A-2-HAS_ANT | 
| 0,69767 (  30/  43) | 0,42857 (   6/  14) | 0,54545 (   6/  11) | 0,48000 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,57895 (  22/  38) | 0,60000 (   9/  15) | 0,47368 (   9/  19) | 0,52941 | R-2-HAS_SYN | 
| 0,75000 (  36/  48) | 0,45455 (   5/  11) | 0,45455 (   5/  11) | 0,45455 | R-2-HAS_ANT | 
| 0,84615 (  44/  52) | 0,71429 (  10/  14) | 0,71429 (  10/  14) | 0,71429 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, ohne Heuristiken, mit Bonus 1, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,78314 ( 957/1222) | 0,76063 ( 483/ 635) | 0,81040 ( 483/ 596) | 0,78473 | ALL | 
| 0,86207 (  25/  29) | 0,89286 (  25/  28) | 0,96154 (  25/  26) | 0,92593 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,62667 (  47/  75) | 0,60526 (  23/  38) | 0,63889 (  23/  36) | 0,62162 | N-2-HAS_SYN | 
| 0,84906 (  90/ 106) | 0,77500 (  31/  40) | 0,81579 (  31/  38) | 0,79487 | N-2-HAS_ANT | 
| 0,79130 (  91/ 115) | 0,71429 (  25/  35) | 0,64103 (  25/  39) | 0,67568 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,69231 (  72/ 104) | 0,47727 (  21/  44) | 0,70000 (  21/  30) | 0,56757 | V-2-HAS_SYN | 
| 0,68493 ( 100/ 146) | 0,59459 (  22/  37) | 0,41509 (  22/  53) | 0,48889 | V-2-HAS_ANT | 
| 0,83333 ( 120/ 144) | 0,63462 (  33/  52) | 0,86842 (  33/  38) | 0,73333 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,65455 (  36/  55) | 0,75758 (  25/  33) | 0,69444 (  25/  36) | 0,72464 | A-2-HAS_SYN | 
| 0,70588 (  24/  34) | 0,68421 (  13/  19) | 0,76471 (  13/  17) | 0,72222 | A-2-HAS_ANT | 
| 0,60465 (  26/  43) | 0,37500 (   9/  24) | 0,81818 (   9/  11) | 0,51429 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,65789 (  25/  38) | 0,66667 (  12/  18) | 0,63158 (  12/  19) | 0,64865 | R-2-HAS_SYN | 
| 0,68750 (  33/  48) | 0,35714 (   5/  14) | 0,45455 (   5/  11) | 0,40000 | R-2-HAS_ANT | 
| 0,76923 (  40/  52) | 0,55000 (  11/  20) | 0,78571 (  11/  14) | 0,64706 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,79624 ( 973/1222) | 0,76489 ( 501/ 655) | 0,84060 ( 501/ 596) | 0,80096 | ALL | 
| 0,86207 (  25/  29) | 0,89286 (  25/  28) | 0,96154 (  25/  26) | 0,92593 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,62667 (  47/  75) | 0,60526 (  23/  38) | 0,63889 (  23/  36) | 0,62162 | N-2-HAS_SYN | 
| 0,85849 (  91/ 106) | 0,78049 (  32/  41) | 0,84211 (  32/  38) | 0,81013 | N-2-HAS_ANT | 
| 0,78261 (  90/ 115) | 0,69444 (  25/  36) | 0,64103 (  25/  39) | 0,66667 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,71154 (  74/ 104) | 0,50000 (  23/  46) | 0,76667 (  23/  30) | 0,60526 | V-2-HAS_SYN | 
| 0,74658 ( 109/ 146) | 0,67391 (  31/  46) | 0,58491 (  31/  53) | 0,62626 | V-2-HAS_ANT | 
| 0,83333 ( 120/ 144) | 0,62963 (  34/  54) | 0,89474 (  34/  38) | 0,73913 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,70909 (  39/  55) | 0,77778 (  28/  36) | 0,77778 (  28/  36) | 0,77778 | A-2-HAS_SYN | 
| 0,73529 (  25/  34) | 0,70000 (  14/  20) | 0,82353 (  14/  17) | 0,75676 | A-2-HAS_ANT | 
| 0,60465 (  26/  43) | 0,37500 (   9/  24) | 0,81818 (   9/  11) | 0,51429 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,65789 (  25/  38) | 0,66667 (  12/  18) | 0,63158 (  12/  19) | 0,64865 | R-2-HAS_SYN | 
| 0,70833 (  34/  48) | 0,40000 (   6/  15) | 0,54545 (   6/  11) | 0,46154 | R-2-HAS_ANT | 
| 0,76923 (  40/  52) | 0,55000 (  11/  20) | 0,78571 (  11/  14) | 0,64706 | R-2-HAS_HYPO/HAS_HYPER | 

Die Ergebnisse mit dem CosineComparator (RelatednessMethod) liegen jeweils leicht unter den Werten von Lesk. Hier CosineComparator mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.005:
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,79460 ( 971/1222) | 0,76417 ( 499/ 653) | 0,83725 ( 499/ 596) | 0,79904 | ALL | 
| 0,86207 (  25/  29) | 0,89286 (  25/  28) | 0,96154 (  25/  26) | 0,92593 | N-1-HAS_SYN | 
| 0,96429 (  27/  28) | 0,96429 (  27/  28) | 1,00000 (  27/  27) | 0,98182 | N-1-HAS_ANT | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,62667 (  47/  75) | 0,60526 (  23/  38) | 0,63889 (  23/  36) | 0,62162 | N-2-HAS_SYN | 
| 0,83962 (  89/ 106) | 0,76923 (  30/  39) | 0,78947 (  30/  38) | 0,77922 | N-2-HAS_ANT | 
| 0,78261 (  90/ 115) | 0,69444 (  25/  36) | 0,64103 (  25/  39) | 0,66667 | N-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 0,90323 (  28/  31) | 0,90323 (  28/  31) | 1,00000 (  28/  28) | 0,94915 | V-1-HAS_ANT | 
| 0,96875 (  31/  32) | 0,96875 (  31/  32) | 1,00000 (  31/  31) | 0,98413 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,71154 (  74/ 104) | 0,50000 (  23/  46) | 0,76667 (  23/  30) | 0,60526 | V-2-HAS_SYN | 
| 0,74658 ( 109/ 146) | 0,67391 (  31/  46) | 0,58491 (  31/  53) | 0,62626 | V-2-HAS_ANT | 
| 0,83333 ( 120/ 144) | 0,62963 (  34/  54) | 0,89474 (  34/  38) | 0,73913 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,70909 (  39/  55) | 0,77778 (  28/  36) | 0,77778 (  28/  36) | 0,77778 | A-2-HAS_SYN | 
| 0,73529 (  25/  34) | 0,70000 (  14/  20) | 0,82353 (  14/  17) | 0,75676 | A-2-HAS_ANT | 
| 0,60465 (  26/  43) | 0,37500 (   9/  24) | 0,81818 (   9/  11) | 0,51429 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,65789 (  25/  38) | 0,66667 (  12/  18) | 0,63158 (  12/  19) | 0,64865 | R-2-HAS_SYN | 
| 0,70833 (  34/  48) | 0,40000 (   6/  15) | 0,54545 (   6/  11) | 0,46154 | R-2-HAS_ANT | 
| 0,76923 (  40/  52) | 0,55000 (  11/  20) | 0,78571 (  11/  14) | 0,64706 | R-2-HAS_HYPO/HAS_HYPER | 

---+++ Experimente auf dem englischen Datensatz:

Alle Paare positiv annotieren (Schwellenwert 0): Die Ergebnisse treten auch bei völlig zufälliger Annotation der Paare auf (RandomBaseline). 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,30982 ( 527/1701) | 0,30982 ( 527/1701) | 1,00000 ( 527/ 527) | 0,47307 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,20118 (  34/ 169) | 0,20118 (  34/ 169) | 1,00000 (  34/  34) | 0,33498 | N-2-HAS_SYN | 
| 0,19728 (  58/ 294) | 0,19728 (  58/ 294) | 1,00000 (  58/  58) | 0,32955 | N-2-HAS_ANT | 
| 0,16842 (  16/  95) | 0,16842 (  16/  95) | 1,00000 (  16/  16) | 0,28829 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,22388 (  15/  67) | 0,22388 (  15/  67) | 1,00000 (  15/  15) | 0,36585 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,22785 (  54/ 237) | 0,22785 (  54/ 237) | 1,00000 (  54/  54) | 0,37113 | V-2-HAS_SYN | 
| 0,17647 (  39/ 221) | 0,17647 (  39/ 221) | 1,00000 (  39/  39) | 0,30000 | V-2-HAS_ANT | 
| 0,10667 (   8/  75) | 0,10667 (   8/  75) | 1,00000 (   8/   8) | 0,19277 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,31169 (  24/  77) | 0,31169 (  24/  77) | 1,00000 (  24/  24) | 0,47525 | A-2-HAS_SYN | 
| 0,22500 (  18/  80) | 0,22500 (  18/  80) | 1,00000 (  18/  18) | 0,36735 | A-2-HAS_ANT | 
| 0,28000 (   7/  25) | 0,28000 (   7/  25) | 1,00000 (   7/   7) | 0,43750 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,23750 (  19/  80) | 0,23750 (  19/  80) | 1,00000 (  19/  19) | 0,38384 | R-2-HAS_SYN | 
| 0,38571 (  27/  70) | 0,38571 (  27/  70) | 1,00000 (  27/  27) | 0,55670 | R-2-HAS_ANT | 
| 1,00000 (   3/   3) | 1,00000 (   3/   3) | 1,00000 (   3/   3) | 1,00000 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words) ohne Heuristiken, ohne Bonus, trainierter Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,75250 (1280/1701) | 0,62100 ( 272/ 438) | 0,51613 ( 272/ 527) | 0,56373 | ALL | 
| 0,85185 (  23/  27) | 1,00000 (  21/  21) | 0,84000 (  21/  25) | 0,91304 | N-1-HAS_SYN | 
| 0,60000 (  18/  30) | 1,00000 (  18/  18) | 0,60000 (  18/  30) | 0,75000 | N-1-HAS_ANT | 
| 0,64286 (   9/  14) | 0,90000 (   9/  10) | 0,69231 (   9/  13) | 0,78261 | N-1-HAS_HYPO/HAS_HYPER | 
| 0,66667 (   6/   9) | 1,00000 (   6/   6) | 0,66667 (   6/   9) | 0,80000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,84615 ( 143/ 169) | 0,61111 (  22/  36) | 0,64706 (  22/  34) | 0,62857 | N-2-HAS_SYN | 
| 0,85034 ( 250/ 294) | 0,68421 (  26/  38) | 0,44828 (  26/  58) | 0,54167 | N-2-HAS_ANT | 
| 0,72632 (  69/  95) | 0,33333 (  10/  30) | 0,62500 (  10/  16) | 0,43478 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,71642 (  48/  67) | 0,41667 (  10/  24) | 0,66667 (  10/  15) | 0,51282 | N-2-HAS_MERO/HAS_HOLO | 
| 0,67857 (  19/  28) | 1,00000 (  19/  19) | 0,67857 (  19/  28) | 0,80851 | V-1-HAS_SYN | 
| 0,34483 (  10/  29) | 1,00000 (  10/  10) | 0,34483 (  10/  29) | 0,51282 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,65823 ( 156/ 237) | 0,33735 (  28/  83) | 0,51852 (  28/  54) | 0,40876 | V-2-HAS_SYN | 
| 0,81448 ( 180/ 221) | 0,47727 (  21/  44) | 0,53846 (  21/  39) | 0,50602 | V-2-HAS_ANT | 
| 0,88000 (  66/  75) | 0,40000 (   2/   5) | 0,25000 (   2/   8) | 0,30769 | V-2-HAS_HYPO/HAS_HYPER | 
| 0,64286 (   9/  14) | 1,00000 (   9/   9) | 0,64286 (   9/  14) | 0,78261 | A-1-HAS_SYN | 
| 0,43750 (   7/  16) | 1,00000 (   7/   7) | 0,43750 (   7/  16) | 0,60870 | A-1-HAS_ANT | 
| 0,57143 (   4/   7) | 1,00000 (   4/   4) | 0,57143 (   4/   7) | 0,72727 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,67532 (  52/  77) | 0,47368 (   9/  19) | 0,37500 (   9/  24) | 0,41860 | A-2-HAS_SYN | 
| 0,81250 (  65/  80) | 1,00000 (   3/   3) | 0,16667 (   3/  18) | 0,28571 | A-2-HAS_ANT | 
| 0,72000 (  18/  25) | 0,50000 (   5/  10) | 0,71429 (   5/   7) | 0,58824 | A-2-HAS_HYPO/HAS_HYPER | 
| 0,43750 (   7/  16) | 1,00000 (   7/   7) | 0,43750 (   7/  16) | 0,60870 | R-1-HAS_SYN | 
| 0,33333 (   5/  15) | 1,00000 (   5/   5) | 0,33333 (   5/  15) | 0,50000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,75000 (  60/  80) | 0,47059 (   8/  17) | 0,42105 (   8/  19) | 0,44444 | R-2-HAS_SYN | 
| 0,74286 (  52/  70) | 1,00000 (   9/   9) | 0,33333 (   9/  27) | 0,50000 | R-2-HAS_ANT | 
| 0,33333 (   1/   3) | 1,00000 (   1/   1) | 0,33333 (   1/   3) | 0,50000 | R-2-HAS_HYPO/HAS_HYPER | 

Nur die Heuristiken 1-3 (alle anderen negativ annotiert):
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,83715 (1424/1701) | 0,91667 ( 275/ 300) | 0,52182 ( 275/ 527) | 0,66505 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,84615 ( 143/ 169) | 0,90000 (   9/  10) | 0,26471 (   9/  34) | 0,40909 | N-2-HAS_SYN | 
| 0,83333 ( 245/ 294) | 0,73684 (  14/  19) | 0,24138 (  14/  58) | 0,36364 | N-2-HAS_ANT | 
| 0,86316 (  82/  95) | 1,00000 (   3/   3) | 0,18750 (   3/  16) | 0,31579 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,79104 (  53/  67) | 0,55556 (   5/   9) | 0,33333 (   5/  15) | 0,41667 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,79747 ( 189/ 237) | 0,63636 (  14/  22) | 0,25926 (  14/  54) | 0,36842 | V-2-HAS_SYN | 
| 0,83258 ( 184/ 221) | 1,00000 (   2/   2) | 0,05128 (   2/  39) | 0,09756 | V-2-HAS_ANT | 
| 0,89333 (  67/  75) | NaN (   0/   0) | 0,00000 (   0/   8) | NaN | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,76623 (  59/  77) | 0,87500 (   7/   8) | 0,29167 (   7/  24) | 0,43750 | A-2-HAS_SYN | 
| 0,83750 (  67/  80) | 0,77778 (   7/   9) | 0,38889 (   7/  18) | 0,51852 | A-2-HAS_ANT | 
| 0,76000 (  19/  25) | 0,66667 (   2/   3) | 0,28571 (   2/   7) | 0,40000 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,80000 (  64/  80) | 1,00000 (   3/   3) | 0,15789 (   3/  19) | 0,27273 | R-2-HAS_SYN | 
| 0,65714 (  46/  70) | 1,00000 (   3/   3) | 0,11111 (   3/  27) | 0,20000 | R-2-HAS_ANT | 
| 0,33333 (   1/   3) | 1,00000 (   1/   1) | 0,33333 (   1/   3) | 0,50000 | R-2-HAS_HYPO/HAS_HYPER | 

FirstCandidateBaselineMethod (ohne Heuristiken):
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,83422 (1419/1701) | 0,77528 ( 345/ 445) | 0,65465 ( 345/ 527) | 0,70988 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,82840 ( 140/ 169) | 0,58621 (  17/  29) | 0,50000 (  17/  34) | 0,53968 | N-2-HAS_SYN | 
| 0,86735 ( 255/ 294) | 0,75676 (  28/  37) | 0,48276 (  28/  58) | 0,58947 | N-2-HAS_ANT | 
| 0,91579 (  87/  95) | 0,78571 (  11/  14) | 0,68750 (  11/  16) | 0,73333 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,86567 (  58/  67) | 0,71429 (  10/  14) | 0,66667 (  10/  15) | 0,68966 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,81435 ( 193/ 237) | 0,64706 (  22/  34) | 0,40741 (  22/  54) | 0,50000 | V-2-HAS_SYN | 
| 0,80090 ( 177/ 221) | 0,41935 (  13/  31) | 0,33333 (  13/  39) | 0,37143 | V-2-HAS_ANT | 
| 0,86667 (  65/  75) | 0,25000 (   1/   4) | 0,12500 (   1/   8) | 0,16667 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,76623 (  59/  77) | 0,68750 (  11/  16) | 0,45833 (  11/  24) | 0,55000 | A-2-HAS_SYN | 
| 0,73750 (  59/  80) | 0,41176 (   7/  17) | 0,38889 (   7/  18) | 0,40000 | A-2-HAS_ANT | 
| 0,76000 (  19/  25) | 0,57143 (   4/   7) | 0,57143 (   4/   7) | 0,57143 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,70000 (  56/  80) | 0,33333 (   5/  15) | 0,26316 (   5/  19) | 0,29412 | R-2-HAS_SYN | 
| 0,62857 (  44/  70) | 0,52941 (   9/  17) | 0,33333 (   9/  27) | 0,40909 | R-2-HAS_ANT | 
| 0,66667 (   2/   3) | 1,00000 (   2/   2) | 0,66667 (   2/   3) | 0,80000 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, ohne Heuristiken, mit Bonus 1, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,78895 (1342/1701) | 0,62463 ( 421/ 674) | 0,79886 ( 421/ 527) | 0,70108 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,80473 ( 136/ 169) | 0,50943 (  27/  53) | 0,79412 (  27/  34) | 0,62069 | N-2-HAS_SYN | 
| 0,86395 ( 254/ 294) | 0,66071 (  37/  56) | 0,63793 (  37/  58) | 0,64912 | N-2-HAS_ANT | 
| 0,74737 (  71/  95) | 0,38889 (  14/  36) | 0,87500 (  14/  16) | 0,53846 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,70149 (  47/  67) | 0,41379 (  12/  29) | 0,80000 (  12/  15) | 0,54545 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,66667 ( 158/ 237) | 0,37374 (  37/  99) | 0,68519 (  37/  54) | 0,48366 | V-2-HAS_SYN | 
| 0,76923 ( 170/ 221) | 0,40625 (  26/  64) | 0,66667 (  26/  39) | 0,50485 | V-2-HAS_ANT | 
| 0,85333 (  64/  75) | 0,33333 (   3/   9) | 0,37500 (   3/   8) | 0,35294 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,71429 (  55/  77) | 0,53125 (  17/  32) | 0,70833 (  17/  24) | 0,60714 | A-2-HAS_SYN | 
| 0,76250 (  61/  80) | 0,47368 (   9/  19) | 0,50000 (   9/  18) | 0,48649 | A-2-HAS_ANT | 
| 0,64000 (  16/  25) | 0,42857 (   6/  14) | 0,85714 (   6/   7) | 0,57143 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,65000 (  52/  80) | 0,34483 (  10/  29) | 0,52632 (  10/  19) | 0,41667 | R-2-HAS_SYN | 
| 0,72857 (  51/  70) | 0,66667 (  16/  24) | 0,59259 (  16/  27) | 0,62745 | R-2-HAS_ANT | 
| 0,66667 (   2/   3) | 1,00000 (   2/   2) | 0,66667 (   2/   3) | 0,80000 | R-2-HAS_HYPO/HAS_HYPER | 

Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.2: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,86302 (1468/1701) | 0,85507 ( 354/ 414) | 0,67173 ( 354/ 527) | 0,75239 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,89349 ( 151/ 169) | 0,80769 (  21/  26) | 0,61765 (  21/  34) | 0,70000 | N-2-HAS_SYN | 
| 0,87415 ( 257/ 294) | 0,81818 (  27/  33) | 0,46552 (  27/  58) | 0,59341 | N-2-HAS_ANT | 
| 0,86316 (  82/  95) | 0,61538 (   8/  13) | 0,50000 (   8/  16) | 0,55172 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,83582 (  56/  67) | 0,62500 (  10/  16) | 0,66667 (  10/  15) | 0,64516 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,79325 ( 188/ 237) | 0,54386 (  31/  57) | 0,57407 (  31/  54) | 0,55856 | V-2-HAS_SYN | 
| 0,86425 ( 191/ 221) | 0,84615 (  11/  13) | 0,28205 (  11/  39) | 0,42308 | V-2-HAS_ANT | 
| 0,90667 (  68/  75) | 1,00000 (   1/   1) | 0,12500 (   1/   8) | 0,22222 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,83117 (  64/  77) | 0,92308 (  12/  13) | 0,50000 (  12/  24) | 0,64865 | A-2-HAS_SYN | 
| 0,85000 (  68/  80) | 0,80000 (   8/  10) | 0,44444 (   8/  18) | 0,57143 | A-2-HAS_ANT | 
| 0,84000 (  21/  25) | 0,71429 (   5/   7) | 0,71429 (   5/   7) | 0,71429 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,81250 (  65/  80) | 0,75000 (   6/   8) | 0,31579 (   6/  19) | 0,44444 | R-2-HAS_SYN | 
| 0,71429 (  50/  70) | 1,00000 (   7/   7) | 0,25926 (   7/  27) | 0,41176 | R-2-HAS_ANT | 
| 0,66667 (   2/   3) | 1,00000 (   2/   2) | 0,66667 (   2/   3) | 0,80000 | R-2-HAS_HYPO/HAS_HYPER | 

Zugehörige Visualisierung (Veränderung der Maße Accuracy, Precision, Recall, F-Measure mit steigendem Schwellenwert):<br />
<img src="%ATTACHURLPATH%/threshold.png" alt="threshold.png" width="800" height="600" />

Die Ergebnisse mit dem CosineComparator (RelatednessMethod) liegen jeweils leicht unter den Werten von Lesk. Hier CosineComparator mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.03:
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,84245 (1433/1701) | 0,76056 ( 378/ 497) | 0,71727 ( 378/ 527) | 0,73828 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,88757 ( 150/ 169) | 0,72727 (  24/  33) | 0,70588 (  24/  34) | 0,71642 | N-2-HAS_SYN | 
| 0,87075 ( 256/ 294) | 0,76316 (  29/  38) | 0,50000 (  29/  58) | 0,60417 | N-2-HAS_ANT | 
| 0,80000 (  76/  95) | 0,42105 (   8/  19) | 0,50000 (   8/  16) | 0,45714 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,79104 (  53/  67) | 0,52632 (  10/  19) | 0,66667 (  10/  15) | 0,58824 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,72996 ( 173/ 237) | 0,43590 (  34/  78) | 0,62963 (  34/  54) | 0,51515 | V-2-HAS_SYN | 
| 0,83710 ( 185/ 221) | 0,54286 (  19/  35) | 0,48718 (  19/  39) | 0,51351 | V-2-HAS_ANT | 
| 0,90667 (  68/  75) | 1,00000 (   1/   1) | 0,12500 (   1/   8) | 0,22222 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,76623 (  59/  77) | 0,63636 (  14/  22) | 0,58333 (  14/  24) | 0,60870 | A-2-HAS_SYN | 
| 0,85000 (  68/  80) | 0,80000 (   8/  10) | 0,44444 (   8/  18) | 0,57143 | A-2-HAS_ANT | 
| 0,80000 (  20/  25) | 0,62500 (   5/   8) | 0,71429 (   5/   7) | 0,66667 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,80000 (  64/  80) | 0,61538 (   8/  13) | 0,42105 (   8/  19) | 0,50000 | R-2-HAS_SYN | 
| 0,77143 (  54/  70) | 1,00000 (  11/  11) | 0,40741 (  11/  27) | 0,57895 | R-2-HAS_ANT | 
| 0,66667 (   2/   3) | 1,00000 (   2/   2) | 0,66667 (   2/   3) | 0,80000 | R-2-HAS_HYPO/HAS_HYPER | 

Die Ergebnisse mit ESA mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.005:
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,83892 (1427/1701) | 0,72875 ( 403/ 553) | 0,76471 ( 403/ 527) | 0,74630 | ALL | 
| 0,92593 (  25/  27) | 0,92593 (  25/  27) | 1,00000 (  25/  25) | 0,96154 | N-1-HAS_SYN | 
| 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 (  30/  30) | 1,00000 | N-1-HAS_ANT | 
| 0,92857 (  13/  14) | 0,92857 (  13/  14) | 1,00000 (  13/  13) | 0,96296 | N-1-HAS_HYPO/HAS_HYPER | 
| 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 (   9/   9) | 1,00000 | N-1-HAS_MERO/HAS_HOLO | 
| 0,84024 ( 142/ 169) | 0,57778 (  26/  45) | 0,76471 (  26/  34) | 0,65823 | N-2-HAS_SYN | 
| 0,85714 ( 252/ 294) | 0,66000 (  33/  50) | 0,56897 (  33/  58) | 0,61111 | N-2-HAS_ANT | 
| 0,87368 (  83/  95) | 0,61111 (  11/  18) | 0,68750 (  11/  16) | 0,64706 | N-2-HAS_HYPO/HAS_HYPER | 
| 0,80597 (  54/  67) | 0,54545 (  12/  22) | 0,80000 (  12/  15) | 0,64865 | N-2-HAS_MERO/HAS_HOLO | 
| 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 (  28/  28) | 1,00000 | V-1-HAS_SYN | 
| 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 (  29/  29) | 1,00000 | V-1-HAS_ANT | 
| 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 (   1/   1) | 1,00000 | V-1-HAS_HYPO/HAS_HYPER | 
| 0,80591 ( 191/ 237) | 0,56452 (  35/  62) | 0,64815 (  35/  54) | 0,60345 | V-2-HAS_SYN | 
| 0,81448 ( 180/ 221) | 0,47059 (  16/  34) | 0,41026 (  16/  39) | 0,43836 | V-2-HAS_ANT | 
| 0,86667 (  65/  75) | 0,25000 (   1/   4) | 0,12500 (   1/   8) | 0,16667 | V-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 (  14/  14) | 1,00000 | A-1-HAS_SYN | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | A-1-HAS_ANT | 
| 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 (   7/   7) | 1,00000 | A-1-HAS_HYPO/HAS_HYPER | 
| 0,75325 (  58/  77) | 0,58621 (  17/  29) | 0,70833 (  17/  24) | 0,64151 | A-2-HAS_SYN | 
| 0,82500 (  66/  80) | 0,57692 (  15/  26) | 0,83333 (  15/  18) | 0,68182 | A-2-HAS_ANT | 
| 0,76000 (  19/  25) | 0,55556 (   5/   9) | 0,71429 (   5/   7) | 0,62500 | A-2-HAS_HYPO/HAS_HYPER | 
| 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 (  16/  16) | 1,00000 | R-1-HAS_SYN | 
| 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 (  15/  15) | 1,00000 | R-1-HAS_ANT | 
| 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 (   2/   2) | 1,00000 | R-1-HAS_HYPO/HAS_HYPER | 
| 0,76250 (  61/  80) | 0,50000 (  11/  22) | 0,57895 (  11/  19) | 0,53659 | R-2-HAS_SYN | 
| 0,70000 (  49/  70) | 0,63636 (  14/  22) | 0,51852 (  14/  27) | 0,57143 | R-2-HAS_ANT | 
| 0,66667 (   2/   3) | 1,00000 (   2/   2) | 0,66667 (   2/   3) | 0,80000 | R-2-HAS_HYPO/HAS_HYPER | 

---+++ Experimente auf dem multilingualen Datensatz (Englisch --> Deutsch):
Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,78713 ( 477/ 606) | 0,60550 ( 132/ 218) | 0,75429 ( 132/ 175) | 0,67176 | ALL | 
| 0,94118 (  16/  17) | 0,94118 (  16/  17) | 1,00000 (  16/  16) | 0,96970 | N-1 | 
| 0,76471 (  26/  34) | 0,63636 (  14/  22) | 1,00000 (  14/  14) | 0,77778 | N-2 | 
| 0,66667 (  34/  51) | 0,41176 (   7/  17) | 0,50000 (   7/  14) | 0,45161 | N-3 | 
| 0,85321 (  93/ 109) | 0,41176 (   7/  17) | 0,53846 (   7/  13) | 0,46667 | N-4 | 
| 0,94118 (  16/  17) | 0,94118 (  16/  17) | 1,00000 (  16/  16) | 0,96970 | V-1 | 
| 0,61765 (  21/  34) | 0,52632 (  10/  19) | 0,71429 (  10/  14) | 0,60606 | V-2 | 
| 0,72917 (  35/  48) | 0,47059 (   8/  17) | 0,66667 (   8/  12) | 0,55172 | V-3 | 
| 0,82653 (  81/  98) | 0,35294 (   6/  17) | 0,50000 (   6/  12) | 0,41379 | V-4 | 
| 1,00000 (  17/  17) | 1,00000 (  17/  17) | 1,00000 (  17/  17) | 1,00000 | A-1 | 
| 0,61765 (  21/  34) | 0,58333 (  14/  24) | 0,82353 (  14/  17) | 0,68293 | A-2 | 
| 0,68627 (  35/  51) | 0,52941 (   9/  17) | 0,52941 (   9/  17) | 0,52941 | A-3 | 
| 0,85417 (  82/  96) | 0,47059 (   8/  17) | 0,61538 (   8/  13) | 0,53333 | A-4 | 

---+++ Experimente auf dem multilingualen Datensatz (Deutsch--> Englisch):
Lesk (set of words), normalisiert auf Werte zwischen 0 und 1, mit Heuristiken 1-3, mit Bonus 1, mit trainiertem Schwellenwert 0.005: 
| *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Gruppe* |
| 0,76067 ( 499/ 656) | 0,56940 ( 160/ 281) | 0,81633 ( 160/ 196) | 0,67086 | ALL | 
| 0,94118 (  16/  17) | 0,94118 (  16/  17) | 1,00000 (  16/  16) | 0,96970 | N-1 | 
| 0,67647 (  23/  34) | 0,57143 (  12/  21) | 0,85714 (  12/  14) | 0,68571 | N-2 | 
| 0,74510 (  38/  51) | 0,55172 (  16/  29) | 1,00000 (  16/  16) | 0,71111 | N-3 | 
| 0,79798 (  79/  99) | 0,46154 (  12/  26) | 0,66667 (  12/  18) | 0,54545 | N-4 | 
| 0,82353 (  14/  17) | 0,82353 (  14/  17) | 1,00000 (  14/  14) | 0,90323 | V-1 | 
| 0,70588 (  24/  34) | 0,61905 (  13/  21) | 0,86667 (  13/  15) | 0,72222 | V-2 | 
| 0,68627 (  35/  51) | 0,65217 (  15/  23) | 0,65217 (  15/  23) | 0,65217 | V-3 | 
| 0,78519 ( 106/ 135) | 0,35294 (  12/  34) | 0,63158 (  12/  19) | 0,45283 | V-4 | 
| 0,88235 (  15/  17) | 0,88235 (  15/  17) | 1,00000 (  15/  15) | 0,93750 | A-1 | 
| 0,70588 (  24/  34) | 0,63158 (  12/  19) | 0,80000 (  12/  15) | 0,70588 | A-2 | 
| 0,72549 (  37/  51) | 0,54167 (  13/  24) | 0,81250 (  13/  16) | 0,65000 | A-3 | 
| 0,75862 (  88/ 116) | 0,30303 (  10/  33) | 0,66667 (  10/  15) | 0,41667 | A-4 | 

---++ Weitere Versuche:
   * Anzahl der positiven Annotationen pro Instanz beschränken
   * Semantische Methoden testen (z.B. PPR)
   * Weitere Relatedness Methoden testen

---++ Current Schedule

%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "1" }%
| *Task* | *Date* | *Hours* | *Remarks* |
| - | 28.03.2011 | 0 | Project Plan (!ChM) |
| Part 1 + Meeting | 11.04.2011 | 1 | |
| Datenbank aufsetzen + Workspace anlegen | 11.04.2011 | 0.75 | |
| In Code einlesen | 12.04.2011 | 0.75 | |
| Software testen, Abläufe bei Datenerzeugung nachvollziehen, Wiktionary genauer ansehen | 15.04.2011 | 2.5 | |
| Daten in Datenbank analysieren, Gedanken über Erstellung eines GoldStandards machen | 24.04.2011 | 2.5 | |
| Random und MFS Evaluationsdaten für WordNet-Wiktionary Alignment erstellen | 28.04.2011 | 1.5 | |
| Meeting | 29.04.2011 | 0.5 | |
| Erstellen einer Statistik über Verteilung von POS, Kandidaten, Relationen in englischer Wiktionary und Bewertung der Daten | 01.05.2011 | 2 | |
| Programmaufbau überlegen, mit Umsetzung beginnen | 03.05.2011 | 3 | |
| Statistik über Labels erstellen, analysieren, Programmieren: Code um Samples aus DB zu extrahieren soweit fertig, Textfile wird erstellt, Einbinden in vorgegebenen Code, Erstellung eines ersten (unaligned) GoldStandards, Analyse der Daten und Feststellung von Problemen | 04.05.2011 | 3.5 | |
| Automatische Erstellung einer Statistik über erstellten GoldStandard programmieren | 07.05.2011 | 1.5 | |
| Weitere Datenbank (en_ws) aufsetzen, de und en_ws Datenbanken ansehen und integrieren, Statistik erweitern | 14.05.2011 | 2.5 | |
| Neue Daten importiert, Datensätze generiert | 31.05.2011 | 1 | |
| Deutschen GoldStandard annotiert (Teil 1) | 07.06.2011 | 1.5 | |
| Deutschen GoldStandard annotiert (Teil 2) | 16.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 1) | 26.06.2011 | 1.5 | |
| Englischen GoldStandard annotiert (Teil 2) | 27.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 3) | 03.08.2011 | 2 | |
| Meeting | 23.08.2011 | 0.5 | |
| Code auschecken und einlesen | 04.09.2011 | 2 | |
| Codeanalyse: Überprüfung der vorhandenen Evaluationsmethode und Feststellung notwendiger Änderungen | 12.09.2011 | 2 | |
| Evaluation und Disambiguierung korrigieren und an unsere Bedürfnisse anpassen: Mehrere positive Annotation pro Instanz, Disambiguierung auf Basis eines Thresholds, Evaluation entsprechend Paaren (nicht Instanzen) | 13.09.2011 | 2,5 | |
| Methoden (z.B. Lesk) testen, Schwachstellen identifizieren | 13.09.2011 | 1,5 | |
| Über Heuristiken nachdenken, eine erste Heuristik implementieren, Nutzen der Heuristik evaluieren | 15.09.2011 | 4 | |
| TreeTagger & StopWords installiert | 18.09.2011 | 0.5 | |
| Heuristiken 2 und 3 implementiert und getestet, TreeTagger weiter eingebunden und getestet | 19.09.2011 | 2 | |
| Schweren Bug bei Kandidatenextraktion gefunden und behoben, Evaluationsdaten für Heuristiken korrigiert | 19.09.2011 | 1 | |
| Schwellenwerttraining + Visualisierung der Ergebnisse implementiert | 05.10.2011 | 1.5 | |
| Schwellenwerttraining besser eingebunden, RelatednessMethod testen, Instanzen mit Folds versehen (für spätere CrossValidation) | 07.10.2011 | 3.5 | |
| Experimente mit verschiedenen Methoden durchführen und Ergebnisse festhalten | 08.10.2011 | 1 | |
| Weitere Experimente auf englischem Datensatz durchführen und festhalten, Fehler im GoldStandard identifizieren | 09.10.2011 | 2 | |
| In Bing Translation API einlesen, erste Version programmieren (siehe Attachments) | 09.10.2011 | 2.5 | |
| Tabellen-Schemata für Übersetzungslinks und Vorgehensweise planen | 26.10.2011 | 1 | |
| Berkeley DB Files zum Laufen gebracht und getestet, Tabellenschemata und Vorgehensweise genauer beschreiben | 30.10.2011 | 2.5 | |
| Code für Übersetzung von Sense-Tabellen geschrieben, getestet, überarbeitet und Übersetzung der deutschen sense Tabelle gestartet | 05.11.2011 | 3.5 | |
| wkten1104_sense_translation fertig übersetzen, Probleme mit URLs in zu übersetzendem Text beheben | 06.11.2011 | 2 | |
| Code zum Parsen von Übersetzungslinks schreiben, Testen, Ausführen | 07.11.2011 | 2.5 | |
| Fehler bei Übersetzung beheben, examples nachtragen (übersetzen), mit Übersetzung von wkten1104_sense beginnen | 08.11.2011 | 2 | |
| Code schreiben, um die target_term_ids in den _translation Tabellen aus den Tabellen der Zielsprache herauszusuchen, Ausführen, Tabellen mit korrekten ids exportieren und hochladen | 11.11.2011 | 1.5 | |
| Englische sense Tabelle vollständig übersetzt | 29.11.2011 | 0.5 | |
| Mit ESA befassen, Code so umschreiben, dass multilinguale Experimente möglich, ein erstes Exeriment mit englisch-deutschem Datensatz durchführen | 11.12.2011 | 2 | |
| Experimente mit ESA und auf multilingualen Datensätzen | 21.12.2011 | 2 | |
| *Summe* | | %CALC{"$SUM( $ABOVE() )"}% | |
| *Soll* | | 120 | bis Ende März 2012 |
<nop>

-- Main.ChristianMeyer - 2011-03-28

%META:FILEATTACHMENT{name="heuristik1.png" attachment="heuristik1.png" attr="h" comment="Heuristik 1" date="1316115427" path="heuristik1.png" size="36857" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="threshold.png" attachment="threshold.png" attr="h" comment="" date="1318159067" path="threshold.png" size="29312" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="bing-api-translate-java-0.1.jar" attachment="bing-api-translate-java-0.1.jar" attr="" comment="Erste Version der BingTranslationAPI zum Übersetzen von deutschen/englischen Texten" date="1318185111" path="bing-api-translate-java-0.1.jar" size="6078" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="wkten1104_sense_translation.sql" attachment="wkten1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wktde1104_sense" date="1320750257" path="wkten1104_sense_translation.sql" size="19659146" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wkten1104_translation.sql" attachment="wkten1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027517" path="wkten1104_translation.sql" size="3520345" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_translation.sql" attachment="wktde1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027587" path="wktde1104_translation.sql" size="2674543" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_sense_translation.sql" attachment="wktde1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wkten1104_sense" date="1322565057" path="wktde1104_sense_translation.sql" size="73521161" user="ChristianKirschner" version="1"}%
