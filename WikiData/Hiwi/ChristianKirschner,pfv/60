%META:TOPICINFO{author="ChristianKirschner" date="1326394175" format="1.1" version="60"}%
%META:TOPICPARENT{name="WebHome"}%
<!--
   * Set ALLOWTOPICVIEW = Main.ChristianKirschner,Main.UkpGroup
   * Set ALLOWTOPICCHANGE = Main.ChristianKirschner,Main.UkpGroup
//-->

---+ Christian Kirschner's Work

---++ Project Plan (tentative)

   * *<span class="green">Part 1</span>*
      * <span class="green">Read task description (CICLing sec. 4; IGI sec. rel. anchoring)</span>
      * <span class="green">Read annotation guidebook</span>
      * <span class="green">Familiarize with task</span>
   * Part 2
      * <span class="green">Look into Wiktionary; structure and API access</span>
      * <span class="green">Which dimensions are necessary/important to consider for a dataset?
         * This will be a core question to be discussed</span>
      * <span class="green">Include Wikisaurus?</span>
      * <span class="green">Develop a well-balanced reference dataset for the English relation anchoring task (maybe also for the German?) [with !ChM]</span>
      * Update the annotation guidebook
   * Part 3
      * Annotate the data [@ChM find additional annotator(s)]
      * Evaluate the dataset [with !ChM]
   * Part 4
      * <span class="green">@ChM Update the anchoring framework</span>
      * <span class="green">Get the framework to work, familiarize with code</span>
      * Run the existing methods with old and new data
      * Analyze errors
         * What do we need to solve?
         * What can be improved?
            * This will be a core question to be discussed
   * Part 5
      * Try and develop heuristics (come up with fancy names for them)
         * existing return relation
         * target gloss contains source word
         * matching domain (@ChM: further think about that)
      * Try and develop new methods, ideas:
         * PPR?
         * Graph-based method (Navid?)
         * PROX?
         * Milne/Witten?
   * Part 6
      * @ChM: get cross-lingual dataset ready
      * Select translation API and translate glosses
      * Experiments on cross-lingual dataset

---++ GoldStandard Generation

   * On the one hand the GoldStandard should build up in a way that weaknesses of disambiguation algorithms can be detected, on the other hand it should be quite representative. Therefore we are going to use the following criteria:
      * Part of speech
      * Relations
      * Number of candidates
      * Labels

---++ Heuristics

   1 Wenn ein Sense eine Relation (z.B. Hyperonym) auf einen anderen Artikel hat und einer der Kandidaten wiederum eine Relation (z.B. Hyponym) zurück zum Ausgangsartikel besitzt, so ist dieser Kandidat höchstwahrscheinlich positiv zu annotieren. Dies funktioniert mit Synonym-Synonym, Antonym-Antonym, Hyperonym-Hyponym und Hyponym-Hyperonym Relationspaaren. Auf dem deutschen Datensatz ist die Heuristik bei 11,3% der Paare anwendbar und hat eine Precision von 88,4%. Auf dem englischen Datensatz ist die Heuristik bei 3,3% der Paare anwendbar und hat eine Precision von 85,7%. 
   2 Wenn eine Instanz nur einen möglichen Kandidaten hat, wird dieser positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 21,6% der Paare anwendbar und hat eine Precision von 95,1%. Auf dem englischen Datensatz ist die Heuristik bei 12,8% der Paare anwendbar und hat eine Precision von 98,6%. 
   3 Wenn ein Kandidat im Gloss das Lemma der Instanz enthält, wird das Paar positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 1,5% der Paare anwendbar und hat eine Precision von 88,9%. Auf dem englischen Datensatz ist die Heuristik bei 4,6% der Paare anwendbar und hat eine Precision von 81,0%. 

 * Heuristik 1: <br />
     <img src="%ATTACHURLPATH%/heuristik1.png" alt="heuristik1.png" width="200" height="175" />

---++ Boni

   1 Der Score des ersten Kandidaten jeder Instanz erhält einen Bonus indem der berechnete Score verdoppelt wird (+ einer kleinen Konstante 0.01, damit er nicht bei 0 verbleibt). Die FirstCandidateBaseline hat alleine eine Precision von 78,6% (deutscher Datensatz) bzw. 77,53% (englischer Datensatz).

---++ Results
Im folgenden werden die wichtigsten Ergebnisse dargestellt. Alle Werte im Detail sind im Topic [[https://maggie.tk.informatik.tu-darmstadt.de/wiki/bin/view/Hiwi/Experiments][Experiments]] zu finden.

---+++ Übersicht der Ergebnisse auf dem deutschen Datensatz:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *PureLesk* | 0,64730 ( 791/1222) | 0,75096 ( 196/ 261) | 0,34875 ( 196/ 562) | 0,47631 | 0.0001 |
| *Random/PureLesk* | 0,45990 ( 562/1222) | 0,45990 ( 562/1222) | 1,00000 ( 562/ 562) | 0,63004 | 0.0 |
| *FirstCand* | 0,79133 ( 967/1222) | 0,78585 ( 422/ 537) | 0,75089 ( 422/ 562) | 0,76797 | - |
| *H123* | 0,76187 ( 931/1222) | 0,91437 ( 299/ 327) | 0,53203 ( 299/ 562) | 0,67267 | - |
| *LeskH123* | 0,76923 ( 940/1222) | 0,80973 ( 366/ 452) | 0,65125 ( 366/ 562) | 0,72189 | 0.005 |
| *LeskB1* | 0,78478 ( 959/1222) | 0,73618 ( 466/ 633) | 0,82918 ( 466/ 562) | 0,77992 | 0.005 |
| *LeskH23B1* |  0,78887 ( 964/1222) | 0,73750 ( 472/ 640) | 0,83986 ( 472/ 562) | *0,78536* | 0.005 |
| *LeskH123B1* | 0,78560 ( 960/1222) | 0,73006 ( 476/ 652) | 0,84698 ( 476/ 562) | 0,78418 | 0.005 |
| *CosH123B1* | 0,78396 ( 958/1222) | 0,72923 ( 474/ 650) | 0,84342 ( 474/ 562) | 0,78218 | 0.005 |

Am besten schneidet die Lesk-Methode in Verbindung mit den Heuristiken 2, 3 und Bonus 1 ab. Heuristik 1 verschlechtert das Ergebnis hier geringfügig, aber nicht signifikant. Die Lesk Methode alleine erreicht einen sehr schlechten F-Measure Wert, allerdings eine akzeptable Precision, sodass die Methode in Verbindung mit den Heuristiken sinnvoll ist. 

*Betrachtung der einzelnen Features (LeskH23B1):*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,80840 ( 308/ 381) | 0,79293 ( 157/ 198) | 0,83069 ( 157/ 189) | 0,81137 |
| *V* | 0,79588 ( 386/ 485) | 0,70563 ( 163/ 231) | 0,84021 ( 163/ 194) | 0,76706 |
| *A* | 0,74286 ( 130/ 175) | 0,70940 (  83/ 117) | 0,88298 (  83/  94) | 0,78673 |
| *R* | 0,77348 ( 140/ 181) | 0,73404 (  69/  94) | 0,81176 (  69/  85) | 0,77095 |
| *1* | 0,95038 ( 249/ 262) | 0,95402 ( 249/ 261) | 0,99600 ( 249/ 250) | 0,97456 |
| *2* | 0,74479 ( 715/ 960) | 0,58839 ( 223/ 379) | 0,71474 ( 223/ 312) | 0,64544 |
| *HAS_SYN* | 0,74302 ( 266/ 358) | 0,71560 ( 156/ 218) | 0,83871 ( 156/ 186) | 0,77228 |
| *HAS_ANT* | 0,79621 ( 336/ 422) | 0,75622 ( 152/ 201) | 0,80423 ( 152/ 189) | 0,77949 |
| *HAS_HYPO/HAS_HYPER* | 0,81900 ( 362/ 442) | 0,74208 ( 164/ 221) | 0,87701 ( 164/ 187) | 0,80392 |

Bei Instanzen mit nur einem Kandidaten ist kaum noch Verbesserungspotenzial vorhanden (diese werden durch Heuristik 2 grundsätzlich positiv annotiert). Deutliche Schwächen sind allerdings bei den Instanzen mit 2 oder mehr Kandidaten zu erkennen. Insbesondere die Precision ist hier verbesserungswürdig. Eventuell ist eine Begrenzung der Anzahl an Zuweisungen pro Instanz zielführend.

*Ergebnisse mit Begrenzung der Anzahl an Zuweisungen pro Instanz auf die Kandidaten mit den höchsten Scores oberhalb des Schwellenwerts:*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *Random* | 0,67840 ( 829/1222) | 0,65736 ( 353/ 537) | 0,62811 ( 353/ 562) | 0,64240 | 0,0 |
| *PureLesk* | 0,62520 ( 764/1222) | 0,55640 ( 513/ 922) | 0,91281 ( 513/ 562) | 0,69137 | 0,0 |
| *FirstCand* | 0,79133 ( 967/1222) | 0,78585 ( 422/ 537) | 0,75089 ( 422/ 562) | 0,76797 | - |
| *H123* | 0,76187 ( 931/1222) | 0,91437 ( 299/ 327) | 0,53203 ( 299/ 562) | 0,67267 | - |
| *LeskH123* | 0,77823 ( 951/1222) | 0,85926 ( 348/ 405) | 0,61922 ( 348/ 562) | 0,71975 | 0,005 |
| *LeskB1*| 0,80933 ( 989/1222) | 0,80633 ( 433/ 537) | 0,77046 ( 433/ 562) | 0,78799 | 0,0 |
| *LeskH23B1* | 0,81178 ( 992/1222) | 0,80855 ( 435/ 538) | 0,77402 ( 435/ 562) | 0,79091 | 0,0 |
| *LeskH123B1* | 0,81342 ( 994/1222) | 0,80699 ( 439/ 544) | 0,78114 ( 439/ 562) | *0,79385* | 0,0 |
| *CosH123B1* | 0,81015 ( 990/1222) | 0,80331 ( 437/ 544) | 0,77758 ( 437/ 562) | 0,79024 | 0,0 |

Die Begrenzung der Zuweisungen bringt in der besten Konfiguration (LeskH123B1) eine deutliche Verbesserung von 78,5% auf 79,4%. Die Betrachtung der einzelnen Features ergibt folgendes Bild:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,79790 ( 304/ 381) | 0,82558 ( 142/ 172) | 0,75132 ( 142/ 189) | 0,78670 |
| *V* | 0,84330 ( 409/ 485) | 0,80729 ( 155/ 192) | 0,79897 ( 155/ 194) | 0,80311 |
| *A* | 0,80000 ( 140/ 175) | 0,80412 (  78/  97) | 0,82979 (  78/  94) | 0,81675 |
| *R* | 0,77901 ( 141/ 181) | 0,77108 (  64/  83) | 0,75294 (  64/  85) | 0,76190 |
| *1* | 0,95038 ( 249/ 262) | 0,95402 ( 249/ 261) | 0,99600 ( 249/ 250) | 0,97456 |
| *2* | 0,77604 ( 745/ 960) | 0,67138 ( 190/ 283) | 0,60897 ( 190/ 312) | 0,63866 |
| *HAS_SYN* | 0,77095 ( 276/ 358) | 0,78571 ( 143/ 182) | 0,76882 ( 143/ 186) | 0,77717 |
| *HAS_ANT* | 0,81517 ( 344/ 422) | 0,81006 ( 145/ 179) | 0,76720 ( 145/ 189) | 0,78804 |
| *HAS_HYPO/HAS_HYPER* | 0,84615 ( 374/ 442) | 0,82514 ( 151/ 183) | 0,80749 ( 151/ 187) | 0,81622 |

Obwohl mit der Begrenzung der Assignments insgesamt eine Verbesserung der Ergebnisse erreicht wurde, ist der F-Measure Wert bei Instanzen mit 2 oder mehr Zuweisungen nach wie vor verbesserungsfähig. Zwar konnte hier die Precision um knapp 10% gesteigert werden, allerdings ist der Recall gleichzeitig um einen ähnlichen Wert gesunken. Während in der vorherigen Konfiguration also Instanzen mit mehreren Kandidaten zu viele Zuweisungen vorgenommen haben, werden nun zu wenige Kandidaten zugewiesen. Der Versuch die Anzahl der Zuweisungen auf die zwei höchsten Scores zu beschränken brachte keine signifikante Verbesserung. Auffällig ist zudem, dass sich nun nicht mehr Nomen, sondern Adjektive am besten klassifizieren lassen. 

---+++ Übersicht der Ergebnisse auf dem englischen Datensatz:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *Random* | 0,30982 ( 527/1701) | 0,30982 ( 527/1701) | 1,00000 ( 527/ 527) | 0,47307 | 0,0 |
| *PureLesk* | 0,75250 (1280/1701) | 0,62100 ( 272/ 438) | 0,51613 ( 272/ 527) | 0,56373 | 0,005 |
| *FirstCand* | 0,83422 (1419/1701) | 0,77528 ( 345/ 445) | 0,65465 ( 345/ 527) | 0,70988 | - |
| *H123* | 0,83715 (1424/1701) | 0,91667 ( 275/ 300) | 0,52182 ( 275/ 527) | 0,66505 | - |
| *LeskH123* | 0,83539 (1421/1701) | 0,75569 ( 365/ 483) | 0,69260 ( 365/ 527) | 0,72277 | 0,125 |
| *LeskB1* | 0,78895 (1342/1701) | 0,62463 ( 421/ 674) | 0,79886 ( 421/ 527) | 0,70108 | 0,005 |
| *LeskH123B1* | 0,86302 (1468/1701) | 0,85507 ( 354/ 414) | 0,67173 ( 354/ 527) | *0,75239* | 0,2 |
| *CosH123B1* | 0,84245 (1433/1701) | 0,76056 ( 378/ 497) | 0,71727 ( 378/ 527) | 0,73828 | 0,03 |
| *ESAH123B1* | 0,83892 (1427/1701) | 0,72875 ( 403/ 553) | 0,76471 ( 403/ 527) | 0,74630 | 0,005 |

Am besten schneidet die Lesk-Methode in Verbindung mit den Heuristiken 1-3 und dem Bonus 1 ab. Die Lesk Methode alleine führt zu sehr schlechten Ergebnissen, auch die Precision ist hier nicht sonderlich gut. 

*Betrachtung der einzelnen Features (LeskH123B1):*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,88369 ( 623/ 705) | 0,85119 ( 143/ 168) | 0,71500 ( 143/ 200) | 0,77717 |
| *V* | 0,85448 ( 505/ 591) | 0,78295 ( 101/ 129) | 0,63522 ( 101/ 159) | 0,70139 |
| *A* | 0,86758 ( 190/ 219) | 0,92537 (  62/  67) | 0,72093 (  62/  86) | 0,81046 |
| *R* | 0,80645 ( 150/ 186) | 0,96000 (  48/  50) | 0,58537 (  48/  82) | 0,72727 |
| *1* | 0,98558 ( 205/ 208) | 0,98558 ( 205/ 208) | 1,00000 ( 205/ 205) | 0,99274 |
| *2* | 0,84595 (1263/1493) | 0,72330 ( 149/ 206) | 0,46273 ( 149/ 322) | 0,56439 |
| *HAS_SYN* | 0,85031 ( 551/ 648) | 0,80952 ( 153/ 189) | 0,71495 ( 153/ 214) | 0,75931 |
| *HAS_ANT* | 0,86887 ( 656/ 755) | 0,93464 ( 143/ 153) | 0,61638 ( 143/ 232) | 0,74286 |
| *HAS_HYPO/HAS_HYPER* | 0,88288 ( 196/ 222) | 0,82979 (  39/  47) | 0,68421 (  39/  57) | 0,75000 |
| *HAS_MERO/HAS_HOLO* | 0,85526 (  65/  76) | 0,76000 (  19/  25) | 0,79167 (  19/  24) | 0,77551 |

Instanzen mit nur einem Kandidaten schneiden bereits optimal ab, bei mehreren Kandidaten sinkt das F-Measure auf einen sehr schlechten Wert von 56%. Der optimale Schwellenwert ist hier mit 0,2 deutlich über 0, worunter insbesondere der Recall leidet. Die Accuracy dagegen ist mit knapp 85% dagegen in einem akzeptablen Bereich. Zwischen den einzelnen Relationsarten ergeben sich kaum Unterschiede, bei den Wortarten schneiden Adjektive etwas besser, Verben etwas schlechter ab.

*Ergebnisse mit Begrenzung der Anzahl an Zuweisungen pro Instanz auf die Kandidaten mit den höchsten Scores oberhalb des Schwellenwerts:*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *Random* | 0,76720 (1305/1701) | 0,64719 ( 288/ 445) | 0,54649 ( 288/ 527) | 0,59259 | 0,0 |
| *PureLesk* | 0,73251 (1246/1701) | 0,54615 ( 426/ 780) | 0,80835 ( 426/ 527) | 0,65187 | 0,0 |
| *FirstCand* | 0,83422 (1419/1701) | 0,77528 ( 345/ 445) | 0,65465 ( 345/ 527) | 0,70988 | - |
| *H123* | 0,83715 (1424/1701) | 0,91667 ( 275/ 300) | 0,52182 ( 275/ 527) | 0,66505 | - |
| *LeskH123* | 0,85126 (1448/1701) | 0,81422 ( 355/ 436) | 0,67362 ( 355/ 527) | 0,73728 | 0,005 |
| *LeskB1* | 0,85655 (1457/1701) | 0,80562 ( 373/ 463) | 0,70778 ( 373/ 527) | 0,75354 | 0,0 |
| *LeskH123B1* | 0,86655 (1474/1701) | 0,81646 ( 387/ 474) | 0,73435 ( 387/ 527) | 0,77323 | 0,0 |
| *CosH123B1* | 0,86772 (1476/1701) | 0,82128 ( 386/ 470) | 0,73245 ( 386/ 527) | *0,77432* | 0,0 |

Durch die Beschränkung lässt sich das Ergebnis um gut 2% verbessern. Betrachtung der einzelnen Features (LeskH123B1):
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,88227 ( 622/ 705) | 0,82682 ( 148/ 179) | 0,74000 ( 148/ 200) | 0,78100 |
| *V* | 0,84433 ( 499/ 591) | 0,72789 ( 107/ 147) | 0,67296 ( 107/ 159) | 0,69935 |
| *A* | 0,87215 ( 191/ 219) | 0,86250 (  69/  80) | 0,80233 (  69/  86) | 0,83133 |
| *R* | 0,87097 ( 162/ 186) | 0,92647 (  63/  68) | 0,76829 (  63/  82) | 0,84000 |
| *1* | 0,98558 ( 205/ 208) | 0,98558 ( 205/ 208) | 1,00000 ( 205/ 205) | 0,99274 |
| *2* | 0,84997 (1269/1493) | 0,68421 ( 182/ 266) | 0,56522 ( 182/ 322) | 0,61905 |
| *HAS_SYN* | 0,84568 ( 548/ 648) | 0,79381 ( 154/ 194) | 0,71963 ( 154/ 214) | 0,75490 |
| *HAS_ANT* | 0,87682 ( 662/ 755) | 0,84236 ( 171/ 203) | 0,73707 ( 171/ 232) | 0,78621 |
| *HAS_HYPO/HAS_HYPER* | 0,89640 ( 199/ 222) | 0,82692 (  43/  52) | 0,75439 (  43/  57) | 0,78899 |
| *HAS_MERO/HAS_HOLO* | 0,85526 (  65/  76) | 0,76000 (  19/  25) | 0,79167 (  19/  24) | 0,77551 |

Das F-Measure bei Instanzen mit 2 oder mehr Kandidaten ist nun etwas besser, die anderen Werte haben sich kaum verändert. 

---+++ Fehleranalyse (Deutscher Datensatz):
*False Positives:* (siehe [[%ATTACHURL%/False_Positives_LeskH123B1Limit.xls][False_Positives_LeskH123B1Limit.xls]])
   * Alle False Positives haben gemeinsam, dass mindestens eine Heuristik, der Bonus oder Lesk falsch liegen
   * Bonus und Heuristik 2 betrachten den Inhalt überhaupt nicht. Es wäre wünschenswert diese statistischen Methoden zu ersetzen. Dafür müsste jedoch anstatt der Lesk Methode eine semantische Methode mit einem deutlich höheren Recall verwendet werden. 
   * Man könnte Instanzen nicht mehr automatisch zuweisen, wenn eine Heuristik anschlägt, sondern den Score ähnlich zum Bonussystem erhöhen. Dazu wären jedoch weitere Heuristiken notwendig. Außerdem würde sich die Anzahl der False Negatives vermutlich erhöhen. 

*False Negatives:* (siehe [[%ATTACHURL%/False_Negatives_LeskH123B1.xls][False_Negatives_LeskH123B1.xls]])
   * Alle False Negatives haben gemeinsam, dass keine der 3 Heuristiken und nicht der Bonus anschlägt. Außerdem findet die Lesk Methode keine übereinstimmenden Wörter
   * Ähnlichkeiten zu finden ist z.B. bei Antonymen sehr schwer, da Lesk nur gleiche Wörter, keine gegensätzlichen, erkennt (z.B. gucken vs. horchen oder aufmachen vs. zumachen). Semantische Methoden wären in der Lage dies festzustellen
   * Auch in anderen Fällen fehlt es an semantischen Methoden (z.B. Strauch vs. Strauchwerk oder hingeben vs. Hingabe)
   * Teilweise sind die Beschreibungen sehr kurz
   * Umkehrung von Heuristik 3 ist teilweise hilfreich, führt aber zu vielen False Positives und kommt somit nicht in Frage
   * Teilweise ist der GoldStandard auch fragwürdig bzw. ich würde 0 und 1 als korrekt ansehen

*Fazit:*
   * Es handelt sich um einen sehr schwierigen Task, viele Beispiele sind auch als Mensch nur schwer zu beurteilen
   * Die Lesk Methode hat einen sehr geringen Recall und weist zu viele Schwächen auf. Sie muss durch eine semantische Methode (z.B. PPR) ersetzt werden

---+++ Fehleranalyse (Englischer Datensatz):
*False  Positives:*
   * ...

*False Negatives:*
   * ...

*Fazit:*
   * 

---++ Weitere Versuche:
   * Anzahl der positiven Annotationen pro Instanz beschränken
   * Semantische Methoden testen (z.B. PPR)
   * Weitere Relatedness Methoden testen

---++ Current Schedule

%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "1" }%
| *Task* | *Date* | *Hours* | *Remarks* |
| - | 28.03.2011 | 0 | Project Plan (!ChM) |
| Part 1 + Meeting | 11.04.2011 | 1 | |
| Datenbank aufsetzen + Workspace anlegen | 11.04.2011 | 0.75 | |
| In Code einlesen | 12.04.2011 | 0.75 | |
| Software testen, Abläufe bei Datenerzeugung nachvollziehen, Wiktionary genauer ansehen | 15.04.2011 | 2.5 | |
| Daten in Datenbank analysieren, Gedanken über Erstellung eines GoldStandards machen | 24.04.2011 | 2.5 | |
| Random und MFS Evaluationsdaten für WordNet-Wiktionary Alignment erstellen | 28.04.2011 | 1.5 | |
| Meeting | 29.04.2011 | 0.5 | |
| Erstellen einer Statistik über Verteilung von POS, Kandidaten, Relationen in englischer Wiktionary und Bewertung der Daten | 01.05.2011 | 2 | |
| Programmaufbau überlegen, mit Umsetzung beginnen | 03.05.2011 | 3 | |
| Statistik über Labels erstellen, analysieren, Programmieren: Code um Samples aus DB zu extrahieren soweit fertig, Textfile wird erstellt, Einbinden in vorgegebenen Code, Erstellung eines ersten (unaligned) GoldStandards, Analyse der Daten und Feststellung von Problemen | 04.05.2011 | 3.5 | |
| Automatische Erstellung einer Statistik über erstellten GoldStandard programmieren | 07.05.2011 | 1.5 | |
| Weitere Datenbank (en_ws) aufsetzen, de und en_ws Datenbanken ansehen und integrieren, Statistik erweitern | 14.05.2011 | 2.5 | |
| Neue Daten importiert, Datensätze generiert | 31.05.2011 | 1 | |
| Deutschen GoldStandard annotiert (Teil 1) | 07.06.2011 | 1.5 | |
| Deutschen GoldStandard annotiert (Teil 2) | 16.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 1) | 26.06.2011 | 1.5 | |
| Englischen GoldStandard annotiert (Teil 2) | 27.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 3) | 03.08.2011 | 2 | |
| Meeting | 23.08.2011 | 0.5 | |
| Code auschecken und einlesen | 04.09.2011 | 2 | |
| Codeanalyse: Überprüfung der vorhandenen Evaluationsmethode und Feststellung notwendiger Änderungen | 12.09.2011 | 2 | |
| Evaluation und Disambiguierung korrigieren und an unsere Bedürfnisse anpassen: Mehrere positive Annotation pro Instanz, Disambiguierung auf Basis eines Thresholds, Evaluation entsprechend Paaren (nicht Instanzen) | 13.09.2011 | 2,5 | |
| Methoden (z.B. Lesk) testen, Schwachstellen identifizieren | 13.09.2011 | 1,5 | |
| Über Heuristiken nachdenken, eine erste Heuristik implementieren, Nutzen der Heuristik evaluieren | 15.09.2011 | 4 | |
| TreeTagger & StopWords installiert | 18.09.2011 | 0.5 | |
| Heuristiken 2 und 3 implementiert und getestet, TreeTagger weiter eingebunden und getestet | 19.09.2011 | 2 | |
| Schweren Bug bei Kandidatenextraktion gefunden und behoben, Evaluationsdaten für Heuristiken korrigiert | 19.09.2011 | 1 | |
| Schwellenwerttraining + Visualisierung der Ergebnisse implementiert | 05.10.2011 | 1.5 | |
| Schwellenwerttraining besser eingebunden, RelatednessMethod testen, Instanzen mit Folds versehen (für spätere CrossValidation) | 07.10.2011 | 3.5 | |
| Experimente mit verschiedenen Methoden durchführen und Ergebnisse festhalten | 08.10.2011 | 1 | |
| Weitere Experimente auf englischem Datensatz durchführen und festhalten, Fehler im GoldStandard identifizieren | 09.10.2011 | 2 | |
| In Bing Translation API einlesen, erste Version programmieren (siehe Attachments) | 09.10.2011 | 2.5 | |
| Tabellen-Schemata für Übersetzungslinks und Vorgehensweise planen | 26.10.2011 | 1 | |
| Berkeley DB Files zum Laufen gebracht und getestet, Tabellenschemata und Vorgehensweise genauer beschreiben | 30.10.2011 | 2.5 | |
| Code für Übersetzung von Sense-Tabellen geschrieben, getestet, überarbeitet und Übersetzung der deutschen sense Tabelle gestartet | 05.11.2011 | 3.5 | |
| wkten1104_sense_translation fertig übersetzen, Probleme mit URLs in zu übersetzendem Text beheben | 06.11.2011 | 2 | |
| Code zum Parsen von Übersetzungslinks schreiben, Testen, Ausführen | 07.11.2011 | 2.5 | |
| Fehler bei Übersetzung beheben, examples nachtragen (übersetzen), mit Übersetzung von wkten1104_sense beginnen | 08.11.2011 | 2 | |
| Code schreiben, um die target_term_ids in den _translation Tabellen aus den Tabellen der Zielsprache herauszusuchen, Ausführen, Tabellen mit korrekten ids exportieren und hochladen | 11.11.2011 | 1.5 | |
| Englische sense Tabelle vollständig übersetzt | 29.11.2011 | 0.5 | |
| Mit ESA befassen, Code so umschreiben, dass multilinguale Experimente möglich, ein erstes Exeriment mit englisch-deutschem Datensatz durchführen | 11.12.2011 | 2 | |
| Experimente mit ESA und auf multilingualen Datensätzen | 21.12.2011 | 2 | |
| Korrigierte Relationtabelle, ExperimentPreparation und Datensätze eingespielt (nur deutsch), Experimente wiederholt, Werte korrigiert, Übersichtstabellen angelegt, Code erweitert, sodass einzelne Features evaluiert werden, einzelne Features evaluiert, Code erweitert, sodass Anzahl der Zuweisungen pro Instanz beschränkt wird, Ergebnisse analysiert | 03.01.2012 | 5 | |
| Zusätzliche WSDEvaluationMethod für Heuristiken erstellt, Voraussetzungen für Fehleranalyse geschaffen: Ergebnisse verschiedener Methoden werden zurück in eine Excel Tabelle geschrieben, dort können Fehlklassifizierungen analysiert und kommentiert werden | 05.01.2012 | 2 | |
| Fehleranalyse | 06.01.2012 | 2.5 | |
| *Summe* | | %CALC{"$SUM( $ABOVE() )"}% | |
| *Soll* | | 120 | bis Ende März 2012 |
<nop>

-- Main.ChristianMeyer - 2011-03-28

   * [[%ATTACHURL%/False_Positives_LeskH123B1_EN.xls][False_Positives_LeskH123B1_EN.xls]]: Fehleranalyse: False Positives (englisch)

%META:FILEATTACHMENT{name="heuristik1.png" attachment="heuristik1.png" attr="h" comment="Heuristik 1" date="1316115427" path="heuristik1.png" size="36857" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="bing-api-translate-java-0.1.jar" attachment="bing-api-translate-java-0.1.jar" attr="" comment="Erste Version der BingTranslationAPI zum Übersetzen von deutschen/englischen Texten" date="1318185111" path="bing-api-translate-java-0.1.jar" size="6078" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="wkten1104_sense_translation.sql" attachment="wkten1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wktde1104_sense" date="1320750257" path="wkten1104_sense_translation.sql" size="19659146" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wkten1104_translation.sql" attachment="wkten1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027517" path="wkten1104_translation.sql" size="3520345" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_translation.sql" attachment="wktde1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027587" path="wktde1104_translation.sql" size="2674543" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_sense_translation.sql" attachment="wktde1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wkten1104_sense" date="1322565057" path="wktde1104_sense_translation.sql" size="73521161" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="False_Negatives_LeskH123B1.xls" attachment="False_Negatives_LeskH123B1.xls" attr="" comment="Fehleranalyse: False Negatives" date="1325852429" path="False_Negatives_LeskH123B1.xls" size="51712" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="False_Positives_LeskH123B1Limit.xls" attachment="False_Positives_LeskH123B1Limit.xls" attr="" comment="Fehleranalyse: False Positives" date="1325852485" path="False_Positives_LeskH123B1Limit.xls" size="47616" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="False_Positives_LeskH123B1_EN.xls" attachment="False_Positives_LeskH123B1_EN.xls" attr="" comment="Fehleranalyse: False Positives (englisch)" date="1326394175" path="False_Positives_LeskH123B1_EN.xls" size="100864" user="ChristianKirschner" version="1"}%
