%META:TOPICINFO{author="ChristianKirschner" date="1325848643" format="1.1" reprev="57" version="57"}%
%META:TOPICPARENT{name="WebHome"}%
<!--
   * Set ALLOWTOPICVIEW = Main.ChristianKirschner,Main.UkpGroup
   * Set ALLOWTOPICCHANGE = Main.ChristianKirschner,Main.UkpGroup
//-->

---+ Christian Kirschner's Work

---++ Project Plan (tentative)

   * *<span class="green">Part 1</span>*
      * <span class="green">Read task description (CICLing sec. 4; IGI sec. rel. anchoring)</span>
      * <span class="green">Read annotation guidebook</span>
      * <span class="green">Familiarize with task</span>
   * Part 2
      * <span class="green">Look into Wiktionary; structure and API access</span>
      * <span class="green">Which dimensions are necessary/important to consider for a dataset?
         * This will be a core question to be discussed</span>
      * <span class="green">Include Wikisaurus?</span>
      * <span class="green">Develop a well-balanced reference dataset for the English relation anchoring task (maybe also for the German?) [with !ChM]</span>
      * Update the annotation guidebook
   * Part 3
      * Annotate the data [@ChM find additional annotator(s)]
      * Evaluate the dataset [with !ChM]
   * Part 4
      * <span class="green">@ChM Update the anchoring framework</span>
      * <span class="green">Get the framework to work, familiarize with code</span>
      * Run the existing methods with old and new data
      * Analyze errors
         * What do we need to solve?
         * What can be improved?
            * This will be a core question to be discussed
   * Part 5
      * Try and develop heuristics (come up with fancy names for them)
         * existing return relation
         * target gloss contains source word
         * matching domain (@ChM: further think about that)
      * Try and develop new methods, ideas:
         * PPR?
         * Graph-based method (Navid?)
         * PROX?
         * Milne/Witten?
   * Part 6
      * @ChM: get cross-lingual dataset ready
      * Select translation API and translate glosses
      * Experiments on cross-lingual dataset

---++ GoldStandard Generation

   * On the one hand the GoldStandard should build up in a way that weaknesses of disambiguation algorithms can be detected, on the other hand it should be quite representative. Therefore we are going to use the following criteria:
      * Part of speech
      * Relations
      * Number of candidates
      * Labels

---++ Heuristics

   1 Wenn ein Sense eine Relation (z.B. Hyperonym) auf einen anderen Artikel hat und einer der Kandidaten wiederum eine Relation (z.B. Hyponym) zurück zum Ausgangsartikel besitzt, so ist dieser Kandidat höchstwahrscheinlich positiv zu annotieren. Dies funktioniert mit Synonym-Synonym, Antonym-Antonym, Hyperonym-Hyponym und Hyponym-Hyperonym Relationspaaren. Auf dem deutschen Datensatz ist die Heuristik bei 11,3% der Paare anwendbar und hat eine Precision von 88,4%. Auf dem englischen Datensatz ist die Heuristik bei 3,3% der Paare anwendbar und hat eine Precision von 85,7%. 
   2 Wenn eine Instanz nur einen möglichen Kandidaten hat, wird dieser positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 21,6% der Paare anwendbar und hat eine Precision von 95,1%. Auf dem englischen Datensatz ist die Heuristik bei 12,8% der Paare anwendbar und hat eine Precision von 98,6%. 
   3 Wenn ein Kandidat im Gloss das Lemma der Instanz enthält, wird das Paar positiv annotiert. Auf dem deutschen Datensatz ist die Heuristik bei 1,5% der Paare anwendbar und hat eine Precision von 88,9%. Auf dem englischen Datensatz ist die Heuristik bei 4,6% der Paare anwendbar und hat eine Precision von 81,0%. 

 * Heuristik 1: <br />
     <img src="%ATTACHURLPATH%/heuristik1.png" alt="heuristik1.png" width="200" height="175" />

---++ Boni

   1 Der Score des ersten Kandidaten jeder Instanz erhält einen Bonus indem der berechnete Score verdoppelt wird (+ einer kleinen Konstante 0.01, damit er nicht bei 0 verbleibt). Die FirstCandidateBaseline hat alleine eine Precision von 78,6% (deutscher Datensatz) bzw. 77,53% (englischer Datensatz).

---++ Results
Im folgenden werden die wichtigsten Ergebnisse dargestellt. Alle Werte im Detail sind im Topic [[https://maggie.tk.informatik.tu-darmstadt.de/wiki/bin/view/Hiwi/Experiments][Experiments]] zu finden.

---+++ Übersicht der Ergebnisse auf dem deutschen Datensatz:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *PureLesk* | 0,64730 ( 791/1222) | 0,75096 ( 196/ 261) | 0,34875 ( 196/ 562) | 0,47631 | 0.0001 |
| *Random/PureLesk* | 0,45990 ( 562/1222) | 0,45990 ( 562/1222) | 1,00000 ( 562/ 562) | 0,63004 | 0.0 |
| *FirstCand* | 0,79133 ( 967/1222) | 0,78585 ( 422/ 537) | 0,75089 ( 422/ 562) | 0,76797 | - |
| *H123* | 0,76187 ( 931/1222) | 0,91437 ( 299/ 327) | 0,53203 ( 299/ 562) | 0,67267 | - |
| *LeskH123* | 0,76923 ( 940/1222) | 0,80973 ( 366/ 452) | 0,65125 ( 366/ 562) | 0,72189 | 0.005 |
| *LeskB1* | 0,78478 ( 959/1222) | 0,73618 ( 466/ 633) | 0,82918 ( 466/ 562) | 0,77992 | 0.005 |
| *LeskH23B1* |  0,78887 ( 964/1222) | 0,73750 ( 472/ 640) | 0,83986 ( 472/ 562) | 0,78536 | 0.005 |
| *LeskH123B1* | 0,78560 ( 960/1222) | 0,73006 ( 476/ 652) | 0,84698 ( 476/ 562) | 0,78418 | 0.005 |
| *CosH123B1* | 0,78396 ( 958/1222) | 0,72923 ( 474/ 650) | 0,84342 ( 474/ 562) | 0,78218 | 0.005 |

Am besten schneidet die Lesk-Methode in Verbindung mit den Heuristiken 2, 3 und Bonus 1 ab. Heuristik 1 verschlechtert das Ergebnis hier geringfügig, aber nicht signifikant. Die Lesk Methode alleine erreicht einen sehr schlechten F-Measure Wert, allerdings eine akzeptable Precision, sodass die Methode in Verbindung mit den Heuristiken sinnvoll ist. 

*Betrachtung der einzelnen Features (LeskH23B1):*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,80840 ( 308/ 381) | 0,79293 ( 157/ 198) | 0,83069 ( 157/ 189) | 0,81137 |
| *V* | 0,79588 ( 386/ 485) | 0,70563 ( 163/ 231) | 0,84021 ( 163/ 194) | 0,76706 |
| *A* | 0,74286 ( 130/ 175) | 0,70940 (  83/ 117) | 0,88298 (  83/  94) | 0,78673 |
| *R* | 0,77348 ( 140/ 181) | 0,73404 (  69/  94) | 0,81176 (  69/  85) | 0,77095 |
| *1* | 0,95038 ( 249/ 262) | 0,95402 ( 249/ 261) | 0,99600 ( 249/ 250) | 0,97456 |
| *2* | 0,74479 ( 715/ 960) | 0,58839 ( 223/ 379) | 0,71474 ( 223/ 312) | 0,64544 |
| *HAS_SYN* | 0,74302 ( 266/ 358) | 0,71560 ( 156/ 218) | 0,83871 ( 156/ 186) | 0,77228 |
| *HAS_ANT* | 0,79621 ( 336/ 422) | 0,75622 ( 152/ 201) | 0,80423 ( 152/ 189) | 0,77949 |
| *HAS_HYPO/HAS_HYPER* | 0,81900 ( 362/ 442) | 0,74208 ( 164/ 221) | 0,87701 ( 164/ 187) | 0,80392 |

Bei Instanzen mit nur einem Kandidaten ist kaum noch Verbesserungspotenzial vorhanden (diese werden durch Heuristik 2 grundsätzlich positiv annotiert). Deutliche Schwächen sind allerdings bei den Instanzen mit 2 oder mehr Kandidaten zu erkennen. Insbesondere die Precision ist hier verbesserungswürdig. Eventuell ist eine Begrenzung der Anzahl an Zuweisungen pro Instanz zielführend.

*Ergebnisse mit Begrenzung der Anzahl an Zuweisungen pro Instanz auf die Kandidaten mit den höchsten Scores oberhalb des Schwellenwerts:*
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* | *Threshold* |
| *Random* | 0,67840 ( 829/1222) | 0,65736 ( 353/ 537) | 0,62811 ( 353/ 562) | 0,64240 | 0,0 |
| *PureLesk* | 0,62520 ( 764/1222) | 0,55640 ( 513/ 922) | 0,91281 ( 513/ 562) | 0,69137 | 0,0 |
| *FirstCand* | 0,79133 ( 967/1222) | 0,78585 ( 422/ 537) | 0,75089 ( 422/ 562) | 0,76797 | - |
| *H123* | 0,76187 ( 931/1222) | 0,91437 ( 299/ 327) | 0,53203 ( 299/ 562) | 0,67267 | - |
| *LeskH123* | 0,77823 ( 951/1222) | 0,85926 ( 348/ 405) | 0,61922 ( 348/ 562) | 0,71975 | 0,005 |
| *LeskB1*| 0,80933 ( 989/1222) | 0,80633 ( 433/ 537) | 0,77046 ( 433/ 562) | 0,78799 | 0,0 |
| *LeskH23B1* | 0,81178 ( 992/1222) | 0,80855 ( 435/ 538) | 0,77402 ( 435/ 562) | 0,79091 | 0,0 |
| *LeskH123B1* | 0,81342 ( 994/1222) | 0,80699 ( 439/ 544) | 0,78114 ( 439/ 562) | 0,79385 | 0,0 |
| *CosH123B1* | 0,81015 ( 990/1222) | 0,80331 ( 437/ 544) | 0,77758 ( 437/ 562) | 0,79024 | 0,0 |

Die Begrenzung der Zuweisungen bringt in der besten Konfiguration (LeskH123B1) eine deutliche Verbesserung von 78,5% auf 79,4%. Die Betrachtung der einzelnen Features ergibt folgendes Bild:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *N* | 0,79790 ( 304/ 381) | 0,82558 ( 142/ 172) | 0,75132 ( 142/ 189) | 0,78670 |
| *V* | 0,84330 ( 409/ 485) | 0,80729 ( 155/ 192) | 0,79897 ( 155/ 194) | 0,80311 |
| *A* | 0,80000 ( 140/ 175) | 0,80412 (  78/  97) | 0,82979 (  78/  94) | 0,81675 |
| *R* | 0,77901 ( 141/ 181) | 0,77108 (  64/  83) | 0,75294 (  64/  85) | 0,76190 |
| *1* | 0,95038 ( 249/ 262) | 0,95402 ( 249/ 261) | 0,99600 ( 249/ 250) | 0,97456 |
| *2* | 0,77604 ( 745/ 960) | 0,67138 ( 190/ 283) | 0,60897 ( 190/ 312) | 0,63866 |
| *HAS_SYN* | 0,77095 ( 276/ 358) | 0,78571 ( 143/ 182) | 0,76882 ( 143/ 186) | 0,77717 |
| *HAS_ANT* | 0,81517 ( 344/ 422) | 0,81006 ( 145/ 179) | 0,76720 ( 145/ 189) | 0,78804 |
| *HAS_HYPO/HAS_HYPER* | 0,84615 ( 374/ 442) | 0,82514 ( 151/ 183) | 0,80749 ( 151/ 187) | 0,81622 |

Obwohl mit der Begrenzung der Assignments insgesamt eine Verbesserung der Ergebnisse erreicht wurde, ist der F-Measure Wert bei Instanzen mit 2 oder mehr Zuweisungen nach wie vor verbesserungsfähig. Zwar konnte hier die Precision um knapp 10% gesteigert werden, allerdings ist der Recall gleichzeitig um einen ähnlichen Wert gesunken. Während in der vorherigen Konfiguration also Instanzen mit mehreren Kandidaten zu viele Zuweisungen vorgenommen haben, werden nun zu wenige Kandidaten zugewiesen. Der Versuch die Anzahl der Zuweisungen auf die zwei höchsten Scores zu beschränken brachte keine signifikante Verbesserung. Auffällig ist zudem, dass sich nun nicht mehr Nomen, sondern Adjektive am besten klassifizieren lassen. 

---+++ Übersicht der Ergebnisse auf dem englischen Datensatz:
| ** | *Accuracy* | *Precision* | *Recall* | *F-Measure* |
| *Random/PureLesk* | 
| *FirstCand* | 
| *H123* | 
| *LeskH123* | 
| *LeskB1* | 
| *LeskH123B1* | 
| *CosH123B1* | 

---++ Weitere Versuche:
   * Anzahl der positiven Annotationen pro Instanz beschränken
   * Semantische Methoden testen (z.B. PPR)
   * Weitere Relatedness Methoden testen

---++ Current Schedule

%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "1" }%
| *Task* | *Date* | *Hours* | *Remarks* |
| - | 28.03.2011 | 0 | Project Plan (!ChM) |
| Part 1 + Meeting | 11.04.2011 | 1 | |
| Datenbank aufsetzen + Workspace anlegen | 11.04.2011 | 0.75 | |
| In Code einlesen | 12.04.2011 | 0.75 | |
| Software testen, Abläufe bei Datenerzeugung nachvollziehen, Wiktionary genauer ansehen | 15.04.2011 | 2.5 | |
| Daten in Datenbank analysieren, Gedanken über Erstellung eines GoldStandards machen | 24.04.2011 | 2.5 | |
| Random und MFS Evaluationsdaten für WordNet-Wiktionary Alignment erstellen | 28.04.2011 | 1.5 | |
| Meeting | 29.04.2011 | 0.5 | |
| Erstellen einer Statistik über Verteilung von POS, Kandidaten, Relationen in englischer Wiktionary und Bewertung der Daten | 01.05.2011 | 2 | |
| Programmaufbau überlegen, mit Umsetzung beginnen | 03.05.2011 | 3 | |
| Statistik über Labels erstellen, analysieren, Programmieren: Code um Samples aus DB zu extrahieren soweit fertig, Textfile wird erstellt, Einbinden in vorgegebenen Code, Erstellung eines ersten (unaligned) GoldStandards, Analyse der Daten und Feststellung von Problemen | 04.05.2011 | 3.5 | |
| Automatische Erstellung einer Statistik über erstellten GoldStandard programmieren | 07.05.2011 | 1.5 | |
| Weitere Datenbank (en_ws) aufsetzen, de und en_ws Datenbanken ansehen und integrieren, Statistik erweitern | 14.05.2011 | 2.5 | |
| Neue Daten importiert, Datensätze generiert | 31.05.2011 | 1 | |
| Deutschen GoldStandard annotiert (Teil 1) | 07.06.2011 | 1.5 | |
| Deutschen GoldStandard annotiert (Teil 2) | 16.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 1) | 26.06.2011 | 1.5 | |
| Englischen GoldStandard annotiert (Teil 2) | 27.06.2011 | 3.5 | |
| Englischen GoldStandard annotiert (Teil 3) | 03.08.2011 | 2 | |
| Meeting | 23.08.2011 | 0.5 | |
| Code auschecken und einlesen | 04.09.2011 | 2 | |
| Codeanalyse: Überprüfung der vorhandenen Evaluationsmethode und Feststellung notwendiger Änderungen | 12.09.2011 | 2 | |
| Evaluation und Disambiguierung korrigieren und an unsere Bedürfnisse anpassen: Mehrere positive Annotation pro Instanz, Disambiguierung auf Basis eines Thresholds, Evaluation entsprechend Paaren (nicht Instanzen) | 13.09.2011 | 2,5 | |
| Methoden (z.B. Lesk) testen, Schwachstellen identifizieren | 13.09.2011 | 1,5 | |
| Über Heuristiken nachdenken, eine erste Heuristik implementieren, Nutzen der Heuristik evaluieren | 15.09.2011 | 4 | |
| TreeTagger & StopWords installiert | 18.09.2011 | 0.5 | |
| Heuristiken 2 und 3 implementiert und getestet, TreeTagger weiter eingebunden und getestet | 19.09.2011 | 2 | |
| Schweren Bug bei Kandidatenextraktion gefunden und behoben, Evaluationsdaten für Heuristiken korrigiert | 19.09.2011 | 1 | |
| Schwellenwerttraining + Visualisierung der Ergebnisse implementiert | 05.10.2011 | 1.5 | |
| Schwellenwerttraining besser eingebunden, RelatednessMethod testen, Instanzen mit Folds versehen (für spätere CrossValidation) | 07.10.2011 | 3.5 | |
| Experimente mit verschiedenen Methoden durchführen und Ergebnisse festhalten | 08.10.2011 | 1 | |
| Weitere Experimente auf englischem Datensatz durchführen und festhalten, Fehler im GoldStandard identifizieren | 09.10.2011 | 2 | |
| In Bing Translation API einlesen, erste Version programmieren (siehe Attachments) | 09.10.2011 | 2.5 | |
| Tabellen-Schemata für Übersetzungslinks und Vorgehensweise planen | 26.10.2011 | 1 | |
| Berkeley DB Files zum Laufen gebracht und getestet, Tabellenschemata und Vorgehensweise genauer beschreiben | 30.10.2011 | 2.5 | |
| Code für Übersetzung von Sense-Tabellen geschrieben, getestet, überarbeitet und Übersetzung der deutschen sense Tabelle gestartet | 05.11.2011 | 3.5 | |
| wkten1104_sense_translation fertig übersetzen, Probleme mit URLs in zu übersetzendem Text beheben | 06.11.2011 | 2 | |
| Code zum Parsen von Übersetzungslinks schreiben, Testen, Ausführen | 07.11.2011 | 2.5 | |
| Fehler bei Übersetzung beheben, examples nachtragen (übersetzen), mit Übersetzung von wkten1104_sense beginnen | 08.11.2011 | 2 | |
| Code schreiben, um die target_term_ids in den _translation Tabellen aus den Tabellen der Zielsprache herauszusuchen, Ausführen, Tabellen mit korrekten ids exportieren und hochladen | 11.11.2011 | 1.5 | |
| Englische sense Tabelle vollständig übersetzt | 29.11.2011 | 0.5 | |
| Mit ESA befassen, Code so umschreiben, dass multilinguale Experimente möglich, ein erstes Exeriment mit englisch-deutschem Datensatz durchführen | 11.12.2011 | 2 | |
| Experimente mit ESA und auf multilingualen Datensätzen | 21.12.2011 | 2 | |
| Korrigierte Relationtabelle, ExperimentPreparation und Datensätze eingespielt (nur deutsch), Experimente wiederholt, Werte korrigiert, Übersichtstabellen angelegt, Code erweitert, sodass einzelne Features evaluiert werden, einzelne Features evaluiert, Code erweitert, sodass Anzahl der Zuweisungen pro Instanz beschränkt wird, Ergebnisse analysiert | 03.01.2012 | 5 | |
| Zusätzliche WSDEvaluationMethod für Heuristiken erstellt, Voraussetzungen für Fehleranalyse geschaffen: Ergebnisse verschiedener Methoden werden zurück in eine Excel Tabelle geschrieben, dort können Fehlklassifizierungen analysiert und kommentiert werden | 05.01.2012 | 2 | |
| *Summe* | | %CALC{"$SUM( $ABOVE() )"}% | |
| *Soll* | | 120 | bis Ende März 2012 |
<nop>

-- Main.ChristianMeyer - 2011-03-28

%META:FILEATTACHMENT{name="heuristik1.png" attachment="heuristik1.png" attr="h" comment="Heuristik 1" date="1316115427" path="heuristik1.png" size="36857" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="bing-api-translate-java-0.1.jar" attachment="bing-api-translate-java-0.1.jar" attr="" comment="Erste Version der BingTranslationAPI zum Übersetzen von deutschen/englischen Texten" date="1318185111" path="bing-api-translate-java-0.1.jar" size="6078" user="ChristianKirschner" version="1"}%
%META:FILEATTACHMENT{name="wkten1104_sense_translation.sql" attachment="wkten1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wktde1104_sense" date="1320750257" path="wkten1104_sense_translation.sql" size="19659146" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wkten1104_translation.sql" attachment="wkten1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027517" path="wkten1104_translation.sql" size="3520345" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_translation.sql" attachment="wktde1104_translation.sql" attr="" comment="geparste Übersetzungslinks (target_term_id bezieht sich auf target)" date="1321027587" path="wktde1104_translation.sql" size="2674543" user="ChristianKirschner" version="2"}%
%META:FILEATTACHMENT{name="wktde1104_sense_translation.sql" attachment="wktde1104_sense_translation.sql" attr="" comment="Übersetzung der Tabelle wkten1104_sense" date="1322565057" path="wktde1104_sense_translation.sql" size="73521161" user="ChristianKirschner" version="1"}%
