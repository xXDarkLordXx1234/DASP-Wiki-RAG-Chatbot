%META:TOPICINFO{author="steuer" comment="save topic" date="1381256423" format="1.1" reprev="14" version="14"}%
%META:TOPICPARENT{name="Main.RichardSteuerLeftBar"}%
%TOC%

---+++ Aktueller Vertrag (September 2013 - Oktober 2013)

%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="2"  footerrows = "1" }%
| *Richards Stunden* |
| *Aufgabe* | *Datum* | *Stunden* | *Bemerkungen* |
| Einarbeitung in Martins Aufgaben, [[https://docs.google.com/document/d/14PWeoTkrnKk9H8_7CfVbdvuoFZ7jYivNTkBX2Hj7qLw/edit?pli=1#][Google syntactic ngrams]] | 30.09.2013 | 1 | |
| Task 1.1 und 1.2 beendet, Ergebnisse an Martin geschickt | 01.10.2013 | 6 | nodes: Abdeckung der Jahre |
| Einarbeitung in [[http://sourceforge.net/projects/jobimtext/][JoBimText]] ([[http://www.ukp.tu-darmstadt.de/software/jobimtext/][UKP]]), mit Hadoop wieder vertraut gemacht | 03.10.2013 | 2 | |
| Einarbeitung in !MateTools, Parser-Infrastruktur | 04.10.2013 | 4 | laden zu speicherintensiv, am besten gleich auf Cluster |
| Hadoop-Skript mit Parser versucht auf Cluster auszuführen | 07.10.2013 | 3 | techn. Probleme, Hans-Peter geschrieben |
| dt_arc_extractor_by_year und wordcount_by_year geschrieben | 08.10.2013 | 7 | |
| *Summe* | | 23 | bisher geleistet |
| *Soll* | | 80 | (aktueller Vertrag, 40 h/Monat) |

---+++ Aufgaben

Von Martin: 

   * <s>Task 1) Abdeckung der Jahre im [[https://docs.google.com/document/d/14PWeoTkrnKk9H8_7CfVbdvuoFZ7jYivNTkBX2Hj7qLw/edit?pli=1#][Google syntactic ngrams]] berechnen</s>
   * Task 2) Dts fuer die verschiedenen Epochen berechnen.
      * 1500-1700
      * 1700-1800
      * 1800-1900
      * 1900-1950
      * 1950-2008
   * Task 3) "So wenn wir ich Zeitscheiben die ich gerne haette mal ermittelt habe haette ich noch gerne eine Matrix mit den Wortoverlaps unter den Zeitscheiben. Kann man dann anhand der !WordCounts der jeweiligen DTs berechnen."

Von Chris:
   * 70+ M Sätze Deutsch parsen ([[Students.MateTools][MateTools]]), Ziel: Auf HDFS liegen die geparsen Sätze, so dass man dann eine DT-Pipeline starten kann.
      * frink: /srv/data/LCC/de/denews70M_sorted_cleaned_uniq (hdfs://node-00:8020/user/riedl/denews70M_uniq)
      * frink: /home/alles/UnsupParsing/data/de/de_news_10M.txt
      * headnode-02: -Dmapreduce.queue.name=langtech

---+++ Links
   * !MateTools
      * [[https://code.google.com/p/mate-tools/wiki/DependencyParsing][How to use the dependency parser from the command line?]]
      * [[https://code.google.com/p/mate-tools/downloads/list][Download list]]
      * [[http://code.google.com/p/mate-tools/source/browse/trunk/mate-tools/src/examples/FullPipeline.java][Full Java pipeline]]