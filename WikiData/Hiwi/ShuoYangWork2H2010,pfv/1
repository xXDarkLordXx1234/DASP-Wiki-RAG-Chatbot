%META:TOPICINFO{author="ShuoYang" date="1286005177" format="1.1" reprev="1" version="1"}%
%META:TOPICPARENT{name="ShuoYang"}%
---+ Arbeitsprotokoll-2H 2010 / Shuo Yang

%TOC%

---++ Sept 2010

---+++ Abgeschlossene Aufgaben
%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "2" }%
| *Aufgabe* | *% done* |
| 1. Umbauen von !TrecTranslationXmlWriter | 100 |

---+++ Detaillierte Auflistung
_Antichronologisch sortiert_
%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "2" }%
| *Aufgabe* | *Datum* | *Stunden* | *Bemerkungen* | *Neu* |
| !WikiWörterbuch | 01.10.2010 | 3.5 | <ul><li>Extraktion von Redirect-Links</li><li>Kombination mit direkter Übersetzungen (noch nicht fertig)</li><li>Umbau von direkter Übersetzungen, gespeichert in List statt einzige konkatenierte String</li><li>Problem: System wird extrem langsam wenn VM über 2GB groß ist</li></ul> | * |
| !WikiWörterbuch | 30.09.2010 | 1 | Angefangen mit der Implementierung von Extraktion aus Redirect-Links |  |
| !WikiWörterbuch, Meeting | 28.09.2010 | 3.5 | Beobachtung und Analyse von Crosslanguage-Links in Wiki dump <br> Erhöhung Robustness von !WikiWörterbuch, indem leere Links ( =[[de:] ]= ), fehlerhafte Links (=[[de:]=, =[[de:=) ignoriert werden <p> Meeting mit Benjamin über Redirect-Extraktion |  |
| !TrecTranslationXmlWriter, !WikiWörterbuch | 27.09.2010 | 3.5 | Saubermachen und Kommentare von !TrecTranslationXmlConcatenatedWriter, Test cases und Readme (fertig) <p> Implementierung direkter Einlesen aus Plaintext-Dateien für !WikiWörterbuch <br> Komische Verhalten in geparste Hashmap gefunden. Versuchen, Ursache herauszufinden |  |
| !GoogleTranslator | 24.09.2010 | 1 | Prüfen von Gültigkeiten verwendeter Bibliltheken, APIs in !GoogleTranslator<p> Aktualisierung der Testcases mit !NewXmlFileReader und !TrecTranslationXmlWriter |  |  
| !WikiWörterbuch, !TrecTranslationXmlWriter | 22.09.2010 | 7 | Testen, Saubermachen und Verfeinerung der Kommentare von !TrecTranslationXmlWriter (fertig) <p> !WikiWörterbuch: <ul><li>Nun wird Key in Kleinbuchstaben gespeichert, und Value in originale.</li><li>Für Keys mit mehrerer Interlanguage-Links, werden diese einzelne Übersetzungen aneinandergehangen</li><li> =HashMapDictionary#getTranslation(String)= nun liefert die Übersetzung vom Wörterbuch.</li><li>Zur Veranschaulichung ein Tool geschrieben, was gespeicherte Wörterbuch im Form von Hashmap ins Plaintext konvertiert.</li><li>Erstellung von Listen der Artikeln, deren Titel Klammern beinhaltet, und Listen der Artikeln mit mehrerer Übersetzungen</li></ul> |  |
| !WikiWörterbuch, !TrecTranslationXmlWriter, Meeting | 21.09.2010 | 7.5 | Meeting mit Benjamin über Ergebnisse und Fortsetzung von Projekete <p> !TrecTranslationXmlWriter: <ul><li>Ausgegebene Dateien spiegelt nun die originale Struktur und Hierarchie vor Einlesen wieder.</li><li>Möglichkeit zur Ausgabe aller Dateien auf dieselben Ordner (PARAM_WRITE_FLATLY)</li></ul> !WikiWörterbuch: <ul><li>Statistik von Redirect</li><li>Ursache Abweichung Anzahl geparster Pages mit ihr in Statistik auf Wikipedia: Wiki nutzt [[http://meta.wikimedia.org/wiki/Article_count_reform][diese Methode zum Zählen]]</li></ul> |  |
| !WikiWörterbuch, !TrecTranslationXmlWriter | 20.09.2010 | 10 | !WikiWörterbuch: <ul><li>Extraktion der Wortpaare aus Wiki Dump (EN-DE)</li><li>Nun gespeichert auf dem Festplatt in HashMap</li><li>Ein interaktives Konsoleprogramm, womit man die Wortpaare abfragen kann.</li></ul> !TrecTranslationXmlWriter: <ul><li>Ausgabe der Dateien in originaler Struktur von Dateien (Falls 3 ein dann 3 aus in originale Dateiname)</li><li>Rekursive Struktur noch nicht testiert (Dateien unter Unterordnern)</li><li>Getrennt in zwei Klassen, eine für aneinandergehangene Ausgabe (!TrecTranslationXmlConcatenatedWriter), eine für separate Dateien (!TrecTranslationXmlWriter)</li></ul> |  |
| !WikiWörterbuch | 19.09.2010 | 9.5 | Erstellung von Statistik über Anteil der Seiten in Wikipedia, die mit Interlanguage-Link in Zielsprache sind. <br> Probiert mit SAX Parser und rein BufferedReader, Performanzvergleich <br> Allerdings unterscheiden sich die Resultate voneinander. Versuchen, die Ursache herauszufinden <br> Untersuchung der Möglichkeiten zur effizienten Speicherung von großer Menge Daten |  |
| !WikiWörterbuch | 18.09.2010 | 1.5 | Einarbeiten in Struktur von XML Dateien von MediaWiki <br> Untersuchung der Möglichkeiten von XML-Parsen mit Java |  |
| !WikiWörterbuch, Meeting | 17.09.2010 | 3 | Einarbeiten in JWPL <br> Meeting mit Benjamin über erneute Aufgaben und Zeitplanung |  |
| !NewXmlFileReader,<br> Wörterbuch aus Wikipedia | 16.09.2010 | 3 | =NewXmlFileReader= fast fertig. Test <br> Herunterladen von WikiDump, Einarbeiten in JWPL |  |
| !NewXmlFileReader | 15.09.2010 | 1 | Weitere Implementierung von =NewXmlFileReader= |  |
| !NewXmlFileReader | 02.09.2010 | 2.5 | Weitere Implementierung von =NewXmlFileReader= |  |
| *Summe* | | %CALC{"$SET(done_hour, $SUM( $ABOVE() ))$EXEC($GET(done_hour))"}% | | |
| *Soll* | | %CALC{"$SET(total_hour, 57.5)$EXEC($GET(total_hour))"}% | bis Ende September noch %CALC{"$EVAL( $GET( total_hour ) - $GET( done_hour ) )"}% Stunden (inkl. 17,5 Übertrag von August) | |
<nop>

---++ Juli ~ Aug 2010

---+++ Abgeschlossene Aufgaben
| *Aufgabe* | *% done* |
| 1. Anpassung von BM25 auf Lucene 3.0 | 100 |
| 2. Dokumentation auf Implementierung eignem Lucene Scoring | 100 |

---+++ Detaillierte Auflistung
_Antichronologisch sortiert_
%EDITTABLE{  sort="on" tableborder="0" cellpadding="1" cellspacing="3" headerrows="1"  footerrows = "2" }%
| *Aufgabe* | *Datum* | *Stunden* | *Bemerkungen* | *Neu* |
| BM25, !NewXmlFileReader | 28.08.2010 | 6 | Zusammenführung von Projekte BM25 Modelle ins Eine. <br> Erneute Evaluierung und Anpassung von dieser Modell an neuer APIs von Lucene 3, mit neu erworbenen Verständnisse von Lucene Scoring <br> Testen und Behoben von Bugs <br> Vorbereitung von NewXmlFileReader auf Implementierung weiterer Funktionälitäten | * |
| Lucene Scoring | 27.08.2010 | 3.5 | Dokument ChangingLuceneScoring fertig geschrieben <br> Saubermachen von !DemoScoring | * |
| Lucene Scoring | 26.08.2010 | 5 | Einarbeiten in Similarity <br> Erstellung vom Dokument ChangingLuceneScoring (noch nicht fertig) |  |
| Lucene Scoring | 25.08.2010 | 5 | Einarbeiten in Lucene Scoring <br> Erstellung von DemoScoring | * |
| Lucene Scoring | 24.08.2010 | 2.5 | Einarbeiten in Lucene Scoring |  |
| Lucene Scoring | 23.08.2010 | 1.5 | Einarbeiten in Lucene Scoring |  |
| Lucene Scoring | 22.08.2010 | 2 | Einarbeiten in Lucene (Datenstruktur, Scoring) |  |
| WikiDictionary | 02.08.2010 | 1.5 | Versuchen, WikiDumps unterzuladen |  |
| !XPathReader | 22.07.2010 | 1.5 | Implementierung von !XmlFileReader |  |
| !XPathReader, Meeting | 20.07.2010 | 2 | Testen von !XmlFileReader und Meeting mit Benjamin |  | 
| BM25, !XPathReader | 17.07.2010 | 3 | Testen und Fixieren von !BM25Modell <br> Modifizierung von !XmlFileReader mit XPath für höherer Flexibilität |  |  
| BM25 | 15.07.2010 | 3 | Debug von !BM25Modell für spezielle Queries |  |
| BM25 | 13.07.2010 | 2.5 | Anpassungen und Testen von !BM25Modell unter Lucene 3.0 |  |
| BM25 | 11.07.2010 | 2.5 | Einarbeiten in Lucene !TermQuery als Beispiel für Scoring, und <br> Anpassungen von !BM25Modell <ul><li> funktioniert schon mit Lucene 3.0 (ohne Explanation) </li><li> Korrektheit allerdings noch nicht testiert </li></ul> |  |
| Lucene Scoring | 10.07.2010 | 3 | Einarbeiten in Lucene Scoring |  |
| BM25 | 08.07.2010 | 1 | Anpassungen |  |
| BM25, Meeting | 06.07.2010 | 3 | Weiteres Anpassen und Meeting mit Benjamin |  |
| BM25 | 04.07.2010 | 2 | Weiteres Anpassen |  |
| BM25 | 02.07.2010 | 2 | Anpassen von BM25 für Lucene 3.0 |  |
| BM25 | 01.07.2010 | 2 | Einarbeiten in BM25 |  |
| *Summe* | | %CALC{"$SET(done_hour, $SUM( $ABOVE() ))$EXEC($GET(done_hour))"}% | |  |
| *Soll* | | %CALC{"$SET(total_hour, 72)$EXEC($GET(total_hour))"}% | bis Ende August noch %CALC{"$EVAL( $GET( total_hour ) - $GET( done_hour ) )"}% Stunden (inkl. 12 Übertrag von Mai) |  |
<nop>


-- Main.ShuoYang - 02 Oct 2010