%META:TOPICINFO{author="ClemensDeusser" date="1344947443" format="1.1" reprev="18" version="18"}%
%META:TOPICPARENT{name="ClemensDeusser"}%
<span class="red">*Information on this site is outdated.*</span>

---+++++ On the Fachsystematik correlating with PEDOCS (Handout)

*Description of the Fachsystematik and PEDOCS*

The  [[ClemensDeusserFachsystematik][Fachsystematik]] (FS) is an index of topic areas of pedagogy scientific papers. It is structured using a general topic category, such as "Bildung und Erziehung allgemein" and then splitting off to subcategories, such as "Theorie der Bildung und Erziehung, einzelne Richtungen". In this specific document, the categories are identified by numbers.

PEDOCS is a database of pedagogic papers, including metadata such as title, abstract, author(s), publication date, publication issue and keywords for each paper.

*The Fachsystematik and PEDOCS keywords*

Our main question now is whether the keywords in the PEDOCS database at least partially match the categories provided by the FS, if it does and if that matching is of good quality, we can use it as our gold standard to test and verify our algorithms against. To find out whether they matched up, I intentionally chose to parse the FS in a very lenient way, so that if the parsed data did match up with the PEDOCS keywords, I may not have sufficient evidence to justify using them as the gold standard, but if they did *not* match up, I would have sufficient evidence to dismiss them as a potential gold standard, so my formal goal was to provide reasoning that the keywords in PEDOCS are not compliant with the FS without further modification. I chose this route 

For my approach I first augmented the FS to form complete words, for example "Jugendhilfe, -berufshilfe, -arbeitslosigkeit" was changed to "Jugendhilfe, Jugendberufshilfe, Jugendarbeitslosigkeit", so that a match from the keyword "Jugendarbeitslosigkeit" would not be missed. I then extracted all words longer than 3 letters (to exclude words such as "der die das") and treated them each as a separate category and repeated the same process with the PEDOCS keywords. My reasoning for this was simple, if one or more keywords matched a category completely, then they would match at least one of the words in that category, so the correct results would be a subset of our results and partially correct (and incorrect) results would be caught as well, which lines up with our goal of attempting to prove that FS and PEDOCS do not match up.

As a result, the amount of different PEDOCS keywords increased slightly by about 500 keywords (+ ~10%) and I parsed 541 words from the Fachsystematik. The intersection of FS words and PEDOCS keywords consisted of about 190 words, which is a subset of ~3% of all PEDOCS keywords and ~38% of FS keys. While only a relatively low amount of PEDOCS keywords occurs in the FS, this by itself is not sufficient to dismiss the matching as unsuitable, we need to actually look at documents to see whether the matching keywords are actually representative and how much information the filtered keywords contained.

*Verifying our results*

589 PEDOCS documents did not contain a single match and the average amount of keywords per document decreased from ~11 to ~3 (average calculated excluding the 589 empty matches). A 70% decrease in keywords doesn't appear too bad considering that 97% of the keywords never appeared in the FS to begin with, but upon closer inspection of the results, the reason for this appears to be that the [[ClemensDeusserFSPedocsKeywords2][intersection]] contains a large amount of words with a rather general meaning in the context of pedagogy, such as "Erziehung", "Schule", "Lernen" etc.

   But even with a general meaning, the classification can still be correct if the categories are equally general and in fact many of the classifications *are* correct, for instance document number 127 has the matching keywords "Lehrerausbildung;Lernen;Lehrerrolle;Lehrerfortbildung;Berufsschule;Weiterbildung;Hochschuldidaktik;Lehrer" which clearly puts it in the category "Der Lehrer", which, looking at the title "Innovative Fortbildung der Lehrerinnen und Lehrer an beruflichen Schulen. Gutachten zum Programm", appears to be correct.
   
However, the bulk of our documents (2276, again excluding empty ones) contains four matches or less and there the situation looks very different. Document 412 for instance uses the keywords " _Angewandte Sozialforschung; Auftragsforschung; Drittmittelforschung; Europäische Forschungsförderung; Forschung und Lehre;  Forschungsbedarf; Forschungsfinanzierung; Forschungsförderung; Forschungsprogramm; Forschungsstatistik; Forschungsüberblick; Sozialforschung; Sozialwissenschaftliche Forschung; Staatliche Forschungsförderung; Fachhochschule; Universität; Sozialarbeiter; Sozialpädagogik; Soziale Arbeit; Deutschland_ ", the matches remaining are " _Forschung;Lehre_ ". Even though the FS does not lack categories pertaining to "Forschung", the specific fields mentioned do not match up and the remaining words are unsuitable for classification.

Without examining a significant portion of the database I cannot say how many documents are classified correctly and how many are not, but examples for both sides were readily available. If I had to guess, I would say that the majority of documents (with matches) are correctly classified, nevertheless because of the inconsistency, the substantial amount of unclassifiable data (empty matches) and the massive loss of keyword information, I don't think FS can be applied this way.

*What I need*

In order to get rid of the incorrect results there are a few possibilities:

   * Discard documents without enough matches and refine current approach.
   * Classify training & testing sets manually, possibly multi label.
   * Use NLP to find matches instead of using the naive approach of exact matches.

I feel that each solution has it's benefits and it's cost, the first one being the easiest but also the least promising and the last one being possibly too sophisticated for me. Using synonyms (or hypernyms) could improve classification for a relatively low cost, but the availabiltity and feasibility of this option has not yet been explored sufficiently to make that call.


---+++++ Technical progress

Small framework for graphs built on top of JUNG and an interface for algorithms. Framework for JDBC pending, may be able to use JDBCReader by Richard & Shuo.

---+++++ Chinese Whispers clustering results including keywords and number of occurrences per cluster:

   * [[ClemensDeusserCluster1][Version 1 / 10 iterations / 22 cluster / normalised edges]]

Sample results using tf*idf and CW randomization seeds:

   * [[ClemensDeusserCluster2][Version 2 / 10 iterations / 3 cluster / seed:2 / normalised edges / tf*idf / cutting edges below average weight]]
   * [[ClemensDeusserCluster3][Version 2 / 10 iterations / 3 cluster / seed:4 / normalised edges / tf*idf / cutting edges below 1.5 * average weight]]
   * [[ClemensDeusserCluster4][Version 2 / 10 iterations / 6 cluster / seed:1 / normalised edges / tf*idf / cutting edges below twice average weight]]

Results very similar, all have a very large single cluster with the majority of nodes.

-- Main.ClemensDeusser - 2012-07-26