{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738339593112188900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "chromadb_client = chromadb.HttpClient(\n",
    "    host=\"localhost\", port=8000, settings=Settings(anonymized_telemetry=False)\n",
    ")\n",
    "\n",
    "chromadb_client.heartbeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_overlap': 64, 'chunk_size': 256, 'collection_name': 'WikiData', 'embedding_model_name': 'sentence-transformers/paraphrase-MiniLM-L6-v2', 'header_match': '^---\\\\++\\\\s+\\\\*?(?:%[A-Z]+%)?(.*?)(?:%[A-Z]+%)?\\\\*?$', 'ignored_line_starts': '%META', 'include_headers_in_chunks': False, 'include_headers_in_embedding': True, 'include_path_in_embedding': True, 'lemmatize': True, 'model': 'sentence-transformers/paraphrase-MiniLM-L6-v2', 'remove_accents': True, 'remove_numbers': True, 'remove_stopwords': True}\n"
     ]
    }
   ],
   "source": [
    "config = chromadb_client.get_collection(\"system_config\").get()[\"metadatas\"][0]\n",
    "\n",
    "model = HuggingFaceEmbedding(config[\"model\"])\n",
    "collection = chromadb_client.get_or_create_collection(\n",
    "    config[\"collection_name\"]\n",
    ")\n",
    "\n",
    "collection.count()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "METADATA: {\n",
      "    \"allow_view\": \"\",\n",
      "    \"author\": \"alles\",\n",
      "    \"chunk_header\": \"Slurm Compute Cluster FAQ;Host and Connect to webservices;Jupyter Notebook;Port Redirection / Proxy / TCP Forwarder\",\n",
      "    \"chunk_id\": 15,\n",
      "    \"date\": 1727877596,\n",
      "    \"deny_view\": \"%USERSWEB%.WikiGuest\",\n",
      "    \"format\": \"1.1\",\n",
      "    \"hash\": \"4a3bd651ff776936c751411daf5e72a5d46b0b09be92e8b897de26edef666e1f\",\n",
      "    \"path\": \"Services/ITBasic/ComputeClusterFAQ.txt\",\n",
      "    \"reprev\": 99,\n",
      "    \"topicparent\": \"Services/ITBasic.ComputeCluster\",\n",
      "    \"version\": 100\n",
      "}\n",
      "CHUNK:\n",
      " %RED%lot of people don't get this right, so please read on!%ENDCOLOR%*\n",
      "\n",
      "         * \"lisa\" is the servers name where your job is executed - so this is the server where the jupyter notebook runs. exchange \"lisa\" by the server name your job runs on!\n",
      "\n",
      "         * \"8888\" in this example is the port on server \"lisa\" that makes your jupyter notebook accessible - this port can only be used once, if another user has a jupyter notebook server running on \"lisa\" at port \"8888\" yours will fail! pick another one - any above 1024 during the start of the jupyter notebook with the =--port=XXXXX= flag - and do *not* use \"8888\"!\n",
      "\n",
      "         * \"5042\" is the \"mapped / redirected\" port from server \"slurm login\" node --> compute node \"lisa\", making the jupyter server available using the login-nodes address - this port can only be used once, if another user has a redirect server running on slurm-login node yours will fail! pick one between 5000 and 5100 and do *not* use \"5042\"!\n",
      "\n",
      "   * *Good to know - please read*:\n",
      "\n",
      "      * Port already taken: Pick another one. You can choose any port from *from 5000 to 5100* as <u>EXTERNAL_PORT</u> and any *above 1024* as <u>JUPYTER_PORT</u>\n",
      "\n",
      "      * Forwarder Status: The forwarder lives in the background and also goes on when exiting the shell, but we kill these forwarders daily at 3am automatically, so restart it when needed.\n",
      "\n",
      "      * Who can use this: This kind of port forwarding is currently *only usable from*:\n",
      "\n",
      "         * *UKP office network* (130.83.167.0/24 - includes Project VMs)\n",
      "\n",
      "         * *UKP VPN* (internal network)\n",
      "\n",
      "         * *TK network* (130.83.163.0/24).\n",
      "\n",
      "         * Only for those networks the external ports 5000 to 5100 have been opened!\n",
      "\n",
      "         * Contact UKP system-admin if you are outside those networks / do not have access to UKP VPN and need to use this. \n",
      "\n",
      "      * Verify / Testing the proxy: \n",
      "\n",
      "         * You can test the forward locally on the *slurm login node* for HTTP via =curl localhost:EXTERNAL_PORT=, e.g. =curl localhost:5000=\n",
      "\n",
      "         * On your workstation/laptop, browse to =http://slurm.ukp.informatik.tu-darmstadt.de:EXTERNAL_PORT= to access the notebook. \n",
      "\n",
      "         * Make sure that when you copy the URL from the terminal with the token that the URL contains the =.ukp.informatik.tu-darmstadt.de= part!\n",
      "\n",
      "\n",
      "\n",
      "Please note:\n",
      "\n",
      "   * You can of course wrap the =srun= and =jupyter notebook= calls in a .sh file to use with sbatch.\n",
      "\n",
      "   * The =-w= argument forces a job to run on a specific node. This is insofar important in that the compute nodes with Pokemon names (=turtok=, =blubella=, ...) cannot be reached from outside via VPN.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METADATA: {\n",
      "    \"allow_view\": \"\",\n",
      "    \"author\": \"alles\",\n",
      "    \"chunk_header\": \"Tips;Forwarding connections\",\n",
      "    \"chunk_id\": 1,\n",
      "    \"date\": 1727883180,\n",
      "    \"deny_view\": \"%USERSWEB%.WikiGuest\",\n",
      "    \"format\": \"1.1\",\n",
      "    \"hash\": \"628b847b472d877193f17b6ecb24c58e049f063559bbb8c356d5c941d8ea3c5d\",\n",
      "    \"path\": \"Services/ITBasic/SshService.txt\",\n",
      "    \"reprev\": 22,\n",
      "    \"topicparent\": \"Resources\",\n",
      "    \"version\": 22\n",
      "}\n",
      "CHUNK:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " %ENDTAB%\n",
      "\n",
      " %TAB{\"Unfold old instructions and tips\"}%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tips Forwarding connections\n",
      "\n",
      "\n",
      "   * If you need to copy data from outside UKP (e.g. your private laptop at home) to e.g. a compute server via SSH, you should do so via a SSH port forwarding:\n",
      "\n",
      "      * Set up forwarding connection in one terminal. This example will create forwarding from port 2222 on your machine to port 22 on projectvm:\n",
      "\n",
      "         * =ssh -L 2222:projectvm.ukp.informatik.tu-darmstadt.de:22 headnode.ukp.informatik.tu-darmstadt=\n",
      "\n",
      "      * Copy data in another terminal. This will use the port forwarding set up above to copy =myfile.txt= to your home directory on selma.\n",
      "\n",
      "         * =scp -P 2222 myfile.txt myukpusername@localhost:~/=\n",
      "\n",
      "   * Such forwardings only work for your machine, so you do not have to be afraid that somebody else in your network might hijack your port forwarding.\n",
      "\n",
      "   * As it is likely that your UKP username is different from your username on whatever machine your are on outside UKP, make sure you always use the \"username@host\" notation as in the example above.\n",
      "\n",
      "   * This also works with rsync: =rsync -e 'ssh -p 2222' myfile.txt myukpusername@localhost:~/=\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tips Forwarding connections Automatically forwarding connections (transparent multi-hop ssh)\n",
      "   * To transparently construct connects through multiple ssh tunnel, you can specify the following in =.ssh/config=\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "Host DestinationHostName\n",
      "\n",
      "\tProxyCommand ssh username@GatewayHostName nc %h %p\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "   * This allows transparent connection to the DestinationHostName through the gateway computer\n",
      "\n",
      "   * Setup example\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "Host desktop-152.ukp.informatik.tu-darmstadt.de\n",
      "\n",
      "\tProxyCommand ssh user@server.ukp.informatik.tu-darmstadt.de nc %h %p\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "   * Connection example\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "ssh user@workstation.ukp.infomatik.tu-darmstadt.de\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "   * If you have the normal pass phrase login, then the above connection asks for two passwords: first one to login to the gateway and another one to login to the destination computer.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METADATA: {\n",
      "    \"allow_view\": \"\",\n",
      "    \"author\": \"alles\",\n",
      "    \"chunk_header\": \"Why Apptainer instead of docker?\",\n",
      "    \"chunk_id\": 0,\n",
      "    \"date\": 1727877523,\n",
      "    \"deny_view\": \"%USERSWEB%.WikiGuest\",\n",
      "    \"format\": \"1.1\",\n",
      "    \"hash\": \"0ab65c9fd9c0ff4ac820db02b52eb87b6274ab97ef418196225f506f826d7656\",\n",
      "    \"path\": \"Services/ITBasic/ComputeClusterDockerUsage.txt\",\n",
      "    \"reprev\": 8,\n",
      "    \"topicparent\": \"Services/ITBasic.ComputeCluster\",\n",
      "    \"version\": 8\n",
      "}\n",
      "CHUNK:\n",
      " Why Apptainer instead of docker?\n",
      "\n",
      "\n",
      "   * There are some important differences between Docker and Apptainer:\n",
      "\n",
      "      * Docker and Apptainer have their own container formats.\n",
      "\n",
      "      * Docker containers may be imported to run via Apptainer.\n",
      "\n",
      "      * Docker containers need root privileges for full functionality which is not suitable for a shared HPC environment.\n",
      "\n",
      "      * Apptainer allows working with containers as a regular user.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Why Apptainer instead of docker? Apptainer on the Cluster\n",
      "\n",
      "\n",
      "   * *As we have only recently implemented this feature, there may be issues or situations that have not been tested or are uncomfortable to use. If you notice anything that needs to be changed or adapted, please let us know via ticket@ukp...*\n",
      "\n",
      "   * Apptainer is available only on the compute nodes on the cluster. Therefore, to use it you need to either start an interactive job or submit a batch-job to the available SLURM queues.\n",
      "\n",
      "   * In the below examples we illustrate the interactive use of Apptainer in an interactive bash shell.\n",
      "\n",
      "   * grab a bash shell, e.g.\n",
      "\n",
      "      * <verbatim>srun --gres gpu:1 --pty bash -i</verbatim>\n",
      "\n",
      "   * check apptainer version\n",
      "\n",
      "      * <verbatim>bash-4.4$ apptainer --version\n",
      "\n",
      "apptainer version 1.1.9-1.el8 </verbatim>\n",
      "\n",
      "   * the most up-to-date help comes from apptainer itself\n",
      "\n",
      "      * <verbatim>bash-4.4$ apptainer --help\n",
      "\n",
      "\n",
      "\n",
      "Linux container platform optimized for High Performance Computing (HPC) and\n",
      "\n",
      "Enterprise Performance Computing (EPC)\n",
      "\n",
      "\n",
      "\n",
      "Usage:\n",
      "\n",
      "  apptainer [global options...]\n",
      "\n",
      "\n",
      "\n",
      "Description:\n",
      "\n",
      "  Apptainer containers provide an application virtualization layer enabling\n",
      "\n",
      "[...] shortened\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Why Apptainer instead of docker? Apptainer on the Cluster Getting existing images onto the cluster\n",
      "\n",
      "\n",
      "   * Apptainer uses container images which you can scp or rsync to the cluster as you would do with any other file. See Copying Data to & from the cluster for more information.\n",
      "\n",
      "   * Note: your folder on the central storage of UKP will be used. You should see a folder /ukp-storage-1/$USERNAME/.apptainer/ that contains all your Apptainer data. \n",
      "\n",
      "   * Apptainer is a fork of Singularity, so must of Singularitys commands and images should work, too.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METADATA: {\n",
      "    \"allow_view\": \"\",\n",
      "    \"author\": \"alles\",\n",
      "    \"chunk_header\": \"Tips;Forwarding connections;Automatically forwarding connections (transparent multi-hop ssh)\",\n",
      "    \"chunk_id\": 2,\n",
      "    \"date\": 1727883180,\n",
      "    \"deny_view\": \"%USERSWEB%.WikiGuest\",\n",
      "    \"format\": \"1.1\",\n",
      "    \"hash\": \"628b847b472d877193f17b6ecb24c58e049f063559bbb8c356d5c941d8ea3c5d\",\n",
      "    \"path\": \"Services/ITBasic/SshService.txt\",\n",
      "    \"reprev\": 22,\n",
      "    \"topicparent\": \"Resources\",\n",
      "    \"version\": 22\n",
      "}\n",
      "CHUNK:\n",
      "  * Connection example\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "ssh user@workstation.ukp.infomatik.tu-darmstadt.de\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "   * If you have the normal pass phrase login, then the above connection asks for two passwords: first one to login to the gateway and another one to login to the destination computer.\n",
      "\n",
      "   * The advantage of this is that the tunneling is transparent to user and system (i.e. you may forget about the intermediate hops altogether), and use other services as usual.\n",
      "\n",
      "      * ssh\n",
      "\n",
      "      * scp\n",
      "\n",
      "      * X forwarding: ssh -X\n",
      "\n",
      "      * rsync\n",
      "\n",
      "      * sftp\n",
      "\n",
      "      * etc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tips Forwarding connections Web proxy over ssh\n",
      "   * Sometimes you may want to create a web proxy to a remote network\n",
      "\n",
      "      * i.e. from home, you want to have access to journals that TU has subscription to, which needs connection from one of the university IP addresses\n",
      "\n",
      "   * 1) Create a SOCKS proxy using the ssh's dynamic port forwarding capability\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "ssh -C2qTnN -D 8080 projectvm.ukp.informatik.tu-darmstadt.de\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "   * 2) Configure your web browser to use a manually configured proxy \n",
      "\n",
      "      * In firefox,\n",
      "\n",
      "         *  Edit -> Preferences -> Advanced -> Network -> Connection/settings -> Manual proxy configuration:\n",
      "\n",
      "            * SOCKS host: localhost\n",
      "\n",
      "            * Port: 8080\n",
      "\n",
      "            * SOCKS v5\n",
      "\n",
      "         * or you can use a proxy plugin such as http://getfoxyproxy.org/ for easy management of proxies\n",
      "\n",
      "   * 3) Check whether that you get the remote server's ip from http://www.whatismyip.com/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tips Passwordless login\n",
      "\n",
      "\n",
      "If you want to login on a compute server, you always have to type your password. This prevents from using scripts, e.g. to copy a updated version of your source tree to your compute server's home directory.\n",
      "\n",
      "\n",
      "\n",
      "Fortunately, there is a workaround.\n",
      "\n",
      "\n",
      "\n",
      "Just copy the public key file (should be in ~/.ssh, otherwise ) to your computer server's home directory (directory =.ssh= has to exist in your home).\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "scp id_rsa.pub user@projectvm.tk.informatik.tu-darmstadt.de:.ssh/authorized_keys\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "(Note, that authorized_keys2 will be overwritten by this command. If you have already installed other keys, you have to add the new key to the file. )\n",
      "\n",
      "\n",
      "\n",
      "Afterwards you can login without the need for typing in your password.\n",
      "\n",
      "\n",
      "\n",
      "If there is no public key file, generate a new keypair with =ssh-keygen -t rsa= answer all questions by typing the RETURN key. Don't enter a passphrase.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METADATA: {\n",
      "    \"allow_view\": \"\",\n",
      "    \"author\": \"alles\",\n",
      "    \"chunk_header\": \"Slurm Compute Cluster FAQ;Host and Connect to webservices;Jupyter Notebook;Port Redirection / Proxy / TCP Forwarder\",\n",
      "    \"chunk_id\": 16,\n",
      "    \"date\": 1727877596,\n",
      "    \"deny_view\": \"%USERSWEB%.WikiGuest\",\n",
      "    \"format\": \"1.1\",\n",
      "    \"hash\": \"4a3bd651ff776936c751411daf5e72a5d46b0b09be92e8b897de26edef666e1f\",\n",
      "    \"path\": \"Services/ITBasic/ComputeClusterFAQ.txt\",\n",
      "    \"reprev\": 99,\n",
      "    \"topicparent\": \"Services/ITBasic.ComputeCluster\",\n",
      "    \"version\": 100\n",
      "}\n",
      "CHUNK:\n",
      "  calls in a .sh file to use with sbatch.\n",
      "\n",
      "   * The =-w= argument forces a job to run on a specific node. This is insofar important in that the compute nodes with Pokemon names (=turtok=, =blubella=, ...) cannot be reached from outside via VPN.\n",
      "\n",
      "   * This just works via UKP network and VPN, not via TU VPN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Slurm Compute Cluster FAQ Docker / Apptainer\n",
      "%INCLUDE{\"Services/ITBasic/ComputeClusterDockerUsage\"}%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Slurm Compute Cluster FAQ Advanced scheduling recipes\n",
      "Here are some examples how Slurm's advanced scheduling options can be combined.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Slurm Compute Cluster FAQ Advanced scheduling recipes Use timeout command to automatically restart jobs\n",
      "\n",
      "\n",
      "Taken from [[https://www.hpc.kaust.edu.sa/tips/use-%E2%80%9Ctimeout%E2%80%9D-command-automatically-restart-jobs][here]].\n",
      "\n",
      "\n",
      "\n",
      "Sometimes our jobs cannot be finished in the 24-hour time limit, and have to be restarted again and again until the calculations are completed successfully. Instead of manually checking the job states and resubmitting the jobscripts, we can use the linux command =timeout= to restart jobs automatically.\n",
      "\n",
      "\n",
      "\n",
      "For example, if you have a job that will need to run more than 24 hours (suppose the job is regularly checkpointed and can be restarted by just resubmitting the job), you can prepare a Slurm jobscript =my_slurm_jobscript= like this:\n",
      "\n",
      "\n",
      "\n",
      "<verbatim>\n",
      "\n",
      "#!/bin/bash\n",
      "\n",
      "…\n",
      "\n",
      "…\n",
      "\n",
      "#SBATCH --partition=ukp\n",
      "\n",
      "#SBATCH --nodes=1\n",
      "\n",
      "#SBATCH --time=24:00:00\n",
      "\n",
      "…\n",
      "\n",
      "…\n",
      "\n",
      "timeout 23h srun --ntasks=32 my_app\n",
      "\n",
      "if [[ $? -eq 124 ]]; then\n",
      "\n",
      "  sbatch my_slurm_jobscript\n",
      "\n",
      "fi\n",
      "\n",
      "</verbatim>\n",
      "\n",
      "\n",
      "\n",
      "In this job, =my_app= will be running for 23 hours at the most. If =my_app= is stopped by the =timeout= command, an exit code =124= will be returned and the jobscript =my_slurm_jobscript= will be automatically submitted again. Then the jobscrtipt =my_slurm_jobscript= will be repeatedly resubmitted until the calculation is fully completed.\n",
      "\n",
      "\n",
      "\n",
      "Please note:\n",
      "\n",
      "   * The Slurm time limit (24 hours in this case) should be a little bit longer than the =timeout= time limit (23 hours in this case), so that the =sbatch my_slurm_jobscript= will be able to executed.\n",
      "\n",
      "   * Do a test to make sure this works for you own case before using it massively in your production runs.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I setup port forwarding on the cluster?\"\n",
    "n_results = 5\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=model.get_text_embedding(query), n_results=n_results\n",
    ")\n",
    "\n",
    "for metadata, chunk in zip(results[\"metadatas\"][0], results[\"documents\"][0]):\n",
    "    print(\"-\" * 80)\n",
    "    print(\"METADATA:\", json.dumps(metadata, indent=4))\n",
    "    print(\"CHUNK:\\n\", chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
